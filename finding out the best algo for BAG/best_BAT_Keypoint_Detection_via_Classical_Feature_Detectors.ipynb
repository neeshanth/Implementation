{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sY48Ap7wK2Sn"
      },
      "source": [
        "PNEUMOTHORAX SEGMENTATION USING SIIM-ACR DATASET"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMmEp3gqUyn1",
        "outputId": "65d471e2-a706-4b08-d344-f21350cc6f8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y_qWc-LUIJCv"
      },
      "outputs": [],
      "source": [
        "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nz4WJSBg9UOk",
        "outputId": "5517e264-f5c5-42ea-9a58-cbc98b47b34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (0.8.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install einops\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sEfIEmqfADNu"
      },
      "outputs": [],
      "source": [
        "# !pip install efficientnet_pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECBIUxVDADNv"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# from monai.networks.nets.swin_unetr import SwinTransformer as SwinViT\n",
        "# from monai.utils import ensure_tuple_rep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7HFiESzDWcY"
      },
      "source": [
        "## Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {
        "id": "CUKZcMbBK2Ss"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import csv\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import json\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn as nn\n",
        "from collections import defaultdict\n",
        "import albumentations as albu\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms.functional as TF\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data.sampler import Sampler\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, f1_score\n",
        "import torchvision.models as models # NEW MARCH-JUNE EDIT\n",
        "\n",
        "try:\n",
        "    from itertools import ifilterfalse\n",
        "except ImportError:  # py3k\n",
        "    from itertools import filterfalse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {
        "id": "pzbBvorxADNw"
      },
      "outputs": [],
      "source": [
        "def init_seed(SEED=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.manual_seed(SEED)\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {
        "id": "Un-DgSH9ADNx"
      },
      "outputs": [],
      "source": [
        "init_seed()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xfcsl-YW_ck9"
      },
      "source": [
        "## Config - 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "-vx6RpZ8_bba"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE         = 512 # This is efficient and better for the completion of the project\n",
        "WHOSE_DIR        = \"Neeshanth\"\n",
        "\n",
        "if WHOSE_DIR == \"Aathesh\":\n",
        "    DIR              = \"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Colab_Notebooks\\\\datasets\\\\main\"\n",
        "    DATA_DIR         = Path(DIR)\n",
        "    TRAIN_IMG_DIR    = Path(\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Colab_Notebooks\\\\datasets\\\\main\\\\train_png\")\n",
        "    TRAIN_LBL_DIR    = Path(\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Colab_Notebooks\\\\datasets\\\\main\\\\mask\")\n",
        "    DATA_FRAME_PATH  = \"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Colab_Notebooks\\\\datasets\\\\main\\\\RLE_kfold.csv\"\n",
        "elif WHOSE_DIR == \"Neeshanth\":\n",
        "    DIR              = \"/content/drive/MyDrive/datasets\"\n",
        "    DATA_DIR         = Path(DIR)\n",
        "    TRAIN_IMG_DIR    = Path(\"/content/drive/MyDrive/datasets/train_png\")\n",
        "    TRAIN_LBL_DIR    = Path(\"/content/drive/MyDrive/datasets/mask\")\n",
        "    DATA_FRAME_PATH  = \"/content/drive/MyDrive/datasets/RLE_kfold.csv\"\n",
        "\n",
        "elif WHOSE_DIR == \"Kousik\":\n",
        "    DIR              = r\"C:\\Users\\kousi\\Downloads\\datasets\"\n",
        "    DATA_DIR         = Path(DIR)\n",
        "    TRAIN_IMG_DIR    = Path(r\"C:\\Users\\kousi\\Downloads\\datasets\\train_png\")\n",
        "    TRAIN_LBL_DIR    = Path(r\"C:\\Users\\kousi\\Downloads\\datasets\\mask\")\n",
        "    DATA_FRAME_PATH  = r\"C:\\Users\\kousi\\Downloads\\datasets\\RLE_kfold.csv\"\n",
        "\n",
        "elif WHOSE_DIR == \"wonder_boys\":\n",
        "    DIR              = \"/content/drive/MyDrive/Colab_Notebooks/datasets/main\"\n",
        "    DATA_DIR         = Path(DIR)\n",
        "    TRAIN_IMG_DIR    = Path(\"/content/drive/MyDrive/Colab_Notebooks/datasets/main/train_png\")\n",
        "    TRAIN_LBL_DIR    = Path(\"/content/drive/MyDrive/Colab_Notebooks/datasets/main/mask\")\n",
        "    DATA_FRAME_PATH  = \"/content/drive/MyDrive/Colab_Notebooks/datasets/main/RLE_kfold.csv\"\n",
        "\n",
        "KFOLD_PATH       = \"\"\n",
        "TRAIN_BATCH_SIZE = 10\n",
        "VALID_BATCH_SIZE = 10\n",
        "BATCH_SIZE       = 10\n",
        "EPOCHS           = 50\n",
        "# Path for pretrained model weights\n",
        "TRAINING_MODEL_PATH = \"\"\n",
        "USE_SAMPLER      = True\n",
        "POSTIVE_PERC     = 0.8\n",
        "DEVICE           = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "PRETRAINED       = False # False means we're using ImageNet weights, so essentially, it's pretrained & never from scratch!!!!!\n",
        "LEARNING_RATE    = 0.0001\n",
        "NUM_WORKERS      = 8\n",
        "USE_CRIT         = True\n",
        "FOLD_ID          = 4\n",
        "EVAL_METRICS      = [\"metric - it calculates dice coefficient.\"]\n",
        "\n",
        "# Regularization Settings\n",
        "EARLY_STOPPING_PATIENCE = 10\n",
        "L2_WEIGHT_DECAY  = 0.000005\n",
        "GRADIENT_CLIPPING = True\n",
        "GRADIENT_CLIPPING_THRESHOLD = 0.1\n",
        "\n",
        "# IF U DON'T WANT TO CHANGE Learning rate from previous experiment then set this to True.\n",
        "OPTIMIZER_LOAD = False\n",
        "# U MUST VERIFY IF LR IS GETTING SET PROPERLY FOR THE SCHEDULER IN THE \"OPTIMIZER & SCHEDULER\" SECTION OF THE NOTEBOOK.\n",
        "\n",
        "# Learning Rate Scheduler Settings\n",
        "SCHEDULER        = \"ReduceLROnPlateau\"\n",
        "if SCHEDULER == \"ReduceLROnPlateau\":\n",
        "    SCHEDULER_PARAMS = {'factor': 0.1, 'patience': 1, 'threshold': 0.0000001, 'min_lr': 0.0000001} # patience changed from 2 to 1 on 12-04-2025\n",
        "elif SCHEDULER == \"CosineAnnealingWarmRestarts\":\n",
        "    SCHEDULER_PARAMS = {'T_0': 1, 'T_mult': 2, 'eta_min': 0.00000001}\n",
        "elif SCHEDULER == \"CosineAnnealingLR\":\n",
        "    SCHEDULER_PARAMS = {'T_max': 8, 'eta_min': 0.0000001}\n",
        "\n",
        "# Thresholds for 1024x1024 is there along with div by 2 values and div by 4 values\n",
        "TRIPLET_THRESHOLDS = [  [0.6, 500.0, 0.35], [0.67, 500.0, 0.37], [0.75, 500.0, 0.3],\n",
        "                        [0.75, 500.0, 0.4], [0.75, 1000.0, 0.3], [0.75, 1000.0, 0.4],\n",
        "                        [0.6, 1000.0, 0.3], [0.6, 1000.0, 0.4], [0.6, 1500.0, 0.3],\n",
        "                        [0.6, 1500.0, 0.4], [0.6, 250.0, 0.35], [0.67, 250.0, 0.37],\n",
        "                        [0.75, 250.0, 0.3], [0.75, 250.0, 0.4], [0.75, 500.0, 0.3],\n",
        "                        [0.75, 500.0, 0.4], [0.6, 500.0, 0.3], [0.6, 500.0, 0.4],\n",
        "                        [0.6, 750.0, 0.3], [0.6, 750.0, 0.4], [0.6, 1000, 0.35],\n",
        "                        [0.67, 1000, 0.37], [0.75, 1000, 0.3], [0.75, 1000, 0.4],\n",
        "                        [0.75, 2000, 0.3], [0.75, 2000, 0.4], [0.6, 2000, 0.3],\n",
        "                        [0.6, 2000, 0.4], [0.6, 3000, 0.3], [0.6, 3000, 0.4]       ]\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    \"-------------------------------SAVING losses & metrics-------------------------------------\"\n",
        "\"\"\"\n",
        "ACCOUNT         = \"Neeshanth\" # \"Neeshanth\" or \"wonder_boys\" or others\n",
        "PURPOSE         = \"Project-2\" # training/inference/hyperparameter-tuning or hpt OR ANYTHING MORE SPECIFIC\n",
        "EXP_NO          = \"first_run\" # hpt experiment with changed settings\n",
        "PHASE           = \"12_04_2025\" # Just date\n",
        "\n",
        "EFFECTIVE_BATCH_SIZE = 10 # accumulation_steps * BATCH_SIZE\n",
        "\n",
        "if ACCOUNT == \"Neeshanth\":\n",
        "    # Save Config.txt\n",
        "    CONFIG_FILE_LOC = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/Config.txt\"\n",
        "\n",
        "    # Save model checkpoint using early stopping class\n",
        "    model_checkpoint_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/m_{IMG_SIZE}_CHECKPOINTS\"\n",
        "\n",
        "    # Save batch wise comboloss during training\n",
        "    store_batch_training_details_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_train_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_training_details_csv = f\"{PURPOSE}_TRAIN_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_epoch_\" # epoch no. will be added to the end\n",
        "\n",
        "    # Save batch wise comboloss during validation\n",
        "    store_batch_validation_details_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_vali_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_validation_details_csv = f\"{PURPOSE}_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_Validation_Metrics\"\n",
        "\n",
        "    # Save epoch wise train and val losses to monitor overfitting\n",
        "    save_progress_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_progress.csv\"\n",
        "\n",
        "    # Save epoch wise dice coefficient\n",
        "    save_dice_score_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_dice_scores.csv\"\n",
        "\n",
        "    # Save bce, dice & focal losses separately after training is done\n",
        "    save_3losses_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_all_loss_values.csv\"\n",
        "\n",
        "    # Save best thresholds & their dice scores - done according to Triplet Scheme of Binarization\n",
        "    save_best_thresholds_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_best_checkpoint_thresholds.csv\"\n",
        "\n",
        "if ACCOUNT == \"Kousik\":\n",
        "    # Save Config.txt\n",
        "    CONFIG_FILE_LOC = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\Config.txt\"\n",
        "\n",
        "    # Save model checkpoint using early stopping class\n",
        "    model_checkpoint_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\m_{IMG_SIZE}_CHECKPOINTS\"\n",
        "\n",
        "    # Save batch-wise comboloss during training\n",
        "    store_batch_training_details_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_train_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_training_details_csv = f\"{PURPOSE}_TRAIN_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_epoch_\"  # epoch no. will be added to the end\n",
        "\n",
        "    # Save batch-wise comboloss during validation\n",
        "    store_batch_validation_details_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_vali_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_validation_details_csv = f\"{PURPOSE}_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_Validation_Metrics\"\n",
        "\n",
        "    # Save epoch-wise train and val losses to monitor overfitting\n",
        "    save_progress_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_progress.csv\"\n",
        "\n",
        "    # Save epoch-wise dice coefficient\n",
        "    save_dice_score_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_dice_scores.csv\"\n",
        "\n",
        "    # Save BCE, dice & focal losses separately after training is done\n",
        "    save_3losses_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_all_loss_values.csv\"\n",
        "\n",
        "    # Save best thresholds & their dice scores - done according to Triplet Scheme of Binarization\n",
        "    save_best_thresholds_path = rf\"E:\\Project Metrics\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\{EXP_NO}_best_checkpoint_thresholds.csv\"\n",
        "\n",
        "\n",
        "if ACCOUNT == \"wonder_boys\":\n",
        "    # Save Config.txt file\n",
        "    CONFIG_FILE_LOC = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/Config.txt\"\n",
        "\n",
        "    # Save model checkpoint using early stopping class\n",
        "    model_checkpoint_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/m_{IMG_SIZE}_CHECKPOINTS\"\n",
        "\n",
        "    # Save batch wise comboloss during training\n",
        "    store_batch_training_details_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_train_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_training_details_csv = f\"{PURPOSE}_TRAIN_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_epoch_\" # epoch no. will be added to the end\n",
        "\n",
        "    # Save batch wise comboloss during validation\n",
        "    store_batch_validation_details_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_vali_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_validation_details_csv = f\"{PURPOSE}_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_Validation_Metrics\"\n",
        "\n",
        "    # Save epoch wise train and val losses to monitor overfitting\n",
        "    save_progress_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_progress.csv\"\n",
        "\n",
        "    # Save epoch wise dice coefficient\n",
        "    save_dice_score_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_dice_scores.csv\"\n",
        "\n",
        "    # Save bce, dice & focal losses separately after training is done\n",
        "    save_3losses_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_all_loss_values.csv\"\n",
        "\n",
        "    # Save best thresholds & their dice scores - done according to Triplet Scheme of Binarization\n",
        "    save_best_thresholds_path = f\"/content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/{PURPOSE}_EXP_{EXP_NO}_{PHASE}/{EXP_NO}_best_checkpoint_thresholds.csv\"\n",
        "\n",
        "if ACCOUNT == \"pc_aathesh\":\n",
        "    # Save Config.txt file\n",
        "    CONFIG_FILE_LOC = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}/Config.txt\"\n",
        "\n",
        "    # Save batch wise comboloss during training\n",
        "    store_batch_training_details_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\CHECKPOINTS\"\n",
        "    name_of_batch_training_details_csv = f\"{PURPOSE}_TRAIN_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_epoch_\" # epoch no. will be added to the end\n",
        "\n",
        "    # Save batch wise comboloss during validation\n",
        "    store_batch_validation_details_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\{PURPOSE}_vali_m{IMG_SIZE}_b{EFFECTIVE_BATCH_SIZE}\"\n",
        "    name_of_batch_validation_details_csv = f\"{PURPOSE}_{IMG_SIZE}_b_{EFFECTIVE_BATCH_SIZE}_Validation_Metrics\"\n",
        "\n",
        "    # Save epoch wise train and val losses to monitor overfitting\n",
        "    save_progress_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\{PURPOSE}_progress.csv\"\n",
        "\n",
        "    # Save epoch wise dice coefficient\n",
        "    save_dice_score_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\{PURPOSE}_dice_score.csv\"\n",
        "\n",
        "    # Save bce, dice & focal losses separately after training is done\n",
        "    save_3losses_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\{PURPOSE}_all_loss_vals.csv\"\n",
        "\n",
        "    # Save model checkpoint using early stopping class - CREATE A NEW FOLDER\n",
        "    model_checkpoint_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\m_{IMG_SIZE}_CHECKPOINTS\"\n",
        "\n",
        "    # Save best thresholds & their dice scores - done according to Triplet Scheme of Binarization\n",
        "    save_best_thresholds_path = f\"C:\\\\Users\\\\aathe\\\\Google Drive - Wonder Boys\\\\Saved Models\\\\{PURPOSE}_EXP_{EXP_NO}_{PHASE}\\\\{PURPOSE}_best_checkpoint_thresholds.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A4XlffPf1jV"
      },
      "source": [
        "## Saving Config as .txt - TYPE ESSENTIAL DETAILS TO RECOVER THIS EXPERIMENT IN THE BELOW SNIPPET"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB0Igy_Tf1jV"
      },
      "source": [
        "ESSENTIALS include current_notebook_loc_in_pc, previous_notebook_loc_in_pc, key_changes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3likqSVNf1jV",
        "outputId": "20017948-3c49-4207-e51f-392fcac8c064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current IST date and time is: 14-04-2025 00:49:20\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "import pytz\n",
        "\n",
        "# Define the IST timezone\n",
        "ist_timezone = pytz.timezone('Asia/Kolkata')\n",
        "\n",
        "# Get the current time in IST\n",
        "ist_time = datetime.now(ist_timezone)\n",
        "\n",
        "# Format the date and time to DD-MM-YYYY HH:MM:SS\n",
        "formatted_ist_time = ist_time.strftime(\"%d-%m-%Y %H:%M:%S\")\n",
        "\n",
        "# Print the formatted IST time\n",
        "print(\"Current IST date and time is:\", formatted_ist_time)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bwNCwwVf1jV",
        "outputId": "7b83cd1a-ac25-4fa9-eb3e-63c559606414"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hyper-parameters have been saved to /content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/Project-2_EXP_first_run_12_04_2025/Config.txt\n"
          ]
        }
      ],
      "source": [
        "hyperparameters = {\n",
        "    'image_size': f\"{IMG_SIZE}x{IMG_SIZE}\",\n",
        "    'date': formatted_ist_time,\n",
        "    'account': ACCOUNT,\n",
        "    'purpose': PURPOSE,\n",
        "    'experiment_no': EXP_NO,\n",
        "    'key_changes': \"\" ,\n",
        "    'checkpoint_used_loc': TRAINING_MODEL_PATH,\n",
        "    'is_optimizer_loaded': OPTIMIZER_LOAD,\n",
        "    'learning_rate': LEARNING_RATE,\n",
        "    'batch_size': EFFECTIVE_BATCH_SIZE,\n",
        "    'gradient_accumulation_steps': int(EFFECTIVE_BATCH_SIZE/BATCH_SIZE),\n",
        "    'num_epochs': EPOCHS,\n",
        "    'IsSamplerUsed': USE_SAMPLER,\n",
        "    'percentage_of_positive_samples': POSTIVE_PERC,\n",
        "    'optimizer': 'Adam',\n",
        "    'loss_function': 'ComboLoss',\n",
        "    'scheduler': SCHEDULER,\n",
        "    'scheduler_params': SCHEDULER_PARAMS,\n",
        "    'L2_Regularization_weight_decay':L2_WEIGHT_DECAY,\n",
        "    'early_stopping_patience': EARLY_STOPPING_PATIENCE,\n",
        "    'is_gradient_clipping_used': GRADIENT_CLIPPING,\n",
        "    'gradient_clipping_threshold': GRADIENT_CLIPPING_THRESHOLD,\n",
        "    'model': 'Hybrid Vision Transformer',\n",
        "    'training_phase': f\"Phase - {PHASE}\",\n",
        "    'fold_ID': FOLD_ID,\n",
        "    'GPU_name': torch.cuda.get_device_name(torch.cuda.current_device()),\n",
        "    'num_workers': NUM_WORKERS,\n",
        "    'weights_given_to_loss_functions': {'bce': 3, 'dice': 1, 'focal': 4},\n",
        "    'triplet_thresholds': TRIPLET_THRESHOLDS,\n",
        "    'evaluation_metrics': EVAL_METRICS,\n",
        "}\n",
        "\n",
        "# Convert the dictionary to a formatted string\n",
        "hyperparameters_str = json.dumps(hyperparameters, indent=4)\n",
        "\n",
        "# Specify the file name\n",
        "file_name = CONFIG_FILE_LOC\n",
        "\n",
        "os.makedirs(os.path.dirname(file_name), exist_ok=True)\n",
        "\n",
        "# Write the string to a file\n",
        "with open(file_name, 'w') as file:\n",
        "    file.write(hyperparameters_str)\n",
        "\n",
        "print(f\"Hyper-parameters have been saved to {file_name}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xtZrBIJeLH_"
      },
      "source": [
        "## Losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "id": "BjVO5UiC1z-h"
      },
      "outputs": [],
      "source": [
        "bce_losses = []\n",
        "dice_losses = []\n",
        "focal_losses = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "id": "8MgSVyz79UOs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from scipy.ndimage import distance_transform_edt as distance\n",
        "from skimage import segmentation as skimage_seg\n",
        "\n",
        "\n",
        "def dice_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target * target)\n",
        "    z_sum = torch.sum(score * score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "\n",
        "def dice_loss1(score, target):\n",
        "    # non-square\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target)\n",
        "    z_sum = torch.sum(score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "\n",
        "def iou_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    tp_sum = torch.sum(score * target)\n",
        "    fp_sum = torch.sum(score * (1 - target))\n",
        "    fn_sum = torch.sum((1 - score) * target)\n",
        "    loss = (tp_sum + smooth) / (tp_sum + fp_sum + fn_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss\n",
        "\n",
        "\n",
        "def entropy_loss(p, C=2):\n",
        "    ## p N*C*W*H*D\n",
        "    y1 = -1 * torch.sum(p * torch.log(p + 1e-6), dim=1) / torch.tensor(\n",
        "        np.log(C)).cuda()\n",
        "    ent = torch.mean(y1)\n",
        "\n",
        "    return ent\n",
        "\n",
        "\n",
        "def softmax_dice_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_softmax = F.softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "    n = input_logits.shape[1]\n",
        "    dice = 0\n",
        "    for i in range(0, n):\n",
        "        dice += dice_loss1(input_softmax[:, i], target_softmax[:, i])\n",
        "    mean_dice = dice / n\n",
        "\n",
        "    return mean_dice\n",
        "\n",
        "\n",
        "def entropy_loss_map(p, C=2):\n",
        "    ent = -1 * torch.sum(p * torch.log(p + 1e-6), dim=1,\n",
        "                         keepdim=True) / torch.tensor(np.log(C)).cuda()\n",
        "    return ent\n",
        "\n",
        "\n",
        "def softmax_mse_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns MSE loss\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_softmax = F.softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "\n",
        "    mse_loss = (input_softmax - target_softmax)**2\n",
        "    return mse_loss\n",
        "\n",
        "\n",
        "def softmax_kl_loss(input_logits, target_logits):\n",
        "    \"\"\"Takes softmax on both sides and returns KL divergence\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to inputs but not the targets.\n",
        "    \"\"\"\n",
        "    assert input_logits.size() == target_logits.size()\n",
        "    input_log_softmax = F.log_softmax(input_logits, dim=1)\n",
        "    target_softmax = F.softmax(target_logits, dim=1)\n",
        "\n",
        "    # return F.kl_div(input_log_softmax, target_softmax)\n",
        "    kl_div = F.kl_div(input_log_softmax, target_softmax, reduction='none')\n",
        "    # mean_kl_div = torch.mean(0.2*kl_div[:,0,...]+0.8*kl_div[:,1,...])\n",
        "    return kl_div\n",
        "\n",
        "\n",
        "def symmetric_mse_loss(input1, input2):\n",
        "    \"\"\"Like F.mse_loss but sends gradients to both directions\n",
        "    Note:\n",
        "    - Returns the sum over all examples. Divide by the batch size afterwards\n",
        "      if you want the mean.\n",
        "    - Sends gradients to both input1 and input2.\n",
        "    \"\"\"\n",
        "    assert input1.size() == input2.size()\n",
        "    return torch.mean((input1 - input2)**2)\n",
        "\n",
        "\n",
        "def compute_sdf01(segmentation):\n",
        "    \"\"\"\n",
        "    compute the signed distance map of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "    \"\"\"\n",
        "    # print(type(segmentation), segmentation.shape)\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "\n",
        "    if len(segmentation.shape) == 4:  # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]):  # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]):  # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            if np.max(posmask) == 0:\n",
        "                continue\n",
        "            negmask = ~posmask\n",
        "            posdis = distance(posmask)\n",
        "            negdis = distance(negmask)\n",
        "            boundary = skimage_seg.find_boundaries(\n",
        "                posmask, mode='inner').astype(np.uint8)\n",
        "            sdf = negdis / np.max(negdis) / 2 - posdis / np.max(\n",
        "                posdis) / 2 + 0.5\n",
        "            sdf[boundary > 0] = 0.5\n",
        "            normalized_sdf[b][c] = sdf\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def compute_sdf1_1(segmentation):\n",
        "    \"\"\"\n",
        "    compute the signed distance map of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "    \"\"\"\n",
        "    # print(type(segmentation), segmentation.shape)\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "    if len(segmentation.shape) == 4:  # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]):  # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]):  # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            if np.max(posmask) == 0:\n",
        "                continue\n",
        "            negmask = ~posmask\n",
        "            posdis = distance(posmask)\n",
        "            negdis = distance(negmask)\n",
        "            boundary = skimage_seg.find_boundaries(\n",
        "                posmask, mode='inner').astype(np.uint8)\n",
        "            sdf = negdis / np.max(negdis) - posdis / np.max(posdis)\n",
        "            sdf[boundary > 0] = 0\n",
        "            normalized_sdf[b][c] = sdf\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def compute_fore_dist(segmentation):\n",
        "    \"\"\"\n",
        "    compute the foreground of binary mask\n",
        "    input: segmentation, shape = (batch_size, class, x, y, z)\n",
        "    output: the Signed Distance Map (SDM)\n",
        "    sdm(x) = 0; x in segmentation boundary\n",
        "             -inf|x-y|; x in segmentation\n",
        "             +inf|x-y|; x out of segmentation\n",
        "    \"\"\"\n",
        "    # print(type(segmentation), segmentation.shape)\n",
        "\n",
        "    segmentation = segmentation.astype(np.uint8)\n",
        "    if len(segmentation.shape) == 4:  # 3D image\n",
        "        segmentation = np.expand_dims(segmentation, 1)\n",
        "    normalized_sdf = np.zeros(segmentation.shape)\n",
        "    if segmentation.shape[1] == 1:\n",
        "        dis_id = 0\n",
        "    else:\n",
        "        dis_id = 1\n",
        "    for b in range(segmentation.shape[0]):  # batch size\n",
        "        for c in range(dis_id, segmentation.shape[1]):  # class_num\n",
        "            # ignore background\n",
        "            posmask = segmentation[b][c]\n",
        "            posdis = distance(posmask)\n",
        "            normalized_sdf[b][c] = posdis / np.max(posdis)\n",
        "    return normalized_sdf\n",
        "\n",
        "\n",
        "def sum_tensor(inp, axes, keepdim=False):\n",
        "    axes = np.unique(axes).astype(int)\n",
        "    if keepdim:\n",
        "        for ax in axes:\n",
        "            inp = inp.sum(int(ax), keepdim=True)\n",
        "    else:\n",
        "        for ax in sorted(axes, reverse=True):\n",
        "            inp = inp.sum(int(ax))\n",
        "    return inp\n",
        "\n",
        "\n",
        "def AAAI_sdf_loss(net_output, gt):\n",
        "    \"\"\"\n",
        "    net_output: net logits; shape=(batch_size, class, x, y, z)\n",
        "    gt: ground truth; (shape (batch_size, 1, x, y, z) OR (batch_size, x, y, z))\n",
        "    \"\"\"\n",
        "    smooth = 1e-5\n",
        "    axes = tuple(range(2, len(net_output.size())))\n",
        "    shp_x = net_output.shape\n",
        "    shp_y = gt.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if len(shp_x) != len(shp_y):\n",
        "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
        "\n",
        "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
        "            # if this is the case then gt is probably already a one hot encoding\n",
        "            y_onehot = gt\n",
        "        else:\n",
        "            gt = gt.long()\n",
        "            y_onehot = torch.zeros(shp_x)\n",
        "            if net_output.device.type == \"cuda\":\n",
        "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
        "            y_onehot.scatter_(1, gt, 1)\n",
        "        gt_sdm_npy = compute_sdf1_1(y_onehot.cpu().numpy())\n",
        "        if net_output.device.type == \"cuda\":\n",
        "            gt_sdm = torch.from_numpy(gt_sdm_npy).float().cuda(\n",
        "                net_output.device.index)\n",
        "        else:\n",
        "            gt_sdm = torch.from_numpy(gt_sdm_npy).float()\n",
        "    intersect = sum_tensor(net_output * gt_sdm, axes, keepdim=False)\n",
        "    pd_sum = sum_tensor(net_output**2, axes, keepdim=False)\n",
        "    gt_sum = sum_tensor(gt_sdm**2, axes, keepdim=False)\n",
        "    L_product = (intersect + smooth) / (intersect + pd_sum + gt_sum)\n",
        "    # print('L_product.shape', L_product.shape) (4,2)\n",
        "    L_SDF_AAAI = -L_product.mean() + torch.norm(net_output - gt_sdm,\n",
        "                                                1) / torch.numel(net_output)\n",
        "\n",
        "    return L_SDF_AAAI\n",
        "\n",
        "\n",
        "def sdf_kl_loss(net_output, gt):\n",
        "    \"\"\"\n",
        "    net_output: net logits; shape=(batch_size, class, x, y, z)\n",
        "    gt: ground truth; (shape (batch_size, 1, x, y, z) OR (batch_size, x, y, z))\n",
        "    \"\"\"\n",
        "    smooth = 1e-5\n",
        "    axes = tuple(range(2, len(net_output.size())))\n",
        "    shp_x = net_output.shape\n",
        "    shp_y = gt.shape\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if len(shp_x) != len(shp_y):\n",
        "            gt = gt.view((shp_y[0], 1, *shp_y[1:]))\n",
        "\n",
        "        if all([i == j for i, j in zip(net_output.shape, gt.shape)]):\n",
        "            # if this is the case then gt is probably already a one hot encoding\n",
        "            y_onehot = gt\n",
        "        else:\n",
        "            gt = gt.long()\n",
        "            y_onehot = torch.zeros(shp_x)\n",
        "            if net_output.device.type == \"cuda\":\n",
        "                y_onehot = y_onehot.cuda(net_output.device.index)\n",
        "            y_onehot.scatter_(1, gt, 1)\n",
        "        # print('y_onehot.shape', y_onehot.shape)\n",
        "        gt_sdf_npy = compute_sdf(y_onehot.cpu().numpy())\n",
        "        gt_sdf = torch.from_numpy(gt_sdf_npy + smooth).float().cuda(\n",
        "            net_output.device.index)\n",
        "    # print('net_output, gt_sdf', net_output.shape, gt_sdf.shape)\n",
        "    # exit()\n",
        "    sdf_kl_loss = F.kl_div(net_output,\n",
        "                           gt_sdf[:, 1:2, ...],\n",
        "                           reduction='batchmean')\n",
        "\n",
        "    return sdf_kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "id": "-GiUgprmeQ97"
      },
      "outputs": [],
      "source": [
        "eps = 1e-6\n",
        "\n",
        "\n",
        "def soft_dice_loss(outputs, targets, per_image=False, per_channel=False):\n",
        "    \"\"\"\n",
        "        If per_image = False, then the function calculates dice loss for a single image-mask pair.\n",
        "    \"\"\"\n",
        "    batch_size, n_channels = outputs.size(0), outputs.size(1)\n",
        "\n",
        "    eps = 1e-6\n",
        "    n_parts = 1\n",
        "    if per_image:\n",
        "        n_parts = batch_size\n",
        "    if per_channel:\n",
        "        n_parts = batch_size * n_channels\n",
        "\n",
        "    dice_target = targets.contiguous().view(n_parts, -1).float()\n",
        "    dice_output = outputs.contiguous().view(n_parts, -1)\n",
        "    intersection = torch.sum(dice_output * dice_target, dim=1)\n",
        "    union = torch.sum(dice_output, dim=1) + torch.sum(dice_target, dim=1)\n",
        "    loss = (1 - (2 * intersection + eps) / (union + eps)) # returns a tensor of size [8]\n",
        "    return loss.mean() # returns a tensor of size [1].\n",
        "\n",
        "def dice_metric(preds, trues, per_image=False, per_channel=False):\n",
        "    preds = preds.float()\n",
        "    return 1 - soft_dice_loss(preds, trues, per_image, per_channel)\n",
        "\n",
        "\n",
        "def jaccard(outputs, targets, per_image=False, non_empty=False, min_pixels=5):\n",
        "    batch_size = outputs.size()[0]\n",
        "    eps = 1e-3\n",
        "    if not per_image:\n",
        "        batch_size = 1\n",
        "    dice_target = targets.contiguous().view(batch_size, -1).float()\n",
        "    dice_output = outputs.contiguous().view(batch_size, -1)\n",
        "    target_sum = torch.sum(dice_target, dim=1)\n",
        "    intersection = torch.sum(dice_output * dice_target, dim=1)\n",
        "    losses = 1 - (intersection + eps) / (torch.sum(dice_output + dice_target, dim=1) - intersection + eps)\n",
        "    if non_empty:\n",
        "        assert per_image == True\n",
        "        non_empty_images = 0\n",
        "        sum_loss = 0\n",
        "        for i in range(batch_size):\n",
        "            if target_sum[i] > min_pixels:\n",
        "                sum_loss += losses[i]\n",
        "                non_empty_images += 1\n",
        "        if non_empty_images == 0:\n",
        "            return 0\n",
        "        else:\n",
        "            return sum_loss / non_empty_images\n",
        "\n",
        "    return losses.mean()\n",
        "\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True, per_image=False):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.register_buffer('weight', weight)\n",
        "        self.per_image = per_image\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        dice_loss = soft_dice_loss(input, target, per_image=self.per_image)\n",
        "        dice_losses.append(dice_loss.item())\n",
        "        return dice_loss\n",
        "\n",
        "\n",
        "class JaccardLoss(nn.Module):\n",
        "    def __init__(self, weight=None, size_average=True, per_image=False, non_empty=False, apply_sigmoid=False,\n",
        "                 min_pixels=5):\n",
        "        super().__init__()\n",
        "        self.size_average = size_average\n",
        "        self.register_buffer('weight', weight)\n",
        "        self.per_image = per_image\n",
        "        self.non_empty = non_empty\n",
        "        self.apply_sigmoid = apply_sigmoid\n",
        "        self.min_pixels = min_pixels\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if self.apply_sigmoid:\n",
        "            input = torch.sigmoid(input)\n",
        "        return jaccard(input, target, per_image=self.per_image, non_empty=self.non_empty, min_pixels=self.min_pixels)\n",
        "\n",
        "class StableBCELoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(StableBCELoss, self).__init__()\n",
        "\n",
        "    def forward(self, logits, target):\n",
        "        bce_loss_with_logits = nn.BCEWithLogitsLoss(reduction='mean') # mean is taken across batches\n",
        "        bce_loss = bce_loss_with_logits(logits, target)\n",
        "        bce_losses.append(bce_loss.item())\n",
        "        return bce_loss # returns a tensor of size [1]\n",
        "\n",
        "\n",
        "class ComboLoss(nn.Module):\n",
        "    def __init__(self, weights, per_image=True, channel_weights=[1, 0.5, 0.5], channel_losses=None):\n",
        "        super().__init__()\n",
        "        self.weights = weights\n",
        "        self.bce = StableBCELoss()\n",
        "        self.dice = DiceLoss(per_image=True)\n",
        "        self.jaccard = JaccardLoss(per_image=True)\n",
        "        self.lovasz = LovaszLoss(per_image=per_image)\n",
        "        self.lovasz_sigmoid = LovaszLossSigmoid(per_image=per_image)\n",
        "        self.focal = FocalLoss2d()\n",
        "        self.mapping = {'bce': self.bce,\n",
        "                        'dice': self.dice,\n",
        "                        'focal': self.focal,\n",
        "                        'jaccard': self.jaccard,\n",
        "                        'lovasz': self.lovasz,\n",
        "                        'lovasz_sigmoid': self.lovasz_sigmoid}\n",
        "        self.expect_sigmoid = {'dice', 'focal', 'jaccard', 'lovasz_sigmoid'}\n",
        "        self.per_channel = {'dice', 'jaccard', 'lovasz_sigmoid'}\n",
        "        self.values = {}\n",
        "        self.channel_weights = channel_weights\n",
        "        self.channel_losses = channel_losses\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        loss = 0\n",
        "        weights = self.weights\n",
        "        sigmoid_input = torch.sigmoid(outputs)\n",
        "        for k, v in weights.items():\n",
        "            if not v:\n",
        "                continue\n",
        "            val = 0\n",
        "            if k in self.per_channel:\n",
        "                channels = targets.size(1)\n",
        "                for c in range(channels):\n",
        "                    if not self.channel_losses or k in self.channel_losses[c]:\n",
        "                        val += self.channel_weights[c] * self.mapping[k](sigmoid_input[:, c, ...] if k in self.expect_sigmoid else outputs[:, c, ...],\n",
        "                                               targets[:, c, ...])\n",
        "\n",
        "            else:\n",
        "                val = self.mapping[k](sigmoid_input if k in self.expect_sigmoid else outputs, targets)\n",
        "\n",
        "            self.values[k] = val\n",
        "            loss += self.weights[k] * val\n",
        "        return loss.clamp(min=1e-5)\n",
        "\n",
        "\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    p = len(gt_sorted)\n",
        "    gts = gt_sorted.sum()\n",
        "    intersection = gts.float() - gt_sorted.float().cumsum(0)\n",
        "    union = gts.float() + (1 - gt_sorted).float().cumsum(0)\n",
        "    jaccard = 1. - intersection / union\n",
        "    if p > 1:  # cover 1-pixel case\n",
        "        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
        "                    for log, lab in zip(logits, labels))\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "    if len(labels) == 0:\n",
        "        # only void pixels, the gradients should be 0\n",
        "        return logits.sum() * 0.\n",
        "    signs = 2. * labels.float() - 1.\n",
        "    errors = (1. - logits * Variable(signs))\n",
        "    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n",
        "    perm = perm.data\n",
        "    gt_sorted = labels[perm]\n",
        "    grad = lovasz_grad(gt_sorted)\n",
        "    loss = torch.dot(F.relu(errors_sorted), Variable(grad))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = scores.view(-1)\n",
        "    labels = labels.view(-1)\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = (labels != ignore)\n",
        "    vscores = scores[valid]\n",
        "    vlabels = labels[valid]\n",
        "    return vscores, vlabels\n",
        "\n",
        "\n",
        "def lovasz_sigmoid(probas, labels, per_image=False, ignore=None):\n",
        "    \"\"\"\n",
        "    Multi-class Lovasz-Softmax loss\n",
        "      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n",
        "      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n",
        "      only_present: average only on classes present in ground truth\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class labels\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        loss = mean(lovasz_sigmoid_flat(*flatten_binary_scores(prob.unsqueeze(0), lab.unsqueeze(0), ignore))\n",
        "                          for prob, lab in zip(probas, labels))\n",
        "    else:\n",
        "        loss = lovasz_sigmoid_flat(*flatten_binary_scores(probas, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_sigmoid_flat(probas, labels):\n",
        "    \"\"\"\n",
        "    Multi-class Lovasz-Softmax loss\n",
        "      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n",
        "      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n",
        "      only_present: average only on classes present in ground truth\n",
        "    \"\"\"\n",
        "    fg = labels.float()\n",
        "    errors = (Variable(fg) - probas).abs()\n",
        "    errors_sorted, perm = torch.sort(errors, 0, descending=True)\n",
        "    perm = perm.data\n",
        "    fg_sorted = fg[perm]\n",
        "    loss = torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted)))\n",
        "    return loss\n",
        "\n",
        "def symmetric_lovasz(outputs, targets, ):\n",
        "    return (lovasz_hinge(outputs, targets) + lovasz_hinge(-outputs, 1 - targets)) / 2\n",
        "\n",
        "def mean(l, ignore_nan=False, empty=0):\n",
        "    \"\"\"\n",
        "    nanmean compatible with generators.\n",
        "    \"\"\"\n",
        "    l = iter(l)\n",
        "    if ignore_nan:\n",
        "        l = ifilterfalse(np.isnan, l)\n",
        "    try:\n",
        "        n = 1\n",
        "        acc = next(l)\n",
        "    except StopIteration:\n",
        "        if empty == 'raise':\n",
        "            raise ValueError('Empty mean')\n",
        "        return empty\n",
        "    for n, v in enumerate(l, 2):\n",
        "        acc += v\n",
        "    if n == 1:\n",
        "        return acc\n",
        "    return acc / n\n",
        "\n",
        "\n",
        "class LovaszLoss(nn.Module):\n",
        "    def __init__(self, ignore_index=255, per_image=True):\n",
        "        super().__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "        self.per_image = per_image\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        outputs = outputs.contiguous()\n",
        "        targets = targets.contiguous()\n",
        "        return symmetric_lovasz(outputs, targets)\n",
        "\n",
        "class LovaszLossSigmoid(nn.Module):\n",
        "    def __init__(self, ignore_index=255, per_image=True):\n",
        "        super().__init__()\n",
        "        self.ignore_index = ignore_index\n",
        "        self.per_image = per_image\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        outputs = outputs.contiguous()\n",
        "        targets = targets.contiguous()\n",
        "        return lovasz_sigmoid(outputs, targets, per_image=self.per_image, ignore=self.ignore_index)\n",
        "\n",
        "class FocalLoss2d(nn.Module):\n",
        "    def __init__(self, alpha=0.65, gamma=2,n_parts=BATCH_SIZE):\n",
        "        super().__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.n_parts = n_parts\n",
        "\n",
        "    def forward(self, outputs, targets):\n",
        "        n_parts = self.n_parts\n",
        "        outputs = outputs.contiguous()\n",
        "        targets = targets.contiguous()\n",
        "        eps = 1e-6\n",
        "        # non_ignored = targets.view(n_parts, -1) != self.ignore_index\n",
        "        targets = targets.view(n_parts, -1).float()\n",
        "        outputs = outputs.view(n_parts, -1)\n",
        "        # clamp just makes sure the values of the tensor is within the given range.\n",
        "        outputs = torch.clamp(outputs, eps, 1. - eps)\n",
        "        targets = torch.clamp(targets, eps, 1. - eps)\n",
        "        \"\"\" pt = predicted probability for the true class\n",
        "        when targets = 1, pt = outputs which means pt now has the predicted probability of positive class.\n",
        "        when tagets = 0, pt = 1 - outputs which means pt has the predicted probability of negative class.\n",
        "        \"\"\"\n",
        "        pt = (1 - targets) * (1 - outputs) + targets * outputs\n",
        "        alpha_t = self.alpha * targets + (1 - self.alpha)*(1 - targets)\n",
        "        pt_proc = -(alpha_t*((1. - pt) ** self.gamma * torch.log(pt))) # torch.log is natural log\n",
        "        focal_loss = pt_proc.mean(dim=1).mean()\n",
        "        focal_losses.append(focal_loss.item())\n",
        "        return focal_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-y8ovXEK2St"
      },
      "source": [
        "## Config - 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQG4nEiq9UOu",
        "outputId": "a88f886e-0375-4150-9adf-811caa998b9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Namespace(arch='BAT', gpu='1', net_layer=50, seg_loss=0, pre=0, trans=1, point_pred=1, ppl=6, cross=0)\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--arch', type=str, default='BAT')\n",
        "parser.add_argument('--gpu', type=str, default='1')\n",
        "parser.add_argument('--net_layer', type=int, default=50)\n",
        "# parser.add_argument('--dataset', type=str, default='isic2016')\n",
        "# parser.add_argument('--exp_name', type=str, default='')\n",
        "# parser.add_argument('--fold', type=str, default='0')\n",
        "# parser.add_argument('--lr_seg', type=float, default=1e-4)  #0.0003\n",
        "# parser.add_argument('--n_epochs', type=int, default=200)  #100\n",
        "# parser.add_argument('--bt_size', type=int, default=8)  #36\n",
        "parser.add_argument('--seg_loss', type=int, default=0, choices=[0, 1])\n",
        "# parser.add_argument('--aug', type=int, default=1)\n",
        "# parser.add_argument('--patience', type=int, default=10)  #50\n",
        "\n",
        "# pre-train\n",
        "parser.add_argument('--pre', type=int, default=0)\n",
        "\n",
        "# transformer\n",
        "parser.add_argument('--trans', type=int, default=1)\n",
        "\n",
        "# point constrain\n",
        "parser.add_argument('--point_pred', type=int, default=1)\n",
        "parser.add_argument('--ppl', type=int, default=6)\n",
        "\n",
        "# cross-scale framework\n",
        "parser.add_argument('--cross', type=int, default=0)\n",
        "\n",
        "parse_config , unknown = parser.parse_known_args()\n",
        "print(parse_config )\n",
        "\n",
        "# if parse_config.arch == 'BAT':\n",
        "#     parse_config.exp_name += '_{}_{}_{}_e{}'.format(parse_config.trans,\n",
        "#                                                     parse_config.point_pred,\n",
        "#                                                     parse_config.cross,\n",
        "#                                                     parse_config.ppl)\n",
        "# exp_name = parse_config.dataset + '/' + parse_config.exp_name + '_loss_' + str(\n",
        "#     parse_config.seg_loss) + '_aug_' + str(parse_config.aug) + '/fold_' + str(\n",
        "#         parse_config.fold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "hz72Jtwr9UOu"
      },
      "outputs": [],
      "source": [
        "def ce_loss(pred, gt):\n",
        "    pred = torch.clamp(pred, 1e-6, 1 - 1e-6)\n",
        "    return (-gt * torch.log(pred) - (1 - gt) * torch.log(1 - pred)).mean()\n",
        "\n",
        "\n",
        "def structure_loss(pred, mask):\n",
        "    \"\"\"            TransFuse train loss        \"\"\"\n",
        "    \"\"\"            Without sigmoid             \"\"\"\n",
        "    weit = 1 + 5 * torch.abs(\n",
        "        F.avg_pool2d(mask, kernel_size=31, stride=1, padding=15) - mask)\n",
        "    wbce = F.binary_cross_entropy_with_logits(pred, mask, reduction='none')\n",
        "    wbce = (weit * wbce).sum(dim=(2, 3)) / weit.sum(dim=(2, 3))\n",
        "\n",
        "    pred = torch.sigmoid(pred)\n",
        "    inter = ((pred * mask) * weit).sum(dim=(2, 3))\n",
        "    union = ((pred + mask) * weit).sum(dim=(2, 3))\n",
        "    wiou = 1 - (inter + 1) / (union - inter + 1)\n",
        "    return (wbce + wiou).mean()\n",
        "\n",
        "\n",
        "def focal_loss(\n",
        "    inputs: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    alpha: float = 0.6,  #0.8\n",
        "    gamma: float = 2,\n",
        "    reduction: str = \"mean\",\n",
        ") -> torch.Tensor:\n",
        "    p = inputs\n",
        "    ce_loss = F.binary_cross_entropy(inputs, targets, reduction=\"mean\")\n",
        "    p_t = p * targets + (1 - p) * (1 - targets)\n",
        "    loss = ce_loss * ((1 - p_t)**gamma)\n",
        "\n",
        "    if alpha >= 0:\n",
        "        alpha_t = alpha * targets + (1 - alpha) * (1 - targets)\n",
        "        loss = alpha_t * loss\n",
        "\n",
        "    if reduction == \"mean\":\n",
        "        loss = loss.mean()\n",
        "    elif reduction == \"sum\":\n",
        "        loss = loss.sum()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "CRITERION = [focal_loss, ce_loss][parse_config.seg_loss]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4SW4ViKfK2St"
      },
      "source": [
        "The [ComboLoss](https://github.com/sneddy/pneumothorax-segmentation/blob/master/unet_pipeline/Losses.py#L104) function used in CRITERION below also comes from the winning solution by Anuar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "g3__XL68K2St"
      },
      "outputs": [],
      "source": [
        "# CRITERION        = ComboLoss(**{'weights':{'bce':3, 'dice':1, 'focal':4}})\n",
        "\n",
        "# # Use During Inference Stage to store images of predicted segmentation masks\n",
        "# # PREDICTION_PATH  = \"/content/drive/MyDrive/Colab_Notebooks/datasets/archive_png_siim_acr/Predicted_masks/tests\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "od_pZDUoK2Su"
      },
      "source": [
        "\n",
        "## Utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8JuSwxSqK2Su"
      },
      "source": [
        "General utility functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "3LcOlxiwK2Sv"
      },
      "outputs": [],
      "source": [
        "def matplotlib_imshow(img, one_channel=False):\n",
        "    fig,ax = plt.subplots(figsize=(10,6))\n",
        "    ax.imshow(img.permute(1,2,0).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "LkS16buBK2Sv"
      },
      "outputs": [],
      "source": [
        "def visualize(**images):\n",
        "    \"\"\"PLot images in one row.\"\"\"\n",
        "    images = {k:v.numpy() for k,v in images.items() if isinstance(v, torch.Tensor)} #convert tensor to numpy\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 8))\n",
        "    image, mask = images['image'], images['mask']\n",
        "    plt.imshow(image.transpose(1,2,0), vmin=0, vmax=1)\n",
        "    if mask.max()>0:\n",
        "        plt.imshow(mask.squeeze(0), alpha=0.25)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "5KOb07Zlb3GN"
      },
      "outputs": [],
      "source": [
        "def save_checkpoint(state, filename=\"my_checkpoint.pth.tar\"):\n",
        "  print(\"Saving checkpoint...\")\n",
        "  torch.save(state, filename)\n",
        "  print(\"Checkpoint saved!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "cIcBkgjOcPWQ",
        "outputId": "673e4396-2b84-409d-8396-8f7d6741e083"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef load_checkpoint(checkpoint):\\n  print(\"Loading checkpoint...\")\\n  model.load_state_dict(checkpoint[\\'state_dict\\'])\\n  optimizer.load_state_dict(checkpoint[\\'optimizer\\'])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 175
        }
      ],
      "source": [
        "\"\"\"\n",
        "def load_checkpoint(checkpoint):\n",
        "  print(\"Loading checkpoint...\")\n",
        "  model.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "NrindR018hyO"
      },
      "outputs": [],
      "source": [
        "def accuracy_fn(y_true, y_pred):\n",
        "  correct = torch.eq(y_true, y_pred).sum().item() # Calculates where two tensors are equal\n",
        "  acc = (correct / len(y_pred) ) * 100\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqxMQpqB5JFV"
      },
      "source": [
        "# ---------------------- DL Workflow -----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNLEHf3QK2Sv"
      },
      "source": [
        "## 1. Data -> Tensor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wbgxfpGK2Sv"
      },
      "source": [
        "### Create five-fold splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDyy5r93K2Sv",
        "outputId": "6622b672-5606-4b69-b346-83b9ad9d4f50"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8570, 2142)"
            ]
          },
          "metadata": {},
          "execution_count": 177
        }
      ],
      "source": [
        "# single fold training for now, rerun notebook to train for multi-fold\n",
        "DF       = pd.read_csv(DATA_FRAME_PATH)\n",
        "TRAIN_DF = DF.query(f'kfold!={FOLD_ID}').reset_index(drop=True)\n",
        "VAL_DF   = DF.query(f'kfold=={FOLD_ID}').reset_index(drop=True)\n",
        "len(TRAIN_DF), len(VAL_DF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njKNWpqFK2Sw"
      },
      "source": [
        "### Dataset and DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "9ywRGbXTK2Sw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import torch\n",
        "\n",
        "# =============================================================================\n",
        "# Helper Functions for Key-Patch Map Generation\n",
        "# =============================================================================\n",
        "\n",
        "def resize_and_clip(img, target_size=(512, 512)):\n",
        "    \"\"\"\n",
        "    Resize image or mask to target_size using nearest neighbor interpolation\n",
        "    and clip its pixel values to [0, 255].\n",
        "    \"\"\"\n",
        "    resized = cv2.resize(img, target_size, interpolation=cv2.INTER_NEAREST)\n",
        "    resized = np.clip(resized, 0, 255)\n",
        "    return resized\n",
        "\n",
        "def draw_msra_gaussian(heatmap, center, sigma):\n",
        "    \"\"\"\n",
        "    Draw a Gaussian blob onto the heatmap centered at `center` with standard deviation `sigma`.\n",
        "    \"\"\"\n",
        "    tmp_size = sigma * 3\n",
        "    mu_x = int(center[0] + 0.5)\n",
        "    mu_y = int(center[1] + 0.5)\n",
        "    h, w = heatmap.shape[0], heatmap.shape[1]\n",
        "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
        "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
        "    if ul[0] >= w or ul[1] >= h or br[0] < 0 or br[1] < 0:\n",
        "        return heatmap\n",
        "    size = 2 * tmp_size + 1\n",
        "    x = np.arange(0, size, 1, np.float32)\n",
        "    y = x[:, np.newaxis]\n",
        "    x0 = y0 = size // 2\n",
        "    g = np.exp(-((x - x0)**2 + (y - y0)**2) / (2 * sigma**2))\n",
        "    g_x = max(0, -ul[0]), min(br[0], w) - ul[0]\n",
        "    g_y = max(0, -ul[1]), min(br[1], h) - ul[1]\n",
        "    img_x = max(0, ul[0]), min(br[0], w)\n",
        "    img_y = max(0, ul[1]), min(br[1], h)\n",
        "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
        "        heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]],\n",
        "        g[g_y[0]:g_y[1], g_x[0]:g_x[1]]\n",
        "    )\n",
        "    return heatmap\n",
        "\n",
        "def compute_key_patch_map_classic(mask_orig, max_corners=100, quality_level=0.01, min_distance=10, sigma=8):\n",
        "    \"\"\"\n",
        "    Compute the key-patch (ground truth point) map using a classical feature detector approach.\n",
        "\n",
        "    Steps:\n",
        "      1. Resize the input mask to 512x512.\n",
        "      2. Threshold the resized mask to obtain a binary mask.\n",
        "      3. Optionally compute an edge map using the Canny edge detector.\n",
        "      4. Use the Shi-Tomasi (Good Features to Track) detector to extract keypoints.\n",
        "      5. Draw a Gaussian blob on a heatmap at each detected keypoint.\n",
        "\n",
        "    Returns a 512x512 heatmap representing the key patch map.\n",
        "    \"\"\"\n",
        "    # Resize the original mask to 512x512\n",
        "    mask_resized = resize_and_clip(mask_orig, (512, 512))\n",
        "\n",
        "    # Threshold mask to binary (pixels > 127 become foreground)\n",
        "    _, mask_bin = cv2.threshold(mask_resized, 127, 255, cv2.THRESH_BINARY)\n",
        "    # Ensure the binary mask is in 8-bit unsigned int format for Canny.\n",
        "    mask_bin = np.uint8(mask_bin)\n",
        "\n",
        "    # Optionally, extract edges to focus the detector on the boundary using Canny.\n",
        "    edges = cv2.Canny(mask_bin, 50, 150)\n",
        "\n",
        "    # Detect keypoints using Shi-Tomasi method on the edge map.\n",
        "    corners = cv2.goodFeaturesToTrack(np.float32(edges),\n",
        "                                      maxCorners=max_corners,\n",
        "                                      qualityLevel=quality_level,\n",
        "                                      minDistance=min_distance)\n",
        "\n",
        "    # Initialize the heatmap of size 512x512\n",
        "    point_heatmap = np.zeros((512, 512), dtype=np.float32)\n",
        "\n",
        "    # If keypoints are detected, draw a Gaussian at each keypoint.\n",
        "    if corners is not None:\n",
        "        for corner in corners:\n",
        "            x, y = corner.ravel()\n",
        "            point_heatmap = draw_msra_gaussian(point_heatmap, (x, y), sigma)\n",
        "\n",
        "    return point_heatmap\n",
        "\n",
        "# =============================================================================\n",
        "# Modified Dataset Class (Using Classical Feature Detectors)\n",
        "# =============================================================================\n",
        "\n",
        "class Dataset():\n",
        "    def __init__(self, rle_df, image_base_dir, masks_base_dir, augmentation=None, mask_augmentation=None):\n",
        "        self.df                 = rle_df\n",
        "        self.image_base_dir     = image_base_dir\n",
        "        self.masks_base_dir     = masks_base_dir\n",
        "        self.image_ids          = rle_df.ImageId.values\n",
        "        self.augmentation       = augmentation\n",
        "        self.mask_augmentation  = mask_augmentation\n",
        "\n",
        "    def __image_ids__(self):\n",
        "        print(self.image_ids)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        image_id = self.image_ids[i]\n",
        "        img_path = os.path.join(self.image_base_dir, Path(image_id + '.png'))\n",
        "        mask_path = os.path.join(self.masks_base_dir, Path(image_id + '.png'))\n",
        "\n",
        "        # Load image and mask using OpenCV\n",
        "        image = cv2.imread(img_path, 1)\n",
        "        mask = cv2.imread(mask_path, 0)\n",
        "\n",
        "        # Generate the ground truth key-patch map using the classical feature detection approach\n",
        "        # We'll do this before augmentation since we need to recompute it after augmentation\n",
        "        original_mask = (mask > 0).astype(np.float32) * 255\n",
        "\n",
        "        # Apply augmentations to both image and mask together to keep them aligned\n",
        "        if self.augmentation:\n",
        "            augmented = self.augmentation(image=image, mask=mask)\n",
        "            image = augmented['image']\n",
        "            mask = augmented['mask']\n",
        "\n",
        "        # Normalize image (scale to [0, 1]) and convert mask to binary after augmentation\n",
        "        image = (image / 255.0).astype(np.float32)\n",
        "        mask = (mask > 0).astype(np.float32)\n",
        "\n",
        "        # Compute the key-patch map from the augmented mask\n",
        "        point = compute_key_patch_map_classic(mask * 255)\n",
        "\n",
        "        # Additional processing specific to input and target\n",
        "        # Apply normalization to image only (not the mask or point)\n",
        "        image_normalized = albu.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                        std=[0.229, 0.224, 0.225],\n",
        "                                        max_pixel_value=1.0)(image=image)['image']\n",
        "\n",
        "        # Convert all to PyTorch tensors\n",
        "        image_tensor = ToTensorV2()(image=image_normalized)['image']\n",
        "        mask_tensor = torch.Tensor(mask).unsqueeze(0)  # Add channel dimension\n",
        "        point_tensor = torch.Tensor(point).unsqueeze(0)\n",
        "\n",
        "        return {\n",
        "            'image': image_tensor,\n",
        "            'mask': mask_tensor,\n",
        "            'point': point_tensor\n",
        "        }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zxv5It8ZK2Sw",
        "outputId": "39c2629d-ff1c-4fb6-c82f-79c096e56bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/albumentations/core/validation.py:87: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
            "  original_init(self, **validated_kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Define combined transforms for both image and mask\n",
        "train_transforms = albu.Compose([\n",
        "    albu.OneOf([\n",
        "        albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "        albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "    ], p=0.3),\n",
        "    albu.OneOf([\n",
        "        albu.ElasticTransform(alpha=120, sigma=6.0, p=0.5),\n",
        "        albu.GridDistortion(num_steps=5, distort_limit=(-0.3, 0.3), p=0.5),\n",
        "        albu.OpticalDistortion(distort_limit=(-2, 2), p=0.5),\n",
        "    ], p=0.3),\n",
        "    albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=45, p=0.5),\n",
        "    albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "], p=1.0)\n",
        "\n",
        "# Test transforms - applies only basic processing\n",
        "test_transforms = albu.Compose([\n",
        "    albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "], p=1.0)\n",
        "\n",
        "# Test transforms\n",
        "TEST_TFMS = albu.Compose([\n",
        "    albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1),\n",
        "    albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], max_pixel_value=255.0, p=1.0),\n",
        "    ToTensorV2(),\n",
        "],\n",
        "    is_check_shapes=True,\n",
        "    p=1.0,\n",
        ")\n",
        "\n",
        "# New Train Transforms - Aggressive Augmentations to avoid overfitting.\n",
        "TFMS =  albu.Compose(\n",
        "    [\n",
        "        albu.OneOf([\n",
        "            albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "        ], p=0.3),\n",
        "        albu.OneOf([\n",
        "            albu.ElasticTransform(alpha=120, sigma=6.0, p=0.5),\n",
        "            albu.GridDistortion(num_steps=5, distort_limit=(-0.3, 0.3), p=0.5),\n",
        "            albu.OpticalDistortion(distort_limit=(-2, 2), p=0.5),\n",
        "        ], p=0.3),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=45, p=0.5),\n",
        "        albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "        albu.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1.0),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    p=1.0\n",
        ")\n",
        "\n",
        "MASK_TFMS =  albu.Compose(\n",
        "    [\n",
        "        albu.OneOf([\n",
        "            albu.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "            albu.RandomGamma(gamma_limit=(80, 120), p=0.5),\n",
        "        ], p=0.3),\n",
        "        albu.OneOf([\n",
        "            albu.ElasticTransform(alpha=120, sigma=6.0, p=0.5),\n",
        "            albu.GridDistortion(num_steps=5, distort_limit=(-0.3, 0.3), p=0.5),\n",
        "            albu.OpticalDistortion(distort_limit=(-2, 2), p=0.5),\n",
        "        ], p=0.3),\n",
        "        albu.ShiftScaleRotate(scale_limit=0.1, rotate_limit=45, p=0.5),\n",
        "        albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "        ToTensorV2(),\n",
        "    ],\n",
        "    p=1.0\n",
        ")\n",
        "\n",
        "mask_transform = albu.Compose([\n",
        "    albu.Resize(height=IMG_SIZE, width=IMG_SIZE, p=1.0),\n",
        "    ToTensorV2()\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "id": "4DKpUR1QK2Sw"
      },
      "outputs": [],
      "source": [
        "# # train dataset\n",
        "# train_dataset = Dataset(TRAIN_DF, TRAIN_IMG_DIR, TRAIN_LBL_DIR, TFMS, MASK_TFMS)\n",
        "# val_dataset   = Dataset(VAL_DF, TRAIN_IMG_DIR, TRAIN_LBL_DIR, TEST_TFMS, mask_transform)\n",
        "\n",
        "\n",
        "# Modified Dataset class instantiation\n",
        "train_dataset = Dataset(TRAIN_DF, TRAIN_IMG_DIR, TRAIN_LBL_DIR, augmentation=train_transforms)\n",
        "val_dataset = Dataset(VAL_DF, TRAIN_IMG_DIR, TRAIN_LBL_DIR, augmentation=test_transforms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7zno_0Q4eVHv",
        "outputId": "a6cbaf39-1ab0-4631-c145-83d6d1d52bef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8570"
            ]
          },
          "metadata": {},
          "execution_count": 181
        }
      ],
      "source": [
        "train_dataset.__len__()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 182,
      "metadata": {
        "id": "8SW1GpbQK2Sw"
      },
      "outputs": [],
      "source": [
        "# # plot one with mask\n",
        "# visualize(**train_dataset[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6-dcysMmK2Sw"
      },
      "source": [
        "### Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "Qx49nrt4K2Sw"
      },
      "outputs": [],
      "source": [
        "class PneumoSampler(Sampler):\n",
        "    def __init__(self, train_df, positive_perc=0.8):\n",
        "        assert positive_perc > 0, 'percentage of positive pneumothorax images must be greater then zero'\n",
        "        self.train_df = train_df\n",
        "        self.positive_perc = positive_perc\n",
        "        self.positive_idxs = self.train_df.query('has_mask==1').index.values\n",
        "        self.negative_idxs = self.train_df.query('has_mask!=1').index.values\n",
        "        self.n_positive = len(self.positive_idxs)\n",
        "        self.n_negative = int(self.n_positive * (1 - self.positive_perc) / self.positive_perc)\n",
        "\n",
        "    def __iter__(self):\n",
        "        negative_sample = np.random.choice(self.negative_idxs, size=self.n_negative)\n",
        "        shuffled = np.random.permutation(np.hstack((negative_sample, self.positive_idxs)))\n",
        "        return iter(shuffled.tolist())\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_positive + self.n_negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {
        "id": "kzJerUgtK2Sx"
      },
      "outputs": [],
      "source": [
        "SAMPLER = PneumoSampler(TRAIN_DF, positive_perc=POSTIVE_PERC)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Asd-jMF9K2Sx"
      },
      "source": [
        "### DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saav3bv6K2Sx",
        "outputId": "9dd0b320-d396-4ae4-e344-e43179132ca3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, TRAIN_BATCH_SIZE,\n",
        "                              shuffle=True if not USE_SAMPLER else False,\n",
        "                              num_workers=NUM_WORKERS,\n",
        "                              sampler=SAMPLER if USE_SAMPLER else None)\n",
        "val_dataloader   = DataLoader(val_dataset, VALID_BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u9nGVmHlj6z5",
        "outputId": "d53f654f-0612-4004-c8f6-f6fab39a2f6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x7aaa617bac90>, <torch.utils.data.dataloader.DataLoader object at 0x7aaa61627450>)\n",
            "Length of train dataloader: 238 batches of 10\n",
            "length of validation dataloader: 215 batches of 10\n"
          ]
        }
      ],
      "source": [
        "print(f\"Dataloaders: {train_dataloader , val_dataloader}\")\n",
        "print(f\"Length of train dataloader: {len(train_dataloader)} batches of {BATCH_SIZE}\")\n",
        "print(f\"length of validation dataloader: {len(val_dataloader)} batches of {BATCH_SIZE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jmBiDQJwFTN"
      },
      "source": [
        "for batch_index, data in enumerate(train_dataloader):\n",
        "    for z in range(3):\n",
        "        print(\"Image: \", data['image'].shape)\n",
        "        print(\"Mask: \", data['mask'].shape)\n",
        "        print(\"data['mask'].unsqueeze(1)\", data['mask'].unsqueeze(1).shape)\n",
        "    break\n",
        "\n",
        "Output\n",
        "Image:  torch.Size([8, 3, 512, 512])\n",
        "Mask:  torch.Size([8, 1, 512, 512])\n",
        "data['mask'].unsqueeze(1) torch.Size([8, 1, 1, 512, 512])\n",
        "Image:  torch.Size([8, 3, 512, 512])\n",
        "Mask:  torch.Size([8, 1, 512, 512])\n",
        "data['mask'].unsqueeze(1) torch.Size([8, 1, 1, 512, 512])\n",
        "Image:  torch.Size([8, 3, 512, 512])\n",
        "Mask:  torch.Size([8, 1, 512, 512])\n",
        "data['mask'].unsqueeze(1) torch.Size([8, 1, 1, 512, 512])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in train_dataloader:\n",
        "  image = data['image']\n",
        "  mask = data['mask']\n",
        "  point = data['point']\n",
        "  break"
      ],
      "metadata": {
        "id": "D4Wrs4Z4D6dj"
      },
      "execution_count": 187,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(10, 2, figsize=(10, 40))  # axs is a 2D array with shape (4, 2)\n",
        "\n",
        "# Row 0\n",
        "axs[0, 0].imshow(point[0][0])\n",
        "axs[0, 1].imshow(mask[0][0])\n",
        "\n",
        "# Row 1\n",
        "axs[1, 0].imshow(point[1][0])\n",
        "axs[1, 1].imshow(mask[1][0])\n",
        "\n",
        "# Row 2\n",
        "axs[2, 0].imshow(point[2][0])\n",
        "axs[2, 1].imshow(mask[2][0])\n",
        "\n",
        "# Row 3\n",
        "axs[3, 0].imshow(point[3][0])\n",
        "axs[3, 1].imshow(mask[3][0])\n",
        "\n",
        "# Row 4\n",
        "axs[4, 0].imshow(point[4][0])\n",
        "axs[4, 1].imshow(mask[4][0])\n",
        "\n",
        "# Row 5\n",
        "axs[5, 0].imshow(point[5][0])\n",
        "axs[5, 1].imshow(mask[5][0])\n",
        "\n",
        "# Row 6\n",
        "axs[6, 0].imshow(point[6][0])\n",
        "axs[6, 1].imshow(mask[6][0])\n",
        "\n",
        "# Row 7\n",
        "axs[7, 0].imshow(point[7][0])\n",
        "axs[7, 1].imshow(mask[7][0])\n",
        "\n",
        "# Row 8\n",
        "axs[8, 0].imshow(point[8][0])\n",
        "axs[8, 1].imshow(mask[8][0])\n",
        "\n",
        "# Row 9\n",
        "axs[9, 0].imshow(point[9][0])\n",
        "axs[9, 1].imshow(mask[9][0])\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IHpinHeKHNIe",
        "outputId": "d54165da-8204-48aa-d355-ff4063e253ed"
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x4000 with 20 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3QAAA+VCAYAAADmKMjoAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs/XuUXNV95/1/9rlUVd+qWq1LNwoSxgYDsgGPhS312Mk4RkHGsgcP8lq2hwcrCcseM4IxyCG2MgRiOyvih9cvJCRcMpkMeK2YkJAnmDEx2IoIIg7iJptYBiODTZCw6G4hqbv6VlXnsp8/TnWpWxI2LbVUvdXv11qFuuuc6tp1YOnLp/c++2ustVYAAAAAAOd4zR4AAAAAAODoEOgAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAARxHoAAAAAMBRBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcR6AAAAADAUU0LdLfddpve8pa3qFAoaMWKFXrqqaeaNRQAAJxGTQWAuaspge5v//ZvtWHDBt144436/ve/r/PPP1+rV6/WwMBAM4YDAICzqKkAMLcZa6090W+6YsUKvec979Gf//mfS5LSNNWSJUt09dVX60tf+tIvfX2aptqzZ486OjpkjDnewwUAHIG1VsPDw1q8eLE8jxX8zUJNBQC3HWs9DY7DmH6hWq2m7du3a+PGjY3nPM/TqlWrtG3btiO+plqtqlqtNr7/+c9/rmXLlh33sQIAfrndu3fr1FNPbfYw5iRqKgCcPI62np7wQPf6668rSRJ1d3dPeb67u1svvPDCEV+zadMmffnLXz7s+ffrwwoUHpdxAgB+sViRvqdvq6Ojo9lDmbOoqQDgvmOtpyc80B2NjRs3asOGDY3vy+WylixZokChAkPxAYCmqC/YZ5meW6ipADDLHGM9PeGBbsGCBfJ9X/39/VOe7+/vV09PzxFfk8/nlc/nT8TwAABwBjUVAHDC72LP5XJavny5tmzZ0nguTVNt2bJFvb29J3o4AAA4i5oKAGjKkssNGzZo3bp1uuCCC/Te975Xf/Inf6LR0VH91m/9VjOGAwCAs6ipADC3NSXQfeITn9DevXt1ww03qK+vT+9617v08MMPH3ZTNwAA+MWoqQAwtzWlD92xKpfLKpVK+oAu4QZuAGiS2EZ6VA9oaGhIxWKx2cPBUaKmAkBzHWs9pRMsAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOmnage+yxx/TRj35UixcvljFG3/zmN6cct9bqhhtu0CmnnKKWlhatWrVKL7744pRz9u/fr8suu0zFYlGdnZ264oorNDIyckwfBAAAl1BPAQAzYdqBbnR0VOeff75uu+22Ix6/+eabdeutt+rOO+/Uk08+qba2Nq1evVqVSqVxzmWXXabnnntOmzdv1oMPPqjHHntMn/3sZ4/+UwAA4BjqKQBgJhhrrT3qFxuj+++/Xx/72MckZb9NXLx4sb7whS/od37ndyRJQ0ND6u7u1t13361PfvKT+vGPf6xly5bp6aef1gUXXCBJevjhh/XhD39Yr776qhYvXvxL37dcLqtUKukDukSBCY92+ACAYxDbSI/qAQ0NDalYLDZ7OE5rVj2VqKkA0GzHWk9n9B66l19+WX19fVq1alXjuVKppBUrVmjbtm2SpG3btqmzs7NRfCRp1apV8jxPTz755BF/brVaVblcnvIAAOBkdbzqqURNBYCTzYwGur6+PklSd3f3lOe7u7sbx/r6+rRo0aIpx4MgUFdXV+OcQ23atEmlUqnxWLJkyUwOGwCAWeV41VOJmgoAJxsndrncuHGjhoaGGo/du3c3e0gAADiJmgoAJ5cZDXQ9PT2SpP7+/inP9/f3N4719PRoYGBgyvE4jrV///7GOYfK5/MqFotTHgAAnKyOVz2VqKkAcLKZ0UB3+umnq6enR1u2bGk8Vy6X9eSTT6q3t1eS1Nvbq8HBQW3fvr1xziOPPKI0TbVixYqZHA4AAE6ingIA3qxgui8YGRnRSy+91Pj+5Zdf1rPPPquuri4tXbpU11xzjf7wD/9QZ555pk4//XT9/u//vhYvXtzYueucc87Rhz70IX3mM5/RnXfeqSiKdNVVV+mTn/zkm96RCwAA11FPAQAzYdqB7plnntGv//qvN77fsGGDJGndunW6++679bu/+7saHR3VZz/7WQ0ODur973+/Hn74YRUKhcZrvvGNb+iqq67ShRdeKM/ztHbtWt16660z8HEAAHAD9RQAMBOOqQ9ds9AzBwCajz50JwdqKgA016zqQwcAAAAAOHEIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOCooNkDwAwyh33xJtgpfwAAAABwB4HuZGAmBTjj1f8wagQ7M/EPOym4WVk78b3VwWBHsgMAAABcQaBznakHNyMZY7JAZyR5nmSMTP1YQz3AWWtlUpsFOGtlZTX11EnfTAp51h4S/AiAAAAAQNMQ6FxmTBbaTBbe5GWBznie5NcDXf2cLPjVw1tqZayV0lRK0/r36ZSfWf9GU9ZiTryuMbs36RjBDgAAADjhCHSuqs/GGWOy2TjPyPi+5Psyvid5fj3UednyS2OyMGetTD3IKZn4M8keEz9rItBN/GkPzuQptbJpmgU7mzZ+ZuM8AAAAACcMgW42m3Jv3KEbndRn33zvYJALfCkIpCDIvvZ8yTOyjZBWX2Y5EeaSRDaOZeJDAp1nps7UTSzNnAiC9RBoEyPZVCa1sqrP8BHqAAAAgBOGQDcbTV7yaCbdHzf5vrb6Ocb3pTCQCcMsyOVC2TCUDQPZwJcCT9Y7GM5MaqU4kYlTKYplokiqRbJJInn1cDg51ElZoJtYnpkkMkkixYkUxwefSyWbWkkpoQ4AAAA4QQh0s82UTU68gzNl3qT74RrnqT4zF8rkclIuJ1sIZXOhbD5QmvOVhp6sf3DJpUklL0plokReNZaqvozvZ7N0gZ+FQN+TPE/20Fm9OJWJYymOZaNYxvOyGT5ld9oZm8pOJE5CHQAAAHDcEehmk8M2Oanf/+Z59a8nBbyJQOcZmXxetpCXCjklrTmlLYGSlkBxwVOaM0oDI2skYyWTWPk1K7+ayh8P5I8H8sYDmSiRzQWyOV9p4Mn6XtZ23mazeiZJZaJUphbLVCOZWiT5kVSr/2zVQ10ill8CAAAAJwiBbraYHOYO2+Tk4KyZvEkboVibvS6fk23JKW3LK24PFbf6itp9xQWjJC+lobJll1byYiu/KgUVT+GopyD0FPieTJwqLfhK8r7SnKc0OLi80yRWXmzlVVP51UDeuC+v4st43pR9U8zEnymhDgAAADgRCHSzweQdK6dsclLf4CQMJN/PlkR6U++Jk7VSLlTanlfcnlO1FCjq8FTrkKI2o6RgleYk62XLLU0sBeNGwbhRXDDK5YxsYGRSKW7xFLV6SnKmHgKzkGZiyY+s/IpVMOYrzPvyx3x59XBpJja5lD24gYo9pOUBAAAAgBlHoGu2xsycObgpSVDf5KS+2YnNZV/bsB7q/EmBLrWSZxS3hqp1+KqWPNVKRrWSVdyRKm1NpXwi41vZ1MjWPMVjvoKR+lJMz2vMxNXaPMVtUlwwWQj0VZ/Vk/yqUTBuFRSM0tAo5xsFVvJ1cMMUk6SSn2atEayVbazFJNgBAAAAxwOBrpkmL7P0p4Y5k89lSynzoWwhpzQXKM3XNzkJjKwxWQ5LrbzEKm7zs5m5klF1nlXUlcgrRWpvr6i9UFPgJ0pST2O1UKMjBUUtOdkgkGRkrKc0lGodRlGHVdKSKi1YybfZPXSRkVfxFIwYhYVsRs96pjEb5yepTJLI1tsZmDSVTeuNzlPCHAAAAHC8EOiabWIHS8+bGuYKedmWvNLWnJLWUEnBV9wysRzSyNY3LPGS7L641JNq7Ua1olXUmSqYX9WCecP6lfYhLSoMq+BFqqWBDkSt2l3o1EDYoaptlYl9mcQobpGiklXSGctvi9TaEikIEllrVK0FisZCVVtCpbn6xizWkxcH2b11tSRrgRAnkh9nLRCyG+kAAAAAHEcEumaZvNTSmEZjcJML65uc5JW055W0hap1BIpbPUWt2SYnSc5Mvb+tZuXFUtxiFLelMsVIXaVRva30ut7e1q8l+f1q82qqpIH645Ja/EjGSHuiQHGlIL9qFBWtknmRWrvGNb9jVPNbRtTqR0qsp3JU0OujbdoftivycjKJn71v1ZNf9eVVAvnVQAomb95iZGw2k8iSSwAAAOD4INA108RmKPUwpyDIesm15JW05RV35FQr+qqWfEXtUtRuFLdYpXkrW18O6cVGXkUKxrL73tLWVIW2mnrayzqjba/e2fpznR7uV7tJVLGe9sRlWWs0noQaHGtRuTVUVDFKSrFausZ12vz9emv761pS2K8Ov6LYeno97tC/F+brJT/VgIqKagV5NU/hmBSPewrGfHmB32hKPtFeodGTDgCAk1RXd6T3frAsSXrpRy16aUdrk0cEYK4h0DWLMTKaaBruZTN0YZj1gsuHSloDRe1+Fug660spi6lsWyJTSGSCLNDFkSeN+0qGs1kzhVb5XKxSblwLw7JO8cta7CdqN4EqNpHViF4Lh9QZzldrLlI5TJW0WHltsea3j+r09n06p+01vS3Xr5JXUSxf/XGH8ibWeJzTWDWnoZFQychESwSjNPAaO3BqSq+8Zl9kAABmXnsp1rX//93yfak0P9ayC0YlSa/+NK/dLxWmnPsP/2uhfritvRnDBDBHEOiayShrHO57kp+1KLD5MGsK3hao1uGpOrHJybxU/ryq2joqKrZUVAhipdZotJbT8FhBYy0FmaFQ8qw8zyo0ifImVt4kKhhPeZP9q86eixV6sXwvlfGkNJcq31JTV8uYlhT26225Ab09HFKn5ylSTR1eTVUbqq+lqP6WdpXzrUrzgZKwfj9fYGR9I1O/F9AakhwA4ORzXu+IWtsT/ddr+3XW+WOH/eLy1LdVderbqlOe2/PvOcWR0fPPtJ3AkQKYSwh0zdCYwTKNJYrG92QDXzbMdrOMC9k9c1G7FJdSefNqWjB/WIvbh7S4ZUhtQVWJ9TQYtWpPS0mv+p0aVqsUeYoTT5U01Gia14gNNZKOSV5N4zbRSP35SpJTlPiyiZE8KfBTFfxIbV5VHV5FJc+ow8spVqpRW1OHN65Wv6a8n80OWi9rl2A9ZQFu4nHo5wMAwElWxki//l8GdV7viCTp/WuG1NEZT+unrP1ve/XrHxvUk/9U1F039WhoX3g8BgtgDiPQNZPxGvfRyasvWww9JTk/2+Ck1Shus7LFWPM6R/W2ztd1Vlu/Ti/sVac3pkSe+uOifhoukiS9knoa3d+qSiXU65U2vVroUqc/Jqt9ajM1VWxOr8Ul7arO10ClXSOVvFT1ZCSl1iixnmLrK7K+arKKlCi2qWrWKLK+4tRXYo2UKtvBsv4wskfe0ZK9UAAAjvF8q7efP6YgtPrdW3epc0GsfEt6TD+zqzvSu39tWHFs9OcbT52hkQJAhkDXbEZZv7b6zpA28GTrSxmTnJQUrMKWSF2tozqtZb/eXujTmbm9mudFimXU5Y/KSDoQtepApUVjQwVFozkNDHfop8ECSVYHkja1elVV01ADUYdeGl2k10aLqlaDLHQlRrVaoHKtoNfjdvUlRXXENY15sSJJfXGr+uOSDkStGq3llEa+gtjIJFZeIplE2U6W9b50jQeJDgDgkHe8d0S/umZIl1zxujxvZmpYmhrd8yfdevKfivrJs2yYAmDmEehOtMnNxI0OztJNDnWekfUlG0g2tMrlYnWEVc0PR9QdDOmUINI8L6fEpjIa14FgSPPCMbWFNXlhqmQwp6EDbfqZNRqN8trT0qm2oJbNpEkKvUQLWkaVJJ4OWKNoKKdoLNTro216ubBAoUlUSXMq+eOKbX0WcHyRXh3tVHmsRRr35VeM/KqVF1mZOJWJJxqKp5I9tt9kAgBwop31rjHd8L//XZ0Lprek8khGy74G9wV67uk2/e2fLdKel/NKU25DAHB8EOiaYSLUTWzxX39YY+oPyRrVA1+9TZ1JFZhEgUkVyiiQJ2OkwMQKTCrfpPKMlTFWXtVIcU5DRpKxKgSRFuWHs350flWR9bU36tBPcwv1Uy/VQFpSUg41NNSmn/rzNZ4EGmjpUJtfU2w9DUYt+vlop/YMllQZLMgf9hSMSkHFyq+k8mqpTJxKSSqlqWxqZdM3WIYJAMAs8473juj3//KVGQlz//T38/T4QyX960Ol+jMEOQDHF4HuRDukmbiCye0KAqWhpzSo/+WfSkqkOPY0nuQ0nBQ0lLZoMK3IqKpY0mAaaChp0WiSVzUJlMaeTCpZTwqCRPNbx/TW9tf1jtaf6625verwaqpZX31BUb5SVZJQo9W8yiOh0sGcXrdFjVVzGmjtUN7PdtIcq++kWRkqyBsMlCsbhSNW4ahVUEnlVWMpiqUkboQ62YkHqQ4AMHt5vtX7Lh7SvIXRUf+M8VFPX/sfSzW4L9BPf9Siypg/gyMEgF+MQNcURsavz875vhRm7QrSQqC4zVfUbrIm4m1WCq3S1NNIlNOrlXnq8CuSpE5vvLEpysvVhdozXtLQeCGb3euMZa1Ra0uk+S2jWpLfr7fm9uqMcERFz1PVRmr1Io2kefUXStpTKGk41yqvnJMqeY2MhBoptMrzU1lrZOu97oJhT+GwUX7QKjdsFY4m8sciedVIphbLxomUJvVAZ5mgAwDMem97x7gu/czeo3ptmhptfaBTm/9unrZv7RCzcQCagUB3gplDWxb4fqNdQZL3FbfU2xV0WMXFVEFnVQs7h9XTOqw2v6bRtKCfVHuUM7Fi6+v1qF2vjM/XwHiHQj/VgvnDihNP49Ww0Yqg1a+q3aupw/PUbvLKmVgdaaw2r6qCHynnJzK+lbFSuN9TOmqU5HxZ38qzRiaW/IpRMCaFI1mYy5UTBSOx/PFYqkZSFElxLJuk9eWWltk5AMAsZxXmrIw3zVdZKap6+uZfLdDd/79TlMQEOQDNQ6BrBu9goFN9ls6GntK8p7gw0a4glSlG6uoc0Zmde3VWW59Oz+9V0asosp4G4qJeqnbpxZFFOlBt0aKWYZVK48qZRJU00OuVdu2vtipKfdXSQFUbqGpryitWVYmq1qhmA0WprySt37RnpWBM8geltN4sXFbyEiu/ahVUrIIxq3AkUTAaKxipyYxVZSo12SjKll3GcXYfnSXUAQBmN2Ok3/2zV6b1mv7dOf3kh6265QtLVBn1lCSEOQDNRaBrFjM51BlZP7t3Lg2N0pyUFqxyLZHmt45qacs+nZnv05m5fSp6iSJr1OmPq2YD7a12qD2o6m1tA+oOy8qZWGNpXq/m5+mlkUUaS3J6PepQX1hUm6lp2ItVs0avJW3qj4sajFo1VsvJ1jx5keRHVvnBrOWA9SRjs7YEXmQVVFP544n88WxmLgtzVdlaTYpi2SSpz85x7xwAwAFGyhXeXL2yVrrnT7r1zKNFPf9023EeGAC8eQS6E82Yg3965mCbAi+bEbO+lE5qV1AMq1oQjKg7GFaPn6rk5VWziazGtTcoa2F+WB1+Ree27NYpwbAKJtFIGjT60z03fIpeGl0oz1gNpwW1exVFNlB/VNSLY93aPdKp4dGCzJjXaEUQVFKFI0k2TiuZ1MqLrUwtkVdL5FUiqRZlM3O1mlSryUax7MTsHEsuAQAOuOL3XtO8X7azpZV+9uMWffdvu/R/71rA8koAsw6Bbrao1wdrpj5njJVnUvmy8mXkycg3Rr4kz6Rq86tanBvU0nBIi/1ELcbXsK0q1n7tzbVrV9ClXSPzVElC9bcU1Vrf5XIwatXPR0rqHywqGsorGPGy5ZYVK79iFQ5HMlEqKWsYbpJ6a4Iolqllyysnllk2wlySylr60AEA3NDWkcjz3/iXjz9/Oa/v/m2XHvg/CzQ+ws6VAGYnAt2JNlE3Jt1jZuqzYCbNljeaRFJiFEe+xuKcykmrDqQt2p9WlaiqmrXan+Y0mLQpsZ5aTE2tJlGbCZQ3gVJZtZlYLV6knBdrtJrTgZGFeq1QVOgnSq2nsVqokdGCoqG8/MmtCMZSBZVEphLLG69mbQislUnrfebiJAtvcVLfBCU5JMzZg58PAIBZ7K9v6daZ54/rlNOqamlLtXdP2DiWxEY3/ubp2v1SoYkjBIBfjkB3wk0KOtZmW/ynqUxiZWIrP7Lya0ZexahaCbVvvE27xrvU5lWUytQ3RfHVFxf1cmWBBuNWjedDjVlfYzZWKqsxm2jM5lRJQ9XSQHHiaXh/m0ZMq4xvpTRrRWDGPAUjnnLleiuCcrbU0h+Ls1YE4zUpirJG4bbeXy5JpTSRTdIs0KW2vglKOiWkAgAw2+3ry+mqD52p91w4rDPPHdc9f7Ko2UMCgGkj0DXDROhJUym1Un05oxel8mt+tuxxzCgaCbSv0Kaf5eYrldFQ0qo2r6rY+toXteuV8S5J0mu5Ti0MhpXY7B66UZvTq3Gn+qKSDlRbVKmGMmO+ghEvW9JpJW9yK4Jhq/xwqtxwtnulN15rtCKw1ZqUJFlfuUkB1E6M3aYHN0KZ+GwAADjD6OktRT29pdjsgQDAUSHQnWDWSmZyMEoSmTiWqcXyK4GCMV9hwVdSMErzgSpei16xXSpXC3q10KlCECtJPQ1HeR0Ya1FLLlLei5XK6LXGLpc5vVrLWhr0jRRVG8nJH/WU32fkRZrSisCvWIWjqcLRLMz5I9Vs98pq1orA1vvLyeqwWbjDWhMQ5gAAAIATikB3wtXDUH2GyySJFCX1QBcrGPcVjholuayNQU2BqkmrBsZDHWhpU+AnSq1RVAsUVwKNtkaSpPEkVGduXDkTq5KG2ltp157hooYGW2WGAwWj9XvkRmzWhiC18mr1/nL1VgTeeO1gmKu3IlBSX15p02y1qE2zRaMEOQAAAKDpCHQnmp142GwpY5zIRpFMNZAJfAWjfr2NgWSsJy8yiiq+khZftXyqqp+93ouM/JpRreirr+ZraLRFhVwk37OKE09jlZyqozlpKFS431NuSApHrAqDifxKmm3CEqXyokReNZGpRlI1OhjmajXZKJGNk4NLLHXI/XEEOQAAAKCpCHQnXLZU0VibzXzVl1yqFsn4nnzfy1oYGMmkkhd58qtSkjdKc77sRKCLJaVSVPOVVDyNtoYaDVPJyzY9UdWTN+opHMnCXG7YKjeSKhhNFIzUpDittyJI6q0I4uyeuUYrgkQ2iSdteMI9cgAAAMBsQ6A70ayVlEqpJJns/jRjZL1a1nPcGPlWUmrlRaGCiqdwzFOSM0rDbOZu4h44a4yCihSPetk9d6GfhcFU8mrZsWDUKjdilRtOlSvH8kdr8kYqWS+5pL5z5aRWBFkLgiPMzDXGDgAAAGC2INA1SWOWrh6ojIlkJRkZyVr5abbrpVcJFBR8paFRGhhZY2SU3QeXBkZBxVNckJK8lPqSvImZPSu/KgWVVOHowZk5b6wmU6lJlWo2Q5hmbQiUZBu0KEmmtiLQIRufAAAAAJg1CHTNUg9zWReBOFtiqWwuzNhsKaSNYplqIDseyAaerG+UTeNljcjT0FNQ8bMNVHJeFugmZugmetpVUvmVWN7EpieVmlS/T25iFq6x4+bE7psTQZNNTwAAAIBZjUDXDNbWg1nWsNsk9VA3+d66uN7OoBrIBr7kedLE/XX1fOWFvvzxQGnoy4ZethzTmGz3zNTKi1KZWraDpqlG2cYntXqYi+J6Y/CJfnL13TcPnZEjzAEAAACzFoGuWSYFJauJUKdGw3GT1u9j82MZ38sCnVefocvWZkpBIBP68nxfNsiOW5l6n7t6S4Q4ze6Xi2PZiT8nwlycZG0IJoc3ghwAAADgDAJdM00OdTaV0UR/uvrDS2Q8T3ZymJsc6HxfJggkz5PxTBb6sp+WzbqlaXZvXH2jkymbniTppB0saUUAAAAAuIhA12yNAGVlUyNTD2w2tVmI87yDQc4cvIdOkozvZbNthwU+25jpa4S6NJ26xHJymCPEAQAAAE4i0M0GE/fU2axHnYyVMZ6UStZL1dgxRQfDnIzqQa4e+Lx6GNSknzMp2DU2OWlselLvcE6YAwAAAJxFoJstDglW1qb1HSsnzchN/LMe7myaSiabncv2Spm0VaZs9iOtzZqCW02akcuOE+YAAAAAtxHoZiM7MXt2yNNm8gxdNhtnPJvN5GVPTgl0qv+R9ZOTJi/vPPRnAwAAAHAPgc4lR9i8xFrzBie/wesAAAAAnDS8X37KQZs2bdJ73vMedXR0aNGiRfrYxz6mnTt3TjmnUqlo/fr1mj9/vtrb27V27Vr19/dPOWfXrl1as2aNWltbtWjRIl133XWK4/jYP81cNPleuTd6AABmHWoqAGAmTCvQbd26VevXr9cTTzyhzZs3K4oiXXTRRRodHW2cc+211+pb3/qW7rvvPm3dulV79uzRpZde2jieJInWrFmjWq2mxx9/XF//+td1991364Ybbpi5TwUAwCxHTQUAzARj7dFP4ezdu1eLFi3S1q1b9Wu/9msaGhrSwoULdc899+jjH/+4JOmFF17QOeeco23btmnlypV66KGH9JGPfER79uxRd3e3JOnOO+/UF7/4Re3du1e5XO6Xvm+5XFapVNIHdIkCEx7t8AEAxyC2kR7VAxoaGlKxWGz2cJxHTQWAuelY6+m0ZugONTQ0JEnq6uqSJG3fvl1RFGnVqlWNc84++2wtXbpU27ZtkyRt27ZN5557bqPwSNLq1atVLpf13HPPHfF9qtWqyuXylAcAACcTaioA4GgcdaBL01TXXHON3ve+9+md73ynJKmvr0+5XE6dnZ1Tzu3u7lZfX1/jnMmFZ+L4xLEj2bRpk0qlUuOxZMmSox02AACzDjUVAHC0jjrQrV+/Xj/60Y907733zuR4jmjjxo0aGhpqPHbv3n3c3xMAgBOFmgoAOFpH1bbgqquu0oMPPqjHHntMp556auP5np4e1Wo1DQ4OTvmNYn9/v3p6ehrnPPXUU1N+3sSOXRPnHCqfzyufzx/NUAEAmNWoqQCAYzGtGTprra666irdf//9euSRR3T66adPOb58+XKFYagtW7Y0ntu5c6d27dql3t5eSVJvb6927NihgYGBxjmbN29WsVjUsmXLjuWzAADgDGoqAGAmTGuGbv369brnnnv0wAMPqKOjo7E+v1QqqaWlRaVSSVdccYU2bNigrq4uFYtFXX311ert7dXKlSslSRdddJGWLVumyy+/XDfffLP6+vp0/fXXa/369fzGEAAwZ1BTAQAzYVptC4wxR3z+rrvu0m/+5m9KypqgfuELX9Df/M3fqFqtavXq1br99tunLP145ZVXdOWVV+rRRx9VW1ub1q1bp5tuuklB8ObyJVssA0Dz0bbg2FBTAQDSsdfTY+pD1ywUHwBoPgLdyYGaCgDN1dQ+dAAAAACA5iHQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgqGkFujvuuEPnnXeeisWiisWient79dBDDzWOVyoVrV+/XvPnz1d7e7vWrl2r/v7+KT9j165dWrNmjVpbW7Vo0SJdd911iuN4Zj4NAACOoKYCAGbCtALdqaeeqptuuknbt2/XM888ow9+8IO65JJL9Nxzz0mSrr32Wn3rW9/Sfffdp61bt2rPnj269NJLG69PkkRr1qxRrVbT448/rq9//eu6++67dcMNN8zspwIAYJajpgIAZoKx1tpj+QFdXV362te+po9//ONauHCh7rnnHn384x+XJL3wwgs655xztG3bNq1cuVIPPfSQPvKRj2jPnj3q7u6WJN1555364he/qL179yqXyx3xParVqqrVauP7crmsJUuW6AO6RIEJj2X4AICjFNtIj+oBDQ0NqVgsNns4JwVqKgDMPcdaT4/6HrokSXTvvfdqdHRUvb292r59u6Io0qpVqxrnnH322Vq6dKm2bdsmSdq2bZvOPffcRuGRpNWrV6tcLjd+I3kkmzZtUqlUajyWLFlytMMGAGDWoaYCAI7WtAPdjh071N7ernw+r8997nO6//77tWzZMvX19SmXy6mzs3PK+d3d3err65Mk9fX1TSk8E8cnjr2RjRs3amhoqPHYvXv3dIcNAMCsQ00FAByrYLovOOuss/Tss89qaGhIf//3f69169Zp69atx2NsDfl8Xvl8/ri+BwAAJxo1FQBwrKYd6HK5nM444wxJ0vLly/X000/rT//0T/WJT3xCtVpNg4ODU36j2N/fr56eHklST0+PnnrqqSk/b2LHrolzAACYK6ipAIBjdcx96NI0VbVa1fLlyxWGobZs2dI4tnPnTu3atUu9vb2SpN7eXu3YsUMDAwONczZv3qxisahly5Yd61AAAHAaNRUAMF3TmqHbuHGjLr74Yi1dulTDw8O655579Oijj+o73/mOSqWSrrjiCm3YsEFdXV0qFou6+uqr1dvbq5UrV0qSLrroIi1btkyXX365br75ZvX19en666/X+vXrWf4BAJhTqKkAgJkwrUA3MDCgT3/603rttddUKpV03nnn6Tvf+Y5+4zd+Q5J0yy23yPM8rV27VtVqVatXr9btt9/eeL3v+3rwwQd15ZVXqre3V21tbVq3bp2+8pWvzOynAgBglqOmAgBmwjH3oWuGcrmsUqlEzxwAaCL60J0cqKkA0FxN60MHAAAAAGguAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA46pgC3U033SRjjK655prGc5VKRevXr9f8+fPV3t6utWvXqr+/f8rrdu3apTVr1qi1tVWLFi3SddddpziOj2UoAAA4i3oKADhaRx3onn76af3FX/yFzjvvvCnPX3vttfrWt76l++67T1u3btWePXt06aWXNo4nSaI1a9aoVqvp8ccf19e//nXdfffduuGGG47+UwAA4CjqKQDgWBxVoBsZGdFll12mv/zLv9S8efMazw8NDemv/uqv9Md//Mf64Ac/qOXLl+uuu+7S448/rieeeEKS9N3vflfPP/+8/vqv/1rvete7dPHFF+urX/2qbrvtNtVqtZn5VAAAOIB6CgA4VkcV6NavX681a9Zo1apVU57fvn27oiia8vzZZ5+tpUuXatu2bZKkbdu26dxzz1V3d3fjnNWrV6tcLuu555474vtVq1WVy+UpDwAAXHei66lETQWAk00w3Rfce++9+v73v6+nn376sGN9fX3K5XLq7Oyc8nx3d7f6+voa50wuPhPHJ44dyaZNm/TlL395ukMFAGDWakY9laipAHCymdYM3e7du/X5z39e3/jGN1QoFI7XmA6zceNGDQ0NNR67d+8+Ye8NAMBMa1Y9laipAHCymVag2759uwYGBvTud79bQRAoCAJt3bpVt956q4IgUHd3t2q1mgYHB6e8rr+/Xz09PZKknp6ew3bpmvh+4pxD5fN5FYvFKQ8AAFzVrHoqUVMB4GQzrUB34YUXaseOHXr22WcbjwsuuECXXXZZ4+swDLVly5bGa3bu3Kldu3apt7dXktTb26sdO3ZoYGCgcc7mzZtVLBa1bNmyGfpYAADMXtRTAMBMmdY9dB0dHXrnO9855bm2tjbNnz+/8fwVV1yhDRs2qKurS8ViUVdffbV6e3u1cuVKSdJFF12kZcuW6fLLL9fNN9+svr4+XX/99Vq/fr3y+fwMfSwAAGYv6ikAYKZMe1OUX+aWW26R53lau3atqtWqVq9erdtvv71x3Pd9Pfjgg7ryyivV29urtrY2rVu3Tl/5yldmeigAADiLegoAeDOMtdY2exDTVS6XVSqV9AFdosCEzR4OAMxJsY30qB7Q0NAQ92E5jJoKAM11rPX0qPrQAQAAAACaj0AHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjppWoPuDP/gDGWOmPM4+++zG8UqlovXr12v+/Plqb2/X2rVr1d/fP+Vn7Nq1S2vWrFFra6sWLVqk6667TnEcz8ynAQDAEdRUAMBMCKb7gne84x36p3/6p4M/IDj4I6699lr94z/+o+677z6VSiVdddVVuvTSS/Wv//qvkqQkSbRmzRr19PTo8ccf12uvvaZPf/rTCsNQf/RHfzQDHwcAAHdQUwEAx2ragS4IAvX09Bz2/NDQkP7qr/5K99xzjz74wQ9Kku666y6dc845euKJJ7Ry5Up997vf1fPPP69/+qd/Und3t971rnfpq1/9qr74xS/qD/7gD5TL5Y79EwEA4AhqKgDgWE37HroXX3xRixcv1lvf+lZddtll2rVrlyRp+/btiqJIq1atapx79tlna+nSpdq2bZskadu2bTr33HPV3d3dOGf16tUql8t67rnn3vA9q9WqyuXylAcAAK6jpgIAjtW0At2KFSt099136+GHH9Ydd9yhl19+Wb/6q7+q4eFh9fX1KZfLqbOzc8pruru71dfXJ0nq6+ubUngmjk8ceyObNm1SqVRqPJYsWTKdYQMAMOtQUwEAM2FaSy4vvvjixtfnnXeeVqxYodNOO01/93d/p5aWlhkf3ISNGzdqw4YNje/L5TIFCADgNGoqAGAmHFPbgs7OTr397W/XSy+9pJ6eHtVqNQ0ODk45p7+/v3F/QE9Pz2E7dE18f6R7CCbk83kVi8UpDwAATibUVADA0TimQDcyMqKf/vSnOuWUU7R8+XKFYagtW7Y0ju/cuVO7du1Sb2+vJKm3t1c7duzQwMBA45zNmzerWCxq2bJlxzIUAACcRk0FAByNaS25/J3f+R199KMf1WmnnaY9e/boxhtvlO/7+tSnPqVSqaQrrrhCGzZsUFdXl4rFoq6++mr19vZq5cqVkqSLLrpIy5Yt0+WXX66bb75ZfX19uv7667V+/Xrl8/nj8gEBAJiNqKkAgJkwrUD36quv6lOf+pT27dunhQsX6v3vf7+eeOIJLVy4UJJ0yy23yPM8rV27VtVqVatXr9btt9/eeL3v+3rwwQd15ZVXqre3V21tbVq3bp2+8pWvzOynAgBglqOmAgBmgrHW2mYPYrrK5bJKpZI+oEsUmLDZwwGAOSm2kR7VAxoaGuI+LIdRUwGguY61nk67sfhsMJFBY0WSc3EUAE4OsSJJB/9OhpuoqQDQXMdaT50MdPv27ZMkfU/fbvJIAADDw8MqlUrNHgaOEjUVAGaHo62nTga6rq4uSdKuXbv4n4hJJnoJ7d69m+VPdVyTw3FNDsc1ObJfdl2stRoeHtbixYubMDrMFGrq4fg74XBckyPjuhyOa3K4411PnQx0npd1WyiVSvyHcgT0FToc1+RwXJPDcU2O7BddFwKA+6ipb4y/Ew7HNTkyrsvhuCaHO1719Jj60AEAAAAAmodABwAAAACOcjLQ5fN53XjjjTROPQTX5XBck8NxTQ7HNTkyrsvcwL/nw3FNDsc1OTKuy+G4Joc73tfEyT50AAAAAABHZ+gAAAAAAAQ6AAAAAHAWgQ4AAAAAHEWgAwAAAABHORnobrvtNr3lLW9RoVDQihUr9NRTTzV7SMfNY489po9+9KNavHixjDH65je/OeW4tVY33HCDTjnlFLW0tGjVqlV68cUXp5yzf/9+XXbZZSoWi+rs7NQVV1yhkZGRE/gpZtamTZv0nve8Rx0dHVq0aJE+9rGPaefOnVPOqVQqWr9+vebPn6/29natXbtW/f39U87ZtWuX1qxZo9bWVi1atEjXXXed4jg+kR9lxtxxxx0677zzGg0re3t79dBDDzWOz7XrcSQ33XSTjDG65pprGs/NxevyB3/wBzLGTHmcffbZjeNz8ZrMZXOpnkrU1ENRT4+MmvrLUVNnWT21jrn33nttLpez/+f//B/73HPP2c985jO2s7PT9vf3N3tox8W3v/1t+z//5/+0//AP/2Al2fvvv3/K8ZtuusmWSiX7zW9+0/7bv/2b/c//+T/b008/3Y6PjzfO+dCHPmTPP/98+8QTT9h/+Zd/sWeccYb91Kc+dYI/ycxZvXq1veuuu+yPfvQj++yzz9oPf/jDdunSpXZkZKRxzuc+9zm7ZMkSu2XLFvvMM8/YlStX2v/4H/9j43gcx/ad73ynXbVqlf3BD35gv/3tb9sFCxbYjRs3NuMjHbP/+3//r/3Hf/xH+5Of/MTu3LnT/t7v/Z4Nw9D+6Ec/stbOvetxqKeeesq+5S1vseedd579/Oc/33h+Ll6XG2+80b7jHe+wr732WuOxd+/exvG5eE3mqrlWT62lph6Kenpk1NRfjJqamU311LlA9973vteuX7++8X2SJHbx4sV206ZNTRzViXFo8UnT1Pb09Nivfe1rjecGBwdtPp+3f/M3f2Ottfb555+3kuzTTz/dOOehhx6yxhj785///ISN/XgaGBiwkuzWrVuttdk1CMPQ3nfffY1zfvzjH1tJdtu2bdbarKh7nmf7+voa59xxxx22WCzaarV6Yj/AcTJv3jz7v//3/57z12N4eNieeeaZdvPmzfY//af/1Cg+c/W63Hjjjfb8888/4rG5ek3mqrlcT62lph4J9fSNUVMz1NSDZlM9dWrJZa1W0/bt27Vq1arGc57nadWqVdq2bVsTR9YcL7/8svr6+qZcj1KppBUrVjSux7Zt29TZ2akLLrigcc6qVavkeZ6efPLJEz7m42FoaEiS1NXVJUnavn27oiiacl3OPvtsLV26dMp1Offcc9Xd3d04Z/Xq1SqXy3ruuedO4OhnXpIkuvfeezU6Oqre3t45fz3Wr1+vNWvWTPn80tz+7+TFF1/U4sWL9da3vlWXXXaZdu3aJWluX5O5hnp6OGoq9fRIqKlTUVOnmi31NJiBz3LCvP7660qSZMoHl6Tu7m698MILTRpV8/T19UnSEa/HxLG+vj4tWrRoyvEgCNTV1dU4x2Vpmuqaa67R+973Pr3zne+UlH3mXC6nzs7OKeceel2OdN0mjrlox44d6u3tVaVSUXt7u+6//34tW7ZMzz777Jy8HpJ077336vvf/76efvrpw47N1f9OVqxYobvvvltnnXWWXnvtNX35y1/Wr/7qr+pHP/rRnL0mcxH19HBzvaZST6eiph6OmjrVbKqnTgU64FDr16/Xj370I33ve99r9lCa7qyzztKzzz6roaEh/f3f/73WrVunrVu3NntYTbN79259/vOf1+bNm1UoFJo9nFnj4osvbnx93nnnacWKFTrttNP0d3/3d2ppaWniyAA0E/V0KmrqVNTUw82meurUkssFCxbI9/3Ddojp7+9XT09Pk0bVPBOf+Rddj56eHg0MDEw5Hsex9u/f7/w1u+qqq/Tggw/qn//5n3Xqqac2nu/p6VGtVtPg4OCU8w+9Lke6bhPHXJTL5XTGGWdo+fLl2rRpk84//3z96Z/+6Zy9Htu3b9fAwIDe/e53KwgCBUGgrVu36tZbb1UQBOru7p6T1+VQnZ2devvb366XXnppzv63MhdRTw83l2sq9fRw1NSpqKm/XDPrqVOBLpfLafny5dqyZUvjuTRNtWXLFvX29jZxZM1x+umnq6enZ8r1KJfLevLJJxvXo7e3V4ODg9q+fXvjnEceeURpmmrFihUnfMwzwVqrq666Svfff78eeeQRnX766VOOL1++XGEYTrkuO3fu1K5du6Zclx07dkwpzJs3b1axWNSyZctOzAc5ztI0VbVanbPX48ILL9SOHTv07LPPNh4XXHCBLrvsssbXc/G6HGpkZEQ//elPdcopp8zZ/1bmIurp4eZiTaWevnnUVGrqL9PUejrdHV2a7d5777X5fN7efffd9vnnn7ef/exnbWdn55QdYk4mw8PD9gc/+IH9wQ9+YCXZP/7jP7Y/+MEP7CuvvGKtzbZY7uzstA888ID94Q9/aC+55JIjbrH8H/7Df7BPPvmk/d73vmfPPPNMZ7dYttbaK6+80pZKJfvoo49O2Sp2bGyscc7nPvc5u3TpUvvII4/YZ555xvb29tre3t7G8YmtYi+66CL77LPP2ocfftguXLjQ2a1zv/SlL9mtW7fal19+2f7whz+0X/rSl6wxxn73u9+11s696/FGJu/IZe3cvC5f+MIX7KOPPmpffvll+6//+q921apVdsGCBXZgYMBaOzevyVw11+qptdTUQ1FPj4ya+ubM9Zo6m+qpc4HOWmv/7M/+zC5dutTmcjn73ve+1z7xxBPNHtJx88///M9W0mGPdevWWWuzbZZ///d/33Z3d9t8Pm8vvPBCu3Pnzik/Y9++ffZTn/qUbW9vt8Vi0f7Wb/2WHR4ebsKnmRlHuh6S7F133dU4Z3x83P73//7f7bx582xra6v9L//lv9jXXnttys/593//d3vxxRfblpYWu2DBAvuFL3zBRlF0gj/NzPjt3/5te9ppp9lcLmcXLlxoL7zwwkbhsXbuXY83cmjxmYvX5ROf+IQ95ZRTbC6Xs7/yK79iP/GJT9iXXnqpcXwuXpO5bC7VU2upqYeinh4ZNfXNmes1dTbVU2OttdOb0wMAAAAAzAZO3UMHAAAAADiIQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAo5oa6G677Ta95S1vUaFQ0IoVK/TUU081czgAADiJegoAc1fTAt3f/u3fasOGDbrxxhv1/e9/X+eff75Wr16tgYGBZg0JAADnUE8BYG4z1lrbjDdesWKF3vOe9+jP//zPJUlpmmrJkiW6+uqr9aUvfWnKudVqVdVqtfF9mqbav3+/5s+fL2PMCR03ACBjrdXw8LAWL14sz2MFf7NMp55K1FQAmG2OtZ4Gx2FMv1StVtP27du1cePGxnOe52nVqlXatm3bYedv2rRJX/7yl0/kEAEAb9Lu3bt16qmnNnsYc9J066lETQWA2epo62lTAt3rr7+uJEnU3d095fnu7m698MILh52/ceNGbdiwofH90NCQli5dqvfrwwoUHvfxAgAOFyvS9/RtdXR0NHsoc9Z066lETQWA2eZY62lTAt105fN55fP5w54PFCowFB8AaIr6gn2W6bmFmgoAs8wx1tOm3PSwYMEC+b6v/v7+Kc/39/erp6enGUMCAMA51FMAQFMCXS6X0/Lly7Vly5bGc2maasuWLert7W3GkAAAcA71FADQtCWXGzZs0Lp163TBBRfove99r/7kT/5Eo6Oj+q3f+q1mDQkAAOdQTwFgbmtaoPvEJz6hvXv36oYbblBfX5/e9a536eGHHz7sxm4AAPDGqKcAMLc1rQ/dsSiXyyqVSvqALuEGbgBokthGelQPaGhoSMVisdnDwVGipgJAcx1rPaUTLAAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjpp2oHvsscf00Y9+VIsXL5YxRt/85jenHLfW6oYbbtApp5yilpYWrVq1Si+++OKUc/bv36/LLrtMxWJRnZ2duuKKKzQyMnJMHwQAAJdQTwEAM2HagW50dFTnn3++brvttiMev/nmm3Xrrbfqzjvv1JNPPqm2tjatXr1alUqlcc5ll12m5557Tps3b9aDDz6oxx57TJ/97GeP/lMAAOAY6ikAYCYYa6096hcbo/vvv18f+9jHJGW/TVy8eLG+8IUv6Hd+53ckSUNDQ+ru7tbdd9+tT37yk/rxj3+sZcuW6emnn9YFF1wgSXr44Yf14Q9/WK+++qoWL1582PtUq1VVq9XG9+VyWUuWLNEHdIkCEx7t8AEAxyC2kR7VAxoaGlKxWGz2cJx2ouqpRE0FgNnmWOvpjN5D9/LLL6uvr0+rVq1qPFcqlbRixQpt27ZNkrRt2zZ1dnY2io8krVq1Sp7n6cknnzziz920aZNKpVLjsWTJkpkcNgAAs8rxqqcSNRUATjYzGuj6+vokSd3d3VOe7+7ubhzr6+vTokWLphwPgkBdXV2Ncw61ceNGDQ0NNR67d++eyWEDADCrHK96KlFTAeBkEzR7AG9GPp9XPp9v9jAAAHAeNRUATi4zOkPX09MjServ75/yfH9/f+NYT0+PBgYGphyP41j79+9vnAMAwFxGPQUAvFkzGuhOP/109fT0aMuWLY3nyuWynnzySfX29kqSent7NTg4qO3btzfOeeSRR5SmqVasWDGTwwEAwEnUUwDAmzXtJZcjIyN66aWXGt+//PLLevbZZ9XV1aWlS5fqmmuu0R/+4R/qzDPP1Omnn67f//3f1+LFixs7d51zzjn60Ic+pM985jO68847FUWRrrrqKn3yk598wx25AAA42VBPAQAzYdqB7plnntGv//qvN77fsGGDJGndunW6++679bu/+7saHR3VZz/7WQ0ODur973+/Hn74YRUKhcZrvvGNb+iqq67ShRdeKM/ztHbtWt16660z8HEAAHAD9RQAMBOOqQ9ds5TLZZVKJXrmAEAT0Yfu5EBNBYDmmlV96AAAAAAAJw6BDgAAAAAcRaADAAAAAEcR6AAAAADAUQQ6AAAAAHAUgQ4AAAAAHEWgAwAAAABHEegAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAARxHoAAAAAMBRBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcR6AAAAADAUQQ6AAAAAHAUgQ4AAAAAHEWgAwAAAABHEegAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAARxHoAAAAAMBRBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcFzR4AZiljJBnJSJLJvs0O1J+TZBv/OPTFRzzHTnzd+PNIrwUAAADwZhHocNDB1CYZT8bUg5kxBx/Zwfqf9UA2OZj9gnOMrYc4K1lrJaUHX0e4AwAAAKaNQIfMRBAzph7kPMnLQpzxPMnzDp7j1f9MJwU6a6eGviOdk6ayaXow3KX1YDfxWkIdAAAAMC0EOkwKYkbGOxjmjO9Lvn8w0HkTM3X1Wy9tmk3A1UOajDnCObYR5hqPJJFN0uz9rM1C3pFm+wAAAAD8QgS6uW7iXrmJMOf5Mr6XBbkgkIJ6qPP9SaFuUqBLJ4W1KcHv8HNsksgkiRQnUpJIcSybpjKSrGX5JQAAADBdBLq5rLHxyaQwF9SDXBhIQSAThlIYyAa+5HuS78nWl1Uaa6XEZuFsItAdco6slamfY+J6iKtFMnGcvX+cyNpYJp0U6rKE15RLAgAAALiEQDfXGU0Nc/UAZ/J5KRfK5kLZfCCbC5QGnmzgTbk/ziSpvCiViVNZ31Ma/oJzaolMLcoCYy2SNTUZE0lGsnGc5bg0yVZfGh15A00AAAAADQS6ucpM3vBk8sxcKJPPyRbqj5ackkKgtOAryXlKAyNbX01pUsmLrbxaFths4CnJv/E5fiWRX6m/l+9l+6AYydRbGFibfZ1tnCKR6AAAAIBfjEA3l00KdSYIpFw9zLXkZVsLStpCxW2h4lZfcYunuGCUhpL16y9PJC+WgoqVV7NKQ3P4OankRdk5wbivYMxXMOLL9z1JRkYmC3JW9VCXsuMlAAAA8CYR6OaiiSBnzMH73urLLbNZubyStpzijlC1oq9au6eoVUpajZLcIYGuJgXjkl81SnNS3GKU5I98TjjqK8wZWS/rb+fXd8A0E+0M6g9jJWvY9RIAAAD4ZQh0c1W9tUA2O+dLYSjlQqmQU9qaU9QRqlbyVe30VCsaRR1WcVuqtGCloL55SWzkVT35o0bBuFFSqJ+Tt1J4+DnxsFGS82QnNtZMrfzUZjtfTuyAmaSyqZUxpt58HAAAAMAbIdDNUUaq94072KLA5kKl+VBJa6Co3Vet6KnaaVSdZ5WUEnkdkVpaIuXCWJJUi31Vx3OKhkPFY55sSyqvI1Khfo4xUi06eE4a+rKekUk9eank1YLs3rtaLBPFsn4s+YmUHGylwH10AAAAwBsj0M0VE20EpKxHnPHqu1tmgU6BL4WB0kKguMVX1G5U6zCqlaySrlj5eRUtKA1rQcuoOsKqJGkkzuv18Ta9nm9XZSSvfFtNC0ojWtAycuRzvBbVFMiLjLzIkz/uy6/6MpXgYM+7OJs1tOnEvXTNuFgAAACAGwh0J7uJIFe/by770jtkl0tPNvBlQ19pvr4BSqtR1C7FpVS5zqoWdw3qzNJeLS3sV1cwIiNpf9Km3YUuvegvVH+uQwvaRvX20oCWFPZrfv2cA0mbdhW69JK/ULutUTVpUTweKK5IcYunYNyXF/pZnzsvC5kT99jJvNGHAgDg5PX288f0jveONr5/7ZWcnvhuqYkjAjCbEehOVocEOTMR6OrLLBsbonhZqLNe1j8uDT0lOaM4b5S0WKk1VqljTEvbD+icttf0ttyAFtbD2utJm9q9qmqpL2uMTm0d1Nltr+mMKee0qs2rKLK+hmt5DYyFilt8JQWjNGcO9q3z6zNzk8ImAABzhe9b/efffl3/cfWQFv5KTaecVmsce+afi9r+aIeimtfEEQKYrQh0JyNTn94yymbgJkJcfTZuYiZsYuml6ksvre8p9Y3SQEpzUpqzCgqxOgvjOqUwpLfk9uqM3AF1Zx0H1OkdUGKN9hY6NJIUdEphSKfnXtfbwgPq9rO37fQGlVpPr+c79GqhUwcKbYryOSVhvb1BYCTf1MdAkAMAzD3nXDCqCz4wrP96Tb887/B7DZb/p7I+uPaAvvM385swOgCzHYHuZNMIc6Zxj5yZ2PjE97MWBb5/8PmJmbqJJY6eJC9rDG59yfNT5fxYrX5NHV5VHSZVu1eQkVQxVXV4VbX6VRX8SK1eTe1eRR1eqo6Jc7yq2r2qWv2a8n4sz08lz0qeZI2RNdmfk0PoxNdsiQIAOJn5gdXb3zWmjbe9ou4ltTc8z3jShz61X//yYKfGhv0TOEIALiDQnUwmBaOJ2TgTZBueZJuOBI0/5Wczcpq8FNOq/rAyqZFSyVqjJPUUpb6qNlDVGtVststlVVZV66uWBopSX5H1VZtyjlHVWtWsr1rqK7aebJbgJr3XwabiUxHlAAAnpzCX6tyVo/rU/+jXWf9hTPmW9BeeP7Qv0H13LNTYCEsuARyOQHeyaCxVnDQzNxHkcqFMGEphKJsLpDBobIIiL5slm+jjbRIrL6k3BI+NkpqvkSiv/VGb+uOSil5FiSqSpNeTgvrikvZHbSpHBe2P2tQXl9RRP8dMOaddI7W84povE0leLHmJlZdmzcVlbdZYfOJrEekAACcjq09ePaDLNvT90rsMnn+6TY/cP0/9u3N6akvxxAwPgHMIdCcTM3VmzoSBFOZk8jnZfC5rGp4PskfOlw2ze+bkSUolk9ps1WNk5Vet/HGpNhbowEir/j0/X61+TWNpqIXBiCSrfXG7Xqku0L+Pzlf/SIdsKrX5VY2nOS0IhmUmnfPy6HztH2lTMhYqrBj5VSuvZmUiKxOnUlIPc42A1+yLCQDAzMrlU122oV8f/28DbxjmalVPu36S12jZ11c/8xYND/K/agB+Mf6WOBlMLLOsb3BifK8e5kKZQk62kJdtySttzSlpCRS3+kry2W6WaaBG/24vyX5cnM+WRJrESLFRFPsaj0MNJwWVkxaFJpVkVU5aNRwXNB6HGq3k9PO4U1ZGr9faVQrHZWRVjlvUN96hnw91anSoRd6wr3DUKBi3CqpWfi2ViRKZJM16z9l6sCPRAQBOKlb/9Zp+ffLq/jc8Y/vWDm37TknfunvBCRwXANcR6E4WjXvhJhqFBzK5nGw+L9uaV9KWV9wRKmrzFLV5iluMkryUhtkGKCaVTGxlUmXHWqziNivTlqizfUynte/XstY9OiM/oIX+iKR62wK/olrqa7ia18CBol6uBdrb0q6WsCYjaTwONTKeV6VckA6ECgeNwmGrcNQqGE/kVWKZKJbiWIoT2SSVTSfN1AEA4LgzzxvThj/erSVnVI54vLw/0E/+rUU3/4/TNLSP/zUDMD38rXFSqPeZ84yMX79vLgylfE62JaekLa+oGKpW8lXr8FTrMIrbpLjFKs2ljSWXXmRkYilpTZW2plIuVdgSqVSoqCc/pNNy+3R6OKhuP9uBsugNKZan/nxRuwvztM9v1/jrraoEBZkwu8HbRp5U8eSP+grLRrmyVa5sFY4k8scSeZVIphZJUSIlSf0+uvrN4eQ5AIDjjLH6tY8O6q3Lxt/wnP/1lcXa/HfzlC2ZAYDpIdCdDCa2+jcma0sQ+DJhKJsLlbaEitsCRR2+qiVPtZJRtdMqaU9l2xJ5+UTGs7KpUVzzZWuevLZYrW1VteRrCv1UhSBWix+pzauq3Vi1mbyMpHavqjZTU0u9JYHvpTJVo2B/KFvvVWdiya9K/rhROGKVG7HKl1OFI7H8sUimGkm1WDaOZCcCXWplbbasEwAAV/mBVWtHog//P/uOeLwy5um5p9u0/dEOEeYAHC0Cneum9J2b6DUXyIaBbGEi0GUzc9WSUbXLKumKFXZWVWofV0e+otBPFNeXTY5WcupoqerUjkHNy42p4MeKUk+x9VSxgSrWqFpvW1BJpYoNGm0L0tTIJEZh2Sio/yLSJFZeJAWVVMGYVTiWKhyO5Y/V5I1WZcZrsrWaFMVSki25ZKklAOBk0HvRkDbe8YqC4Mh1bdN/P01PbSkqTQhzAI4egc51pr7csr7kMtvh0mu0JUjynqJWT1GbFHVYJaVE+a6KujvLWtp+QAvzwyp4kappqH1Rm/rHi+rKj+rtbf06JTekgqlp3OZ0IG5TX9SpDq+qSBUZWe1NCnot7tTrUbuGa3nFtUAmNvJiKT9U38UylbzYyq+mCsZT+ZVY3lgkb7wmU6nWw1w2OzcR5qy1U9oXAADgmkJbokt++3UF4eG1bGTI15//3qn6yb+1EuYAHDMCncsas3PKwtykUKfAV1oPdEnBKG41ittT+cWaujvLOquzX+e0vaYl4X61ejWNpzntiTr1s3ChOoMxnd+6W6cGg2o1iUZtoN1xp35WXaR/G1+i+UG2KUrWkmC+Xh6Zr/0jrUrHAuXGJL9iFYynyg0l8qJUXmxlokReNZGpxTKVSKZWk63UpKgmO7EpSppkSy3tL26wCgDAbDa/p6Yv/fkunds7ctix/t05/eTfWvXP3+yULGEOwLEj0LnKTCyzrM/KGS/rQWeyPnTW92QDozQ0SnJSkpNsIVW+NVJ367DeUtins/J9Oi0YUpuXaiz1VPTHFctXq1fVqcGQlgSx2oyvURvJalD9UVE7x0/RS3aRJGk4LqhvvKg9QyWN1VsSBGNGQcVmoW4slj8aycSpTJxIcZLtaFmLZKMom5mrh7nG/XMTs3LMzgEAHNRWTPTFP9ul8/7j4WFOkh65f57uvumUEzwqACczAp2LGmGu3kTcDw72nQsDWd+XPCM78fAlG1gpl6qQi1QMK1oYDqvbH9EpgdRm8hrzIsUa1R5/REZWLSZWq/FVMKGspBaTqMWLVEt9PX/gFEWJp0ocanQ8r2o5L28wUG7QU27YKhyxCsYSeZVE3lg12/gkSeptCZKDLQriifvmsjDHUksAgOvectb4G4a572/t0H23LzzBIwJwsiPQOcrUe84Z35dCPwtz+ZxsS162kFeaD2R9T8p6hDdWdRhZ+SaVb1IFxiqQkS9PgTwFSmVkVbWhxmygUVuTJI3aWGM2r7E0p0oSqlzJa/BAu2zVkyq+/FHvsJYEwXgsr1rfxbJSzWbi0kRK0izANe6ZSwlzAICTwrkrR/R7d7yS3RFxKCv96RdP1WiZ//UCMLP4W8U1kxuIe0aq950zuYm+c3mlbXnF7aGidl9xPusZZxJJiVEUBxqNcxpKWjSY5LXfG1XVVDRmrQ6kBQ0lrSonLdrldyrVkFpNFuZ2RfP0Wq1T+6utGq/kZIcDBQd8+VWjYEyNlgS5cqJwONv4xFSixvJKW4safebsxNLK+p82neg7R5gDALjJD6xWXlRWV3d0xOP/7/9aqNf7whM8KgBzgTedkzdt2qT3vOc96ujo0KJFi/Sxj31MO3funHJOpVLR+vXrNX/+fLW3t2vt2rXq7++fcs6uXbu0Zs0atba2atGiRbruuusUx/Gxf5o5wphJbQoCXwomhbn2vKKOUNV5gca7fFXme6p2GqWhpMjT2HhOA+MdeqUyXy/WFmlnraQXooJ2RkW9WOvWK9X5emlskX44vlTfH1+qZyqnavv4Uv1wbIl+MrJIe4ZLqo7m5I16yg8atfZbte5N1bIvVeFArNxgpGCk3pKgUq3fKxdLUSwbxY1llkoS2YlwJxHmAMw51NSTy5IzKlr73waOeGxfX6inthQV16b1v10A8KZMa4Zu69atWr9+vd7znvcojmP93u/9ni666CI9//zzamtrkyRde+21+sd//Efdd999KpVKuuqqq3TppZfqX//1XyVJSZJozZo16unp0eOPP67XXntNn/70pxWGof7oj/5o5j/hyaYxQ1dvIu772X1zuVBpIVTcWm8iXsyCXK1kFRdT2dZUphBLRto72q6f+gsla/R6vkMtXk2VNNRAraifji7Q/kqrBmst2p2bp7wXq5oG2ldt02vDRe0fapcth8qNGgVj2RLL3EgifzyRX0myZuHjNZlKTbZay2bo6uEtW1qZTl1aSZADMEdRU08mVp++ru8Nl1r+7PkWPfu9jhM+KgBzg7H26P+Peu/evVq0aJG2bt2qX/u1X9PQ0JAWLlyoe+65Rx//+MclSS+88ILOOeccbdu2TStXrtRDDz2kj3zkI9qzZ4+6u7slSXfeeae++MUvau/evcrlcr/0fcvlskqlkj6gSxSYObZ8wcvumzu4zLIg01pQ2tGqpJhXtSuvyjxPlfmeKvOt4nmJgnlVdbRXVCyMK+8nSqxRNQmU8xO1hVW1BpE8Y1VJApWrBY3U8qrEgTxj5RurOPFUqYaqjuZlhwLlDmSzc4V9qfIHEuUHI3ljNXm1WKpEMrVItlo9uNwyTrKWBPVQl7HZzX0AnBXbSI/qAQ0NDalYLDZ7OM6jprrrbe8Y06Z7f6bS/MNnRn/8TJv+5/9zOvfOAXhDx1pPj2nuf2hoSJLU1dUlSdq+fbuiKNKqVasa55x99tlaunSptm3bJknatm2bzj333EbhkaTVq1erXC7rueeeO+L7VKtVlcvlKY+5ykyeoZvcRDznK8n7iluMolajqD2bmQvmVdXdVdaZXQN6V9fP9e6uXXpX16t6e+eAAi9RuVaQJ6vufFlntffr/K6fa1lXn+a3jqoWBdq3v0OD/R2q9LfKDITK78/CXLb5SapwLJE3HmVLLEcrMuMV2Uo9zMXx1DA3eVaOMAcAU1BT3XXRJ/cfMczZVHrgrgWEOQDH1VH/DZOmqa655hq9733v0zvf+U5JUl9fn3K5nDo7O6ec293drb6+vsY5kwvPxPGJY0eyadMmffnLXz7aoZ58JjcQrzcRt0HWRDyuNxGP2lOZUqT5nSM6s3NAZ7X16y35verwqqpZX31RScWgR+W4oLPb+nRabp/avKqqaaC+uKS2oCrPSLtqgWoHWpQ74Ckcri+zHE4VjqTKDcXyRyJ54zWZai0LchN95SZaFEwOc+xiCQBHRE11V1sx1oKeI9+z+MTmkv7lH0sneEQA5pqjDnTr16/Xj370I33ve9+byfEc0caNG7Vhw4bG9+VyWUuWLDnu7zu7HZylk+fJBtkjCY2SvJQWrPItkRa2jugtLfv09kKfzgj3qcNLVLNG87wxRdbXUNKqs/Kv6a3hAbV7qcatp05/TJU01FDUotdb2lQr5GWNp2DcKj9klRtKFI4l8kci+aNVmUpNqtayRuH13SwnWhIQ5gDgl6OmuuvM88b1/jWDhz1fq3r6zr1dbIQC4Lg7qkB31VVX6cEHH9Rjjz2mU089tfF8T0+ParWaBgcHp/xGsb+/Xz09PY1znnrqqSk/b2LHrolzDpXP55XP549mqCcfY9QIc/VH1kBcSn3JBtlDoVU+F6mYq2hBOKIev6xT/FQdXl41G8tqTP1hWTmTqDsY0Sm+VZuXV8XGSu2YFoVldYbjaslFGgpT2UBKfSOTWgWVVMHwxE6WtazPXC3Kes1NzMzZem85drEEgF+ImuouP7C66o9ePeKxvldyevoRNkIBcPxN69dG1lpdddVVuv/++/XII4/o9NNPn3J8+fLlCsNQW7ZsaTy3c+dO7dq1S729vZKk3t5e7dixQwMDB7f23bx5s4rFopYtW3Ysn2VuMRP/mOgYfsjWWsbKSPJk5SuVb6wCY+TXG4n7Uv35VIFS+WaiwbhRYLLXeCaVZ6xkbKMxeUNqpVq9aXi1lrUniOP6Mst06gYohDkAOAw11X3GWM1bePhyyxd/2Kobf+t0xRGzcwCOv2nN0K1fv1733HOPHnjgAXV0dDTW55dKJbW0tKhUKumKK67Qhg0b1NXVpWKxqKuvvlq9vb1auXKlJOmiiy7SsmXLdPnll+vmm29WX1+frr/+eq1fv57fGL4Ztv6P1E5dyphamVTZY6KJeOJrLAlVTlo0mBR0wKsq9qqqWavBNNdoIj6YFnQgHVZsKhq3VoNpXkNJq0bjvGqxLxt78hLJpBPvc/B9bZpmfeUmh7lDWxMAAA5DTXVfWzGVd0hmSxOj7Vs7tOdlrj+AE2Nage6OO+6QJH3gAx+Y8vxdd92l3/zN35Qk3XLLLfI8T2vXrlW1WtXq1at1++23N871fV8PPvigrrzySvX29qqtrU3r1q3TV77ylWP7JHPGpJBUX9JoUiuTWHmxlRdJXk3yKp6q46FeH2/XrkKX2v2KUhl1eFVVra/+uKSXqwtUjlvU7lcUWU/tXk0Vm22K8kp1vvrGixoZL0gVT15N8muSF0smtjJJ9r62ESolpZYwBwBvEjXVfVd+9edqbU+mPLd/INDdNx15uSsAHA/TCnRvpmVdoVDQbbfdpttuu+0NzznttNP07W9/ezpvjckaISrbeERJKhMn8qJUfs3Krxr540bRaKh9w216OTdfklROWtRW3+VyX9Shn40t0EiUl5V0IN+mFq+mmg20t9ahn40u0GvDRVVGcvLGPPnjRn7Vyq9l72Xi+pLKNLtXLvtvg2bhAPBmUVPd5vlWQWAbdz6kqdGWv5+nf/r7eZRBACcUjVFOdqZ+p52RjKyMsTJWyv4hDVZb9MPar+iVfJfyfqw49VWuFfT6SJuGh1qlAznlyp7CEatgPFUwnsqrJlJcf0zcKzcxS0cVAwDMAe+7eEjvu3io8f2un+R1y+8sURIfetM5ABxfBDoXNXa49LKHnzUXT0NPSc4oKUhJi5XfFmlB+6hOb9+nc1r36K25vY0ll31xSb6sKnGolwe7tLfcLt+zSlOjWi1QPBrKDAcKB43CspQbsQrHUvmVRKYWy0T1e+aSiUCXHlx+CQDASc7zrTx/YmWK9A//ayFhDkBTEOicM6lY1PvQWc/I+kZpYJSGUpqT0kKq1pZIC1pGtLSwT2fkBnRGbkhFY1S1VkWvqvE01N6WdvWPtqtv/zxp1JcSIxMZBeNG4ahROGyVK6fKlVMFw7G88UimGmU7XNY3Qsl6zUlT7u8DAGCOeG1XTk9tKTZ7GADmKAKdaybaFXhTe9Gp3otu4iHfKvQTtfiROryKSv645nme2k1OkU00ZmOV/HG1+TXlgiRbijnqKzdk5MWSX5GCcatwxCo3kiocjhWMRvLGazKNNgVJtsNl434+Ah0A4OSXy6f6wCWDje/v/8uFOrA3bN6AAMxpBDpXNWbEDm5EMmWhhzX1jSeNYnmKrafYWiUmVaRUsbLnE+vJWiPZrOVBOCrlylZ+xSqoWAXjiYKxRP5oVG8knvWdUxTLxnGj39ybubkfAICTgR9anfHOcQ38PKcbf/N09e/ONXtIAOYwAp1rJnaTnNSDzkz0oEskE2etBRQZVWuhylFBr0cd6g+Lavf2qWhrqlqjvrhNA1FJg1GLxmqhbOQ1WhIEo6nyQ4n8SvbwKpFMJZKpVKVqTapF2QxdkhzeDw8AgJPc+IivG38zawT/s+dbmjwaAHMdgc5VjYbi2QyZiVN5cSo/8uRVjbyKUW0s1N6xdv17Yb7yXqRqGqjdqyqqb4rys/GF2jNW0shYQRr35VVN1vYgloKxWP5ITV41kqqxTC2SrdWkKGost7T1DVFsSpADAMwtBDkAswWBzkWTw1ySSnEiEyXyqmm2THLMKhwxqraE2pdr14teqvE4p75CSS1+pCj1dSBq1e7RTr02WFJ1KK9gxFM4mt0351dSeVEqrxrJjFbqM3JxtglKXP8zSaU0Odh/jtk5AAAA4IQj0DnG1pdYTgQ6W28qbqJseWQw7iscM0pGPCU5T7Gf14AtaqyaU19Lh3J+rCT1NFrLqTzaospQQd5goLBsFIxmYdCvJDLVWIqS7F65au1gmKu/Z+O+OZZaAgAAAE1DoHOSzUJVksoksRTFMtVIXugrGPWVC7IWBpJRLfEVVVs0OJzTUKFNnp/KWqO05ktjfjYzN2SUH7TKl63C0UT+WCxvYpllHEtJLBtFWd85a+ttCghzAAAAQLMR6FwzOUglqZQkslEkUwvkVbJAZz0j6xkZ68kkRl7VKGkxSnOBrG8lKwWRkV8xCkalcCQLc7nhRMFoLL8SSdVIiuLsXrk4mbqbZZoeHAsAAACApiHQOchaK2OtbJpIsSfjxVK1JmOMPM8olJWxkhf78quewlGjOC+luYmgl+1m6Vez1gThqFU4koW5YKQqM1aTqVazWbk4ru9mSZgDAAAAZhsCnWsmgpRNpdRkM3SxkYwnY0wW6qwUpJKJA/lVX3HBU5rLlmFaT5KVvETyalZBNZU/nsgfj+WPRzKj1axxeDWSJnazTA9ZXkmYAwAAAGYFAp2jslm6VDZRvaG4kVXWXNxYK5Mk8mqh/EqgIOcrDT1Zf9IMXWplolReLZVXjevtCSKZSq3enqAmG8WySXywNQH3zAEAAACzCoHORfVQZdNURlL23cGvsr502Q6VfjWQFwaygSd5RjImO83abHfMOM02Vall98zZKKr3mqvvapmksjbNZgQBAAAAzCoEOlc1Qp2VUSqrOJujs5JJU9kkkYkDKQhkfE/W9yTPO/j61MrUNzrJWhIkUpztmGmT5JAwx1JLAAAAYDYi0LnMWkmpbGoOzs+lNtvEJMlm6OT7WZDzjIzn1Wfo7MH2AxPNydMka4UQx9nyynRSmGOpJQAAADArEehcd8jyS8k2mo9bL5F8T8Zkgc6arDdd43U2bYS3xn1yaXrweWslEeYAAACA2YpAdzKYFOokk7U0sKmUGCnxsgw3EebMoa/Jgl1j1u7QGTnCHAAAADBrEehOFo3gZWXtwZk4Y9Ns70sjNQKd1cQ/6hukpPWnCHIAAACASwh0J5OJEGaU3Usn1ZdZvsnXHfo1AAAAgFmNQHcyIqABAAAAc4L3y08BAAAAAMxGBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcR6AAAAADAUQQ6AAAAAHAUgQ4AAAAAHEWgAwAAAABHEegAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAARxHoAAAAAMBRBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcR6AAAAADAUQQ6AAAAAHAUgQ4AAAAAHEWgAwAAAABHEegAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAARxHoAAAAAMBRBDoAAAAAcBSBDgAAAAAcRaADAAAAAEcR6AAAAADAUQQ6AAAAAHAUgQ4AAAAAHEWgAwAAAABHEegAAAAAwFEEOgAAAABwFIEOAAAAABxFoAMAAAAAR00r0N1xxx0677zzVCwWVSwW1dvbq4ceeqhxvFKpaP369Zo/f77a29u1du1a9ff3T/kZu3bt0po1a9Ta2qpFixbpuuuuUxzHM/NpAABwBDUVADATphXoTj31VN10003avn27nnnmGX3wgx/UJZdcoueee06SdO211+pb3/qW7rvvPm3dulV79uzRpZde2nh9kiRas2aNarWaHn/8cX3961/X3XffrRtuuGFmPxUAALMcNRUAMBOMtdYeyw/o6urS1772NX384x/XwoULdc899+jjH/+4JOmFF17QOeeco23btmnlypV66KGH9JGPfER79uxRd3e3JOnOO+/UF7/4Re3du1e5XO5NvWe5XFapVNIHdIkCEx7L8AEARym2kR7VAxoaGlKxWGz2cE4K1FQAmHuOtZ4e9T10SZLo3nvv1ejoqHp7e7V9+3ZFUaRVq1Y1zjn77LO1dOlSbdu2TZK0bds2nXvuuY3CI0mrV69WuVxu/EbySKrVqsrl8pQHAAAnC2oqAOBoTTvQ7dixQ+3t7crn8/rc5z6n+++/X8uWLVNfX59yuZw6OzunnN/d3a2+vj5JUl9f35TCM3F84tgb2bRpk0qlUuOxZMmS6Q4bAIBZh5oKADhW0w50Z511lp599lk9+eSTuvLKK7Vu3To9//zzx2NsDRs3btTQ0FDjsXv37uP6fgAAnAjUVADAsQqm+4JcLqczzjhDkrR8+XI9/fTT+tM//VN94hOfUK1W0+Dg4JTfKPb396unp0eS1NPTo6eeemrKz5vYsWvinCPJ5/PK5/PTHSoAALMaNRUAcKyOuQ9dmqaqVqtavny5wjDUli1bGsd27typXbt2qbe3V5LU29urHTt2aGBgoHHO5s2bVSwWtWzZsmMdCgAATqOmAgCma1ozdBs3btTFF1+spUuXanh4WPfcc48effRRfec731GpVNIVV1yhDRs2qKurS8ViUVdffbV6e3u1cuVKSdJFF12kZcuW6fLLL9fNN9+svr4+XX/99Vq/fj2/LQQAzCnUVADATJhWoBsYGNCnP/1pvfbaayqVSjrvvPP0ne98R7/xG78hSbrlllvkeZ7Wrl2rarWq1atX6/bbb2+83vd9Pfjgg7ryyivV29urtrY2rVu3Tl/5yldm9lMBADDLUVMBADPhmPvQNQM9cwCg+ehDd3KgpgJAczWtDx0AAAAAoLkIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOCoYwp0N910k4wxuuaaaxrPVSoVrV+/XvPnz1d7e7vWrl2r/v7+Ka/btWuX1qxZo9bWVi1atEjXXXed4jg+lqEAAOAs6ikA4GgddaB7+umn9Rd/8Rc677zzpjx/7bXX6lvf+pbuu+8+bd26VXv27NGll17aOJ4kidasWaNarabHH39cX//613X33XfrhhtuOPpPAQCAo6inAIBjcVSBbmRkRJdddpn+8i//UvPmzWs8PzQ0pL/6q7/SH//xH+uDH/ygli9frrvuukuPP/64nnjiCUnSd7/7XT3//PP667/+a73rXe/SxRdfrK9+9au67bbbVKvVZuZTAQDgAOopAOBYHVWgW79+vdasWaNVq1ZNeX779u2KomjK82effbaWLl2qbdu2SZK2bdumc889V93d3Y1zVq9erXK5rOeee+6I71etVlUul6c8AABw3YmupxI1FQBONsF0X3Dvvffq+9//vp5++unDjvX19SmXy6mzs3PK893d3err62ucM7n4TByfOHYkmzZt0pe//OXpDhUAgFmrGfVUoqYCwMlmWjN0u3fv1uc//3l94xvfUKFQOF5jOszGjRs1NDTUeOzevfuEvTcAADOtWfVUoqYCwMlmWoFu+/btGhgY0Lvf/W4FQaAgCLR161bdeuutCoJA3d3dqtVqGhwcnPK6/v5+9fT0SJJ6enoO26Vr4vuJcw6Vz+dVLBanPAAAcFWz6qlETQWAk820At2FF16oHTt26Nlnn208LrjgAl122WWNr8Mw1JYtWxqv2blzp3bt2qXe3l5JUm9vr3bs2KGBgYHGOZs3b1axWNSyZctm6GMBADB7UU8BADNlWvfQdXR06J3vfOeU59ra2jR//vzG81dccYU2bNigrq4uFYtFXX311ert7dXKlSslSRdddJGWLVumyy+/XDfffLP6+vp0/fXXa/369crn8zP0sQAAmL2opwCAmTLtTVF+mVtuuUWe52nt2rWqVqtavXq1br/99sZx3/f14IMP6sorr1Rvb6/a2tq0bt06feUrX5npoQAA4CzqKQDgzTDWWtvsQUxXuVxWqVTSB3SJAhM2ezgAMCfFNtKjekBDQ0Pch+UwaioANNex1tOj6kMHAAAAAGg+Ah0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI4i0AEAAACAowh0AAAAAOAoAh0AAAAAOIpABwAAAACOItABAAAAgKMIdAAAAADgKAIdAAAAADiKQAcAAAAAjiLQAQAAAICjCHQAAAAA4CgCHQAAAAA4ikAHAAAAAI6aVqD7/9j79zg7y/re/39f131Ya81hrcnkMJNAwkFQjAJq0DBV225JSTG1WujeyJdtqeVXKw1uEUuV1gLa7oaH9lerVun+7rZgf7uUirtoPUCNQWLVcDBC5aAUEEkgmZmc5rBmne7D9fvjXrOSSeIhx8nNvJ6Px3Jm1n2vNde6iXx457ru63PTTTfJGDPjcdZZZ3WONxoNrV27VvPnz1dPT48uueQSjYyMzHiPLVu2aM2aNerq6tKiRYt03XXXKY7jo/NpAADICWoqAOBo8A/1Ba94xSv09a9/fe8b+Hvf4n3ve5++8pWv6M4771SlUtHVV1+tiy++WN/+9rclSUmSaM2aNRocHNR3vvMdbd++Xb/1W7+lIAj053/+50fh4wAAkB/UVADAkTrkQOf7vgYHBw94fnx8XH/3d3+n22+/XW9605skSbfeeqte/vKX6/7779f555+vr33ta3riiSf09a9/XQMDA3rVq16lP/3TP9UHPvAB3XTTTQrD8KC/s9lsqtlsdn6emJg41GEDAHDCoaYCAI7UId9D99RTT2nJkiU6/fTTdfnll2vLli2SpM2bNyuKIq1atapz7llnnaVly5Zp06ZNkqRNmzbp7LPP1sDAQOec1atXa2JiQo8//vhP/J3r1q1TpVLpPJYuXXqowwYA4IRDTQUAHKlDCnQrV67UbbfdpnvuuUe33HKLnn32Wb3xjW/U5OSkhoeHFYah+vr6ZrxmYGBAw8PDkqTh4eEZhWf6+PSxn+T666/X+Ph457F169ZDGTYAACccaioA4Gg4pCWXF110Uef7c845RytXrtQpp5yiz33ucyqVSkd9cNMKhYIKhcIxe38AAI43aioA4Gg4orYFfX19eulLX6qnn35ag4ODarVaGhsbm3HOyMhI5/6AwcHBA3bomv75YPcQAAAwV1BTAQCH44gCXbVa1TPPPKPFixdrxYoVCoJAGzZs6Bx/8skntWXLFg0NDUmShoaG9Oijj2p0dLRzzvr161Uul7V8+fIjGQoAALlGTQUAHI5DWnL5B3/wB3rLW96iU045Rdu2bdONN94oz/N02WWXqVKp6Morr9S1116r/v5+lctlvec979HQ0JDOP/98SdKFF16o5cuX6x3veIc++tGPanh4WB/60Ie0du1aln8AAOYUaioA4Gg4pED3/PPP67LLLtOuXbu0cOFCveENb9D999+vhQsXSpI+/vGPy1qrSy65RM1mU6tXr9ZnPvOZzus9z9OXv/xlXXXVVRoaGlJ3d7euuOIKfeQjHzm6nwoAgBMcNRUAcDQY55yb7UEcqvHxcfX19ekNerN8BbM9HACYk2JF+pa+qrGxMVUqldkeDg4TNRUAZteR1tNDbix+Iti1a5ck6Vv66iyPBAAwOTlJoMsxaioAnBgOt57mMtD19/dLkrZs2cJ/ROxjYmJCS5cu1datW1Uul2d7OCcErsmBuCYH4poc3M+6Ls45TU5OasmSJbMwOhwt1NQD8e+EA3FNDo7rciCuyYGOdT3NZaCzNtucs1Kp8AflIMrlMtdlP1yTA3FNDsQ1Obifdl0IAPlHTf3J+HfCgbgmB8d1ORDX5EDHqp4eUdsCAAAAAMDsIdABAAAAQE7lMtAVCgXdeOON9NnZD9flQFyTA3FNDsQ1OTiuy9zAP+cDcU0OxDU5OK7LgbgmBzrW1ySXbQsAAAAAADmdoQMAAAAAEOgAAAAAILcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5FQuA92nP/1pnXrqqSoWi1q5cqUefPDB2R7SMfPNb35Tb3nLW7RkyRIZY/SFL3xhxnHnnG644QYtXrxYpVJJq1at0lNPPTXjnN27d+vyyy9XuVxWX1+frrzySlWr1eP4KY6udevW6bWvfa16e3u1aNEive1tb9OTTz4545xGo6G1a9dq/vz56unp0SWXXKKRkZEZ52zZskVr1qxRV1eXFi1apOuuu05xHB/Pj3LU3HLLLTrnnHNULpdVLpc1NDSku+++u3N8rl2Pg7n55ptljNE111zTeW4uXpebbrpJxpgZj7POOqtzfC5ek7lsLtVTiZq6P+rpwVFTfzZq6glWT13O3HHHHS4MQ/f3f//37vHHH3e/+7u/6/r6+tzIyMhsD+2Y+OpXv+r++I//2P3Lv/yLk+TuuuuuGcdvvvlmV6lU3Be+8AX3H//xH+7Xf/3X3Wmnnebq9XrnnF/91V915557rrv//vvdv//7v7szzjjDXXbZZcf5kxw9q1evdrfeeqt77LHH3COPPOLe/OY3u2XLlrlqtdo5593vfrdbunSp27Bhg/vud7/rzj//fPcLv/ALneNxHLtXvvKVbtWqVe7hhx92X/3qV92CBQvc9ddfPxsf6Yj967/+q/vKV77i/vM//9M9+eST7o/+6I9cEATusccec87NveuxvwcffNCdeuqp7pxzznHvfe97O8/Pxety4403ule84hVu+/btnceOHTs6x+fiNZmr5lo9dY6auj/q6cFRU386amrmRKqnuQt0r3vd69zatWs7PydJ4pYsWeLWrVs3i6M6PvYvPmmausHBQfexj32s89zY2JgrFArun/7pn5xzzj3xxBNOknvooYc659x9993OGONeeOGF4zb2Y2l0dNRJchs3bnTOZdcgCAJ35513ds75wQ9+4CS5TZs2Oeeyom6tdcPDw51zbrnlFlcul12z2Ty+H+AYmTdvnvvbv/3bOX89Jicn3ZlnnunWr1/vfumXfqlTfObqdbnxxhvdueeee9Bjc/WazFVzuZ46R009GOrpT0ZNzVBT9zqR6mmully2Wi1t3rxZq1at6jxnrdWqVau0adOmWRzZ7Hj22Wc1PDw843pUKhWtXLmycz02bdqkvr4+nXfeeZ1zVq1aJWutHnjggeM+5mNhfHxcktTf3y9J2rx5s6IomnFdzjrrLC1btmzGdTn77LM1MDDQOWf16tWamJjQ448/fhxHf/QlSaI77rhDU1NTGhoamvPXY+3atVqzZs2Mzy/N7T8nTz31lJYsWaLTTz9dl19+ubZs2SJpbl+TuYZ6eiBqKvX0YKipM1FTZzpR6ql/FD7LcbNz504lSTLjg0vSwMCAfvjDH87SqGbP8PCwJB30ekwfGx4e1qJFi2Yc931f/f39nXPyLE1TXXPNNXr961+vV77ylZKyzxyGofr6+macu/91Odh1mz6WR48++qiGhobUaDTU09Oju+66S8uXL9cjjzwyJ6+HJN1xxx363ve+p4ceeuiAY3P1z8nKlSt122236WUve5m2b9+uD3/4w3rjG9+oxx57bM5ek7mIenqguV5TqaczUVMPRE2d6USqp7kKdMD+1q5dq8cee0zf+ta3Znsos+5lL3uZHnnkEY2Pj+vzn/+8rrjiCm3cuHG2hzVrtm7dqve+971av369isXibA/nhHHRRRd1vj/nnHO0cuVKnXLKKfrc5z6nUqk0iyMDMJuopzNRU2eiph7oRKqnuVpyuWDBAnmed8AOMSMjIxocHJylUc2e6c/8067H4OCgRkdHZxyP41i7d+/O/TW7+uqr9eUvf1nf+MY3dPLJJ3eeHxwcVKvV0tjY2Izz978uB7tu08fyKAxDnXHGGVqxYoXWrVunc889V5/4xCfm7PXYvHmzRkdH9ZrXvEa+78v3fW3cuFGf/OQn5fu+BgYG5uR12V9fX59e+tKX6umnn56zf1bmIurpgeZyTaWeHoiaOhM19WebzXqaq0AXhqFWrFihDRs2dJ5L01QbNmzQ0NDQLI5sdpx22mkaHByccT0mJib0wAMPdK7H0NCQxsbGtHnz5s459957r9I01cqVK4/7mI8G55yuvvpq3XXXXbr33nt12mmnzTi+YsUKBUEw47o8+eST2rJly4zr8uijj84ozOvXr1e5XNby5cuPzwc5xtI0VbPZnLPX44ILLtCjjz6qRx55pPM477zzdPnll3e+n4vXZX/ValXPPPOMFi9ePGf/rMxF1NMDzcWaSj39+VFTqak/y6zW00Pd0WW23XHHHa5QKLjbbrvNPfHEE+5d73qX6+vrm7FDzIvJ5OSke/jhh93DDz/sJLm//Mu/dA8//LB77rnnnHPZFst9fX3ui1/8ovv+97/v3vrWtx50i+VXv/rV7oEHHnDf+ta33JlnnpnbLZadc+6qq65ylUrF3XfffTO2iq3Vap1z3v3ud7tly5a5e++91333u991Q0NDbmhoqHN8eqvYCy+80D3yyCPunnvucQsXLszt1rkf/OAH3caNG92zzz7rvv/977sPfvCDzhjjvva1rznn5t71+En23ZHLubl5Xd7//ve7++67zz377LPu29/+tlu1apVbsGCBGx0ddc7NzWsyV821euocNXV/1NODo6b+fOZ6TT2R6mnuAp1zzn3qU59yy5Ytc2EYute97nXu/vvvn+0hHTPf+MY3nKQDHldccYVzLttm+U/+5E/cwMCAKxQK7oILLnBPPvnkjPfYtWuXu+yyy1xPT48rl8vune98p5ucnJyFT3N0HOx6SHK33npr55x6ve5+//d/382bN891dXW53/iN33Dbt2+f8T4//vGP3UUXXeRKpZJbsGCBe//73++iKDrOn+bo+J3f+R13yimnuDAM3cKFC90FF1zQKTzOzb3r8ZPsX3zm4nW59NJL3eLFi10Yhu6kk05yl156qXv66ac7x+fiNZnL5lI9dY6auj/q6cFRU38+c72mnkj11Djn3KHN6QEAAAAATgS5uocOAAAAALAXgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcmrWAt2nP/1pnXrqqSoWi1q5cqUefPDB2RoKAAC5Rk0FgLlrVgLdP//zP+vaa6/VjTfeqO9973s699xztXr1ao2Ojs7GcAAAyC1qKgDMbcY55473L125cqVe+9rX6q//+q8lSWmaaunSpXrPe96jD37wgz/z9Wmaatu2bert7ZUx5lgPFwBwEM45TU5OasmSJbKWFfyzhZoKAPl2pPXUPwZj+qlarZY2b96s66+/vvOctVarVq3Spk2bDvqaZrOpZrPZ+fmFF17Q8uXLj/lYAQA/29atW3XyySfP9jDmJGoqALx4HG49Pe6BbufOnUqSRAMDAzOeHxgY0A9/+MODvmbdunX68Ic/fMDzb9Cb5Ss4JuMEAPx0sSJ9S19Vb2/vbA9lzqKmAkD+HWk9Pe6B7nBcf/31uvbaazs/T0xMaOnSpfIVyDcUHwCYFe0F+yzTyxdqKgCcYI6wnh73QLdgwQJ5nqeRkZEZz4+MjGhwcPCgrykUCioUCsdjeAAA5AY1FQBw3O9iD8NQK1as0IYNGzrPpWmqDRs2aGho6HgPBwCA3KKmAgBmZcnltddeqyuuuELnnXeeXve61+mv/uqvNDU1pXe+852zMRwAAHKLmgoAc9usBLpLL71UO3bs0A033KDh4WG96lWv0j333HPATd0AAOCno6YCwNw2K33ojtTExIQqlYp+WW/lBm4AmCWxi3Sfvqjx8XGVy+XZHg4OEzUVAGbXkdZTOsECAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE75sz0A4KCMOfj3h8u5g38PAAAA5BiBDieW6fBmjGSMjEz7+84J2ffToWzfbGb2Pb7PQSc5l7a/J9gBAADgxYNAhxPDPkHOGNMJdDI2e86amed1Ap2Tc2q/RjNn85xrhzkn40z2c+rkjCPYAQAA4EWBQIfZsf+SyvbPZjrEWZuFOLvP9+1wJ6kd1vY+jDGSnX6f9hRdO8BlX1MpTeXSVCZNsyDY/ipjCHUAAADIJQIdjq/pZZHtpZFmOoDtMytnrJV8T8bzJM/uE+pmBjrXDmrGuXYIbL9W06e0j6eplCRSMv01kUtdFvtSp71LMwl1AAAAyBcCHY6fzrJKO3NZZWcGrh3oPE8KfMn3ZXxf8j3JWjmbhTZJndk30555k7VyXvucaWkqk7osxMWJXBzLxHH7ayIXS0bt2To5ad+lmIQ7AAAA5ACBDsfHvjNw0/fF7T/7Nh3YPE8mCKQwkAt8KfDlfE/Ot3s3SHFOJnFycSKTpHuPTwfD6cAXpzJxIkWxTBRLrSj7PSaWJLkkO9e4NJuoc2k2szeNYAcAAIATGIEOx86+O1bKZF+slay337LKbGllJ9R5nlwhyB7FQGnoKw2tnG/lPCMnyTgnEzvZKJWJU7nAKg3ax43JjqfKjrcS2WYs24yzsGhtdo4keemM++vkzD732LmZO2oCAAAAJxgCHY6+/VsPTN8nN32Pm+93llUa3+8sr3T7zNilxUBpKVDS5SsuWiVFqzQwSr3srbKw5uS1nGzklBSMksDI+UbOZsdNInktJ6+Zyq/58hqxbHsWz5h28Jtesrnv/XXGZLN7Sg/e7gAAAAA4QRDocHTtf59ce3fKGTtWBr4UBDJhmC2nLGRLK51v5XxPskZpaBV3+4p6PEVdRnHRKClIzmsvuUynw1r2dfp4GuztQ2djJ69h5DeMgoJRMGXlWyMvG6CM72VhLk7kkkQmjqU4keI4C3aSTOr2troj1AEAAOAEQ6DD0bP/fXLTM3LevjtWtmfmwkCuWMiWVBYDpQVPaegpDYycZ5R6RlG3VatsFPUYxV1OSVFK/bQ9Q2dkm5JfN/KaRnFJiktOLnBynpNSyUZGft3IrxnFBaMktCq090yxnpVJsuWaipPO/XUuirIlmVEko+lQl8qJmToAAACceAh0ODr2D3Oe7dwfN71TpfH97H4535MrhEq7C0pKgZIuT3HJU1I0SkLTvg9OiotSq8+oVXZKehOplMqGiWSkNDZKGp7imievbpR0p3JdqUwhkfGcXGoUN62Smqe4apV6RrKSSb1sdq/gycROJk5km4lMK5bxPZnm3vvrnCSj9gzddD87etYBAADgBEKgw5E7WJjz/WxppR9kX6d3rPS9bEfKgq+4J1TU215W2Z3NsiUFo9SXZCTnSa15qdK+WKVKQ71ddXWHLVnj1Ep8jdeLmqoWFU8F8ntbKvfW1VtoKPBSRYnVVKug8WpJ0XhBzvOz8aXZxilKnWwsea1Ufj2V10hk676s7+3td2emQ12s6V51nY1SJIIdAAAAZh2BDkfJQcJcEMgUCnJhILV3rUxDTy7wlAZWUa+vZrm9rLLXKOpySkpOzneSlZRKrhKru7+mk/vGdFLXmPrCunyTqJYUtL1e1gthRWNhlxZUqlrWu0cLw6qKXqRm6mtXq1tbwnka8cpqJF2KIk82Noq6jEzq5LUkr2nl11MFNSvfM/KNkXXZLppyLruHbp9ed0bthuYuZbYOAAAAs45AhyMzPTNn9wtzYZiFuVIoVyxkO1aWfCVFq6SQ7VgZF42aFaPmPKOokirtTWS7YgVhLGOlNDHyg0Qn9Y3pFZXtOqM0qgF/XL5JNJGW9Gy4UCUv0la/T2dUdurl3dt1UrhbXaalhgu0PepTlxfJGOn5lqe4WVTqZzfR2USyLcmrGwVVq6RgFHrZJi6+JDsd5pI061FnTHsHzKxZuXOiCTkAAABmHYEOh2ef1gRmn1BnfK89MxfKFUO5rqKS7lBRj6+421NUMtm9ckG2I2XUK7X6U2lepJ5KXfO6p9QTtuTbVM3EUyMOdFLXuF5SGtXy4jYNejUFchp3vkITq5X6ip3VaaWdOqu4Xaf4Y+q2qWqpVZ+tq5EGmoiK2tXVrcmKr7QiyTglsZUaVrZmlbYDpjOScb5Mmt1bpziRSZLseRvLxTb7OUlkEu3dKEUi1AEAAGBWEOjw85nRJFydENd+stMQXL4vEwRyhVCuq9C+Ty5Qq+yp1Wuye+W6pDR0Sn2ntOCkvkiV/qqW9e3RKd27NT+oKjCJamlBI81elYOGBvxxDXo1LfE8+caqK4004U9oW1DVjqBHC4MJDXqTWuxJ3TZU3caKVdWiYEJ9YV3dxaa8BalKQZTdgxd7qtaLalRDNYNQqWeynTNjKxt5ss1AXpTIOZeF1FYkebEUxZIxcooJdQCAXLOe06KTWgc9tuOFUEliDnoMwInFHuoLvvnNb+otb3mLlixZImOMvvCFL8w47pzTDTfcoMWLF6tUKmnVqlV66qmnZpyze/duXX755SqXy+rr69OVV16parV6RB8Ex8g+G57I2mwWzma7V07vYGl8T2Z6V0s/yDZAKYZKurIw1+zz1Jhn1Jhv1Fjo1BhI1FocK17SUrogUqnc0EmVMb28vF0ren6sld3P6PzuZ/Ta7h/pFT3bVPHr8k2qQE6+sfJlFcgoUCrfJPJN2n44BcbIl9c+x8k3qTyTqL9U09kLt+m8hVt03sLndO7CF/SShTvUv2BSmt9S1Oey+/h6TLbjZslT0lOQ6y3JdZfkukoyxWK2lHS6Ibpns/sGNTPsAsDPg3qK2VKZH+nid+3Qf792WLdt+oE+e5DH5dcO6+J37dDF79qhV71hcraHDOCnOOQZuqmpKZ177rn6nd/5HV188cUHHP/oRz+qT37yk/rsZz+r0047TX/yJ3+i1atX64knnlCxWJQkXX755dq+fbvWr1+vKIr0zne+U+9617t0++23H/knwtEzHVCslZmehTNmRpPwvbtbmnbA8+TCrFl4UvIUdVtFPUatPqPmvFRpX6Kg3FSp1FIxyO5vs8ZpsDShUwu7dGY4qsV+Q6GkSTclK6cnGks0kZY0lvoqpS0FMhpPncbToiaToqaSUBNJSeNpqLG0psg0VXOpxtOiJpKSGkmgl/Ts1KnFnVoUTMhTqvGkS8+F81XwYkWJp4mWVTQVZD3rSkY28pWGnryGL9uIZX2vHeCULcFsXyKnOGtxkE7/DwD8fKinOF78IFWxO6tRb/5/dusX3zKmM8+t/dTXXP6+kc73u4YD/eiJkv7imqWqTniKW4c8HwDgGDrkQHfRRRfpoosuOugx55z+6q/+Sh/60If01re+VZL0D//wDxoYGNAXvvAFvf3tb9cPfvAD3XPPPXrooYd03nnnSZI+9alP6c1vfrP+4i/+QkuWLDmCj4OjZt9WBNZKxsp4003C2w3C9w11NuvdpsCXCwKlRV9xl6eoJ9vFstXnlM7PdqxcUhnXQGlS5aAhI6daEqovqGuBP6mFXlOLbKDQeCqlLY35VZW9hra2+hWaWBPphAKTaCIt6pnWIm1t9Guk3qstwXyVvbqabu+mKC9EfXquMV+BTXVW13adVdiuAa8m3ziNpaF6vIYSZ7Wn2aVaraCk5CsuGrXKRnHBl9908utWfs1TEHiyvpWd7lHnJOMkpU4udTLGsOISwCGhnuJ48INUv3fTNq15xy5J7bJtD61gzR+MNH8g0u3fe0Jf/cf5euKhLj31/S5tfbp4LIYM4BAd1Xvonn32WQ0PD2vVqlWd5yqVilauXKlNmzbp7W9/uzZt2qS+vr5O8ZGkVatWyVqrBx54QL/xG79xwPs2m001m83OzxMTE0dz2Njf/mHOtpdUthuEy/c7TcOzULf3fjrnWcm3SsJsN8u4JMVdUtKTqFhpaEllXGdVRnRKcZcW+JMyctqd9GgiKcpJ7Yfb+9Vlz21t9GsqKWhBMClfqappUVsb8/Rsdb5GJnsV2FSS065Cj0q2pUYaaLRV1vONeVpcHNegP67Ffk1LPCNPVl2mqUl/XNvDPpXDhsIwVi10irud0tBkLQ3qRsGUURBmTcl9I5nUSWl7p8s0ydoZpOnepuMS99IBOGLHqp5K1NS5wg9SvfZNk1r99t06/1fGZY50Us1Inu/0lit26i1XSD96vKT/+E6P/t+PLFHKvXbArDqqgW54eFiSNDAwMOP5gYGBzrHh4WEtWrRo5iB8X/39/Z1z9rdu3Tp9+MMfPppDxU+y7xLK9kYn2X1yvhRkG54oDOR8Xwo8OT+bpXPTm6U41+kzl4RGScEo7nIy3bHm9dR0as8uvaL7BZ0ZjmiRV5eR0660qKdaizSWdGtHUpSvhkITa9JZ7Uh6tDvu1ki9Vz+amK/esCnPpGokgXbVu7V7sluNqVBR7GuiVdSzhQUq2Fit1NNEqyjfpjqltEsFG6tkUhVMQZ6sSiZR0cQKTSzfJrLWSaVEUSGVEiPTsPJqRsmEUVKwctaoYNr961Ink6RSkmRfvUTOpTLOymVrL2f3nyGA3DtW9VSipr7YdfUmevlrpvR7N23T4lNbCgvH5naA019R16kvb6inkuhr/9yv72/q1t4bEgAcT7nY5fL666/Xtdde2/l5YmJCS5cuncURvUjtu5Pl9MzcdJgL260IwlAqBEoLvlzoKw2sXLt/m9pLEI1zcp6R86XUl1zg5IWJegtNLQintMQf08n+lAa87N68UlLXlD+mHzSW6KnWIk344wpNosm0oGdbC7NllbVe7Zrslu+lssYpjj01G4HSKV9mylO1ZdWoBxot9sqzqZLUKE48LZk3rkYaaCotqJpaTZmWPGM06Zyqaah6GqqV+PL9RH2LJiUjRZGnRiNUPJkFV2eNTKJsB8yWL9tK5FqBTBTLefHeZacAkAPU1Bej7C8SjZF+78Zt+tX/Z9dx+a3WOv3Kf9utN/7amNZ/rl9f/of5+vEPiyLYAcfXUQ10g4ODkqSRkREtXry48/zIyIhe9apXdc4ZHR2d8bo4jrV79+7O6/dXKBRUKBSO5lDxk9j2zo3Wy3ZznNEkvCBXCpSUAiVFX0nJUxqYrIebleQkk0o2ytZJOiPJZl+t5xTYRAUbqWgjlYxTyQQykkq2qZKJFMvq4eoy9QV1BSZWLSloW6OiLdV52jXeo+bukpqxsjqRGNmmUVAz8htG8VSgpMtXLXSSzX65KyaaKBU10ijrucJ8FU1LU64qX6nG0m49Fy3QtmafYmd1+rxdnXv6puJQO+o9Gi32asrrUtP4MrGVja28ZrZRimn6Mk1P8j2ZqD1LadNscMls/gME8GJwrOqpRE19MTr5JU195B+eVaGYqn9RfNx/f7Er1Vt+e6eGVo/rA5e+RM9zbx1wXB3VQHfaaadpcHBQGzZs6BSciYkJPfDAA7rqqqskSUNDQxobG9PmzZu1YsUKSdK9996rNE21cuXKozkcHApjJJlsN0tj9rYhmG4SXioo7S4o6Q6yJuFdnuIuo7hglAaS8yQ5ySaSbUle00kyUpqFvDQxaiWeGmmgWhpqyhnVXEtGRlOpVHOh6kmoH0/NV5R68kyqZuJrrFHS+GRJrT1F+Xs8ebX20s5E2X1uTSev6RRPZQ3L00ByVnLWKZonTU6WtDXsU8nP7qtb6E/KM6kmkpKea8zX9kZFJ3eNaVlxtxYEk7JyGku6tKU4XwU/1o9Tq0ZcUlwziuvKfkfBkws8Od+TsVauM0PH30gCODqop/h5FEqp/utVo/qlt47ppNOaP/sFx9iCxZFu+vsfa91Vp+iZx0uzPRxgzjjkQFetVvX00093fn722Wf1yCOPqL+/X8uWLdM111yjP/uzP9OZZ57Z2WZ5yZIletvb3iZJevnLX65f/dVf1e/+7u/qb/7mbxRFka6++mq9/e1vZ0eu2WaU7Vbp7dMkPAzligWlXWG7SbivVsVT1D3ds63dJNzLXm5iyWsa+TUjv+5kY8lERknT10SzqNFmr54v9KtoItXdlIykXUmPtkb9Gm5WtLPWrV2T3ZIzShKruO5LNU/+hCe/amQTSalk4yzM+Q3JrzsFU05JkC3zdJ4UlYycbxUVChoxZaXOaHezW+WgIc+kmopDTUZFLSxWdVb3dp1ZGNGAV5WV0+60pB7bUOKMJppFDdcDJSVfSdEoCdszkr6VvPaGMNObwpDnABwC6ikOl+c7/fpv79RF/32Xlp3ZOKFW/S89o6Gbbn1W1192up5/hpk64Hg45ED33e9+V//lv/yXzs/T6/CvuOIK3XbbbfrDP/xDTU1N6V3vepfGxsb0hje8Qffcc0+nZ44k/eM//qOuvvpqXXDBBbLW6pJLLtEnP/nJo/BxcPhMttRyuoG4ny25dGEgVwyUdIeKyr6aFU/Nvmxr/6jslHSlUjGV/PZN15HNNhSZtAomTTtwGTWnPI1NdunHYb+KXqxqUtB8vyojpz1Jt7Y05uvZ6nztrnaruaskU/dkUslrZfevyUqtealklQW6yMirG/k1KfSkcNKpOJVks4GBkenL7u1z1lOUlDQcedpd6lYhzHrfpanRwp6qFhUmdUq4S6f7Yxr0smzWl0wocp52xb16rtivXcUetQqp0sBT6hulvsnuGzQze/FlM5xsiQLg50M9xeFYft6UzvsvE7r8mpET9i8SF53c0p/9nx/pz951qp5+tGu2hwO86Bnn8rfH+sTEhCqVin5Zb5VvgtkezovD9L1zfnbfnCkWZEpFue6SknJJUSVUoz9QY55Rc75Rqy9VOi9W2NNSV6mp0I/lZNRoBarXQ8XjobxxX+GeLJA1+52SBZFK/XUNVia0qFRVOWhIxqkaFTVa79HIRFnV3V2yu3yFY1ayUtzlFHenUnciW0hkrJNLjdKWJ0158qtW4ZhROO5U3JMqnEhknNSseGqVrZp9RlGPU9zjlBZTKcjusQt6WzpjcIdWzHtOb+h5SmeF4xr0CrIy2p029cOopO/WTtO3d79ET44OqPZCj4ojnrqGnbp2JCrsasrfU5Op1uVqdblWS67ZkpJELjn+9y8AsyF2ke7TFzU+Pq5yuTzbw8FhoqbmQ6GU6A8/tUVnnl3XwNLWbA/n5/IPHxvU7Z8YkEtP0OQJnCCOtJ7mYpdLHAfTzcH3W3LpQr/TJLzVaxSVjVrzUqX9kSrzq1rcO6mB0oS6/aacjMajkoZrvRoOK6r5JUVpoHC3UThu1DKB6onRlmag0VKvCkEsI6dm5Ld3lQxlx3yFY0Y2lprznJL5sYJKU5WeunoLDQVeojj1NNksaLxaUmu8IOcFkjGyiZWNnArjsQpjTibJNjPx61I8lfXGS4N2uOuKFaVWLeer4QI1nFHDxfJk1HBOzTRQM/UVpZ5SZ2Ta3QiMU9ZnrvP3IO3uefn7exEAQE7MH4z0Bx/folf/4uQJtbzyZ/nv147oG3fN07YfswkPcCwR6DCzXYHJlhIaa+U8Kxd4SkKruGiVFKWo2yntTdRdqWtZZUxn9o5qWXGX5nk1pTLaEffqx8F8SUYvJFbNuiev5ikcl4wzimJfcd3TVDHUVNBephlnfd/8qWyZpm1JrT6npJKoOK+uRX2TOqV3txaGVRW9SI000K5mt54L+zVie1VPjKLIl9cw8us2e0zFKqSSjT3FDat4SkpDKeo2SgpS2vJUbRW0u9Wt4biism0ocTVZk2p3UtT2uKKdUY8mWwVFTV8mykKmiZ1Mkm30otRlj07Am26JDgDA0VEopbruE1v06jdOzvZQDpn1XK4CKJBXBDrM1J6pm24q7nzbbhIuxUWjpJTK6440v3dKp/fubDcJH1W/bSiR0UjSrS7bVD0JNdUKNVINlZSs3KRRUHVSamRb7Y1FPC/bGTOa3khFsi2nqGwU9zp5lZYG+ib1sr4Rvbx7u04OdqvLtlRPA20rzFOX35KR09aW3w5tXjbGopVM1j/ORk5hnCioGcVFI+fZ7J6+mqexapeeC/vV5bVUS0Mt9PfucvnjxgL9qLpAu6o9Smq+grqR18h21rRRKhMnUpJKabo31AEAcBT1D0S67hNb9Ko35C/MTTtteV0vPMsMHXAsEejmuukZuelt96dn6dq7Nzpr5DzJ+e2WAIFTWIhVDhtaFEzoJH+Plvo19VtPqaTAVFVNC3ourKq30NTOMFEaOiVFo6jXKCk5JQWXbW7iss1NFGVtCGzkZJyUFCRXTFUstbSoa1KnlHbpZYXtWuZPqNumqqVWvV5D9TTUWFeXdnb1aLIYKinY9iycVavXyplsiWTW4sDJRk5eXfJrUjzpqVEsaputSJLGoi5VgrqsnCaTgobrZW2fKGtqvCgz4Xd27fSaqbxWKhOlMkkil6Z7Z+gIdQCAo8Kp1JPNzL3mF/Mb5iTpnR/crm99pW+2hwG8qBHo5rLO8sr2zpZettRyRk+1dsBz7aeclax1Cr0kaxBuI3UZo5IJlMqpy2RNwgs2lm+zTUxS215C2ZPIdCfyirE8L1WaGiUtT62ar3jSUxpa+TUp9Z0UpCqEsSpBXQv9SQ14U1rsS92moJqNFGtKC4MJVcK6imGkyTCV86WkYFRfsLcfnUmnWylkLQ68plMwme2E2fR8TSXdei7ytLPUo2IYyZjsnr6pekGNakFmT6BwzCqccAqrTkEtlW3EMlEsxXG2CUqayO27/BIAgMMUhKne/j9Gtfrtu7RwcXRMfkezYbVtn1mzwWVNlbrTY/K7ABx7BLq5qh3U9oY5XwrajcSDIOuxZkxn5sm4djhqNwlvJp7qadhuEl5TwUVK5TTlrGouVCMNFCWeXJrN8CXzYoXzGurrqatSrKvgxYqdVbVV0J5ql6YKJTW9QJJtN7STjJw84+SZVL5J5cvIk5UvK09p52Ha9605I7V6paTolIZOzpsOdEZeXQqmjIJJyW9IbsxJzipqGbUaXWoVizJBmoXW2EgNT96UVTBhsjA34RRUE3m1WLYRS81IihMpaS+9dO1CSJ4DABw2p0uvHtV/v3b4mP2Gh+4ta9PXyvrKPyzoPPcr/3W3Fp/S1OvfPK5Tz2ocs98N4Ngg0M1F02Gu3UfNeFnPOQW+TCGUCqFcV0FpMZDzbTsUOdnYyERGUdPXeLOkkVZZW4OsSfiE11Aqq5G4R8+35mlHs0eTzaKSlicXpir2N3TSvDEt692jxYUxdXkttVJfu6Nu/bgwX897fRp33YpaoWwkKTaKEk9TcajxpKQ9aVHldEpN01DNOY2lJY0nXZpKCmrFvpRYpYEU9ybS9Cxgu8VBEnlKpjwlVS+7d28sa0Ruk+zevbjmKSlYOV9ZkIwl2zLy61JQdQqqToWJRMFkLK8WyTRaMq1ILorkkiS7j845OdfeChMAgEN0+ivqev9fbtEpL20e1fdNU6PdI74+9+lFeuzBbu3cFmp898z//Ft/Z78k6d/+eb7OOb+q3/7gds1bFMvzqGlAHhDo5qy9O1rK87IwF4ZypYJcqaC0p6C4y1fc7Svqypp025bk14xaU4F2T3brmcKC9j1nRfX5NaUu2+VyS32+nqv2a3yqpDQ18nsjLaxM6szKqF7evV2nhjvVY5tqOU/DcUVdXkvOKWtfUPNld1upYVWvFzRS79WWwnz12oYaaXtTFBdoWzRPzzXna6Teq1o9lGsZJZVYhb6myj01VYoNhV6iOM1mAceqXaoXi2p6viQrm0rhuJNfc4pL2RLN1DPZZUmcvMhlyzNrTn4tbYe5luxUU6bRkmtFUhRLcSKXtDdGAQDgMBjj9Iu/NqYzzq4ftfesTXra8H/nqVG3+vs/X6w0kX5WJ/KRraHWb52n9Z+fp6v//AW95YqdR208AI4dAt1c074/zhjtvW/O9yU/yGbmiqHSrlBRT6Co11Or1yrqMYpLRkmxfV9a1VMtKOp5r09R4mlnq1s9fkupM5qMC9rV7FYr9dRdakpy8jynBaUpLS3u1ksKozoj2KMe49R0Rr22qVpa0M5Wj0ZLvWoUi3KelVeziqrtfnVe1rR8Z9irkm2pkQYabZX1dHWhhifLak2FkicV5zU0OG9cy3r3aKAwoZIXZbOArW49F87TNq9P1bRLUSto76rpFE6kCmpS6hs5Lyt0JnWykWRbqfxGKq8ey9Yj2XpLptGUa7Wk9uycS9qzc2JjFADAofM8p//6+6P6r78/esTv1WpYbX26oL/7n4vVbFg99kC3flaIO5CRnPR3f7ZYvu+0+u27ZZmpA05oBLq5aN/NUNoNxE0YyBVCpV0Fxb2hWhVfzYpVq2LUKjvFPanSUiqF2X1miq3G93SrVi9opFRWqdhSV9DSwmJVp/bsUmgS1dNAOxq92t0oqTdoaL4/pYVeVYs8ox5TUMvFitXQAn9SlaCuUhDJ+KmcJwWTRs73Ne51K0qsJlpFVQrzVbCJWqmniWZRO6s9mhovytV9eZWWFvZN6mV9ozqre7tOCXep2zTVdL6G44q6/aZkpOciT826p7jmKS4ZeS2joJoqqKYy7U1NTCqZJNvJ0rYSmWYs02wvs2y0pKglF8VycSylSbbUMuVmcgDAoXvtBRO64g+Hjyg0PfHdbu3cHuhr/9yv7/17r5LoyJu/1ac8ffKDJytqGv36O3ceei4EcNwQ6Oai6U0sp++f8z25wJcr+EpLvuKubGauVTZqznOK+lKZcqRSd0uFMJK1TnFiVW+EihqBpozUW2poWfcendk9qkXBhEITayotaGvYr2e8hbLGdX71wb7uz2tK4bhVywSqRVYv1EPtKPTIek5pmt3HF08FMpO+TCFVoRhpYamqZcXdOjMc0enBmHpsqoYzKtuGamlBu1td2lHqUbNYVFLIZh6dsUr9LNSFk7G8epwFuCSViVMpau9oGUVy+35t73A5ff+cJGbnAACHyMn33SGHOeeyDcru+NQivfCjgr6/qUc7toVHfXRpYvS3/3OJCl2pLrx0N03CgRMUgW4OMqbdONzabDdL35dCX2nBV1zy1OqxavVmrQai/kTB/Ibm91W1uHtCfWFdgU1UTwLtbPRoeLJXTkYn9+7RWT3DOrv0vBZ7kyqYRFUXaJ43JWOcttb7tTvp1o6kWxU7prppqumkHUlRu+IeTcRF1aNALrZ72wxMSTayimpGSZenelDY27+uZRTUs8oSdTuFYaRy0NCCYFKL/KoGPanHFtRwsRLVtcifUF97FnCskCiqZA3T/apRUpDSwJOMFDonv5XI1LMZOUWxXJy0A1z7+yTpbIbi6EEHADhMhZLT//jo8z/3+bVJT08/WtLu0UCf+qOTVJ/0lCTHNmU161af+uDJGji5pVe9oXpMfxeAw0Ogm3Om76GbbiCehTrne3JhtttjUjSKu4yinlRepaUFfVWd0bdDZ3Tt0MJgQgUbayopaGuhX0V/oXbVuzU/rGlxMKaT/XEt8VIVjaeqa6rlxrQjLuuF+jxtrferxzaVONveFCVbDvlcY4GG62VN1QtZu4BWNkMX1LJ72fyaFBezXSxlJaWSjbNHq+zaLQ6ym8qNnKycrJGMjKyMbLu1gTGS76XqqdTVLMZqVQOlxSBroi4jE1vZyJdtpTLNQGZ6WWWrvZvlPkGOMAcAOFK/8t92q6ec/OwTnbTxS336zt0V3ffFecd+YPuJWlZ33z5fZ58/Jc+n5gEnGgLdnLW3B52slXyr1LdKQqO4ICUlJ9edqqunqZN7x/Sy7hG9svS8FvsTKphU1TRQn1+TkZQ6q0KnyXiqbuMrNL5SOZVMpKJtyZpUz1QXqJX6Gi32qsu21HJZ24Jnq/P1wnhF9YmCvKqVXzPyGqnCiVT+lJQUrZLQZRuXtJuF20SKi1LUZbIWB7Gnqbigsbhbu5Mu7bQTatqm6s5pV1LUWNKt1Bm9pLxTzW5fe1pdGu4qazzsUssVJJfdT+e1rLyGJ9vw5Vq+jO/LuSwMOknGKQty009IolUBAOBwrFw18RMDUhIbPf+jgqKm0c1rT9HO4UD1qnecR7jXxi/2yXpOV//PF9T984RQAMcNgW4umr6Hrj1T56yRs1lrAue3t/APJIWJeopNLSxUdXK4W6cEYzrJS1QwVpNpXbF2a1ehR9ubZTXTQLU0UM1ZTblYiZym0kQ1V1AjDdVMAu2a6tZ4vajnS5WssXjqqdoqaPdUl6bGSjJjgYJJk/V+qzv5tUQ2SpWE2fJI50vOGBnn5IyRm5/N5pmGVaMeake9R1sK/erxGopl1W1baqa+tscVVdOCziiNqGQj1dNQ21sVdfmL9GPTr12xVRwFimpWft0oKXryA08Kfbm0kN1j2IpkbCyZqN18PJZR2u4nbiQ5ch0A4Kj4wXe7df/6su7460WSOzFuXHPO6N7/2684MvqDv9qqQpHNwIATBYFuTmoXh+lll9NrFq3J6oYxctbJeE6+TVS0kbpsS90mUbf1FcpXalvqMtnzvkm1s9mtbYV5mu9NKXLte+jSorZG87S9VdGeZknVqaKihq89hW5ZL2v6Hbc8pTVfdtJTMGYVjmeNvP2prF2AN9WS51u5wJOzphNE425fXtPKa2S98bIWBz0qeAsVO6udhd6sebnzZOV0amGnTvL3qMvEqrlAC/xsyUoz8VWtFdWc8pUUpaRglAZZqJMryPqe1IxkPE+yrWyWrn0V94a66dk6Eh0A4PDVJj09/0xBf/Z7p2jn9qO/ycnR8M1/7ZMfOL335udV7CbUAScCAt2c5PZ+dU6d2aXUybR/NE5yqVGSWjVTX/U0UN1Z1dJEqXGqu0QNV1AjDdRIAg3Xyip6g0pkta29y2UtLWhrsz/rF1ctq1UNZff4ik3WN06pZGKjsC75U0bBpFNh0ikcTxRUI9l6JFNrZmPybHavmzFZuPOM/JpVUPSUTBilga+a7dJzqdVEs6itxXkqeLEWFas6t2erTgt2aZnfVJfxNOVq8pVoT6Fbw8Wyni/2qVkoKA2tUl+KS1YygbySJ6/my2v4sjVPxpq9Sy+lrP/c9OpL127nwP10AIDDsGc00Mfeu1Tf+2av3AkyK3dwRvf+33k68+y6Ln7XjtkeDAAR6OYmN/1w2f1h6fRDMomTjZ1MJLmW1VSzoN2tbg1HfXrBn1SqavseulAvxBWNRGWNtUraPdWlKPE0FYfZTpgmUSMNtKO9E+bEWJfMhK9g3MprZQ3K1b4Xzms4+Y1sZi6oJgqqsbypdiPvZkuKk70buFgrdRVkG7H8mqcwNErCbLloS4EaidFILdDuUrfm9U5pSWlcXbapHhOpx/gqmUBWkXpsrG7bVMmL5HupZLMxJUWjxjzJa3ryG1ZBaBVMWfkm249F7evlnOtsjiJnplPdrP5jBQDky//vLwb1r7cukCRVxz39YHP3LI/o52X01X+cr9dfNK6Bpa3ZHgww5xHo5iwnlzqZ6VASJ7JRIq/ly2tKft0ornmamipqa6lPJS9SIqPt+/SY29Kcr6erizQy2avqWJdqtqjxqZKK+/Wqa06FMmOBwj1GhTGnYFLZKk/nshYFkctCXT2RX4tla5FsrSnTaMk1mlnLAGWhyQS+5FlZ31MQ2HYQM7KJZCOjqO4r7vbU7PcUlRpqpb5azlfDeWq4WFZGDZeo6QI1na9W6ittL5lMSk71QLItyW8Y+VNGScEoCY0KVgqMkW0HOqWpTLq3dYFhs0sAwCH6z//omu0hHLatTxX14StP1We+9p+zPRRgziPQzUntmbnpWaZ2E20TpfKaqfxGttOkXzWKiqF2+L0ykmpJoL5gbx+60UavtlfLGh/vkhn35WKjWjVQLWwvP0yN1LDyalm/t3BcCiedCmOJTJKFIJM42cjJthLZZiLbiGQakUyjKdds7W3k7Vw2O2eU9YfzrKxn5RuTbZSSWJnYymtKTWfU7LFqtAKNRSWNRmVtD3rlm3F1mVhTztP2uFej7dnFRuTLFBJpUaI0tUqaVvGUJ79oso1irJVNfZnEKYgCuSiRiZOsJ52XZg3GDbN0AIC5ZXhLQd/8Up/e+GtjP7Hp+L/874XHd1DAHESgm3P2LrOcDnOKYymKZJu+vLqvYMoqLpisTYDnqelK2tbytGeqpFIhkmecosSq1iioUQ2l8UDBHiuvbtr3oTlpur1Ay8hrSMFUtqQynEwVTkSyzaQ9BsnESRYoW3G7mXckN/01iqU4zsbseVmjb9PM9nBRe5YvddnMYstTw3mKS0amZlWfKuiFakUlryVrnHYGvSrZluppqBdafXpqapFGar0qFSLN75mSb1NFqafJRkHVaknRWChnPTljZCMjE7d71LUSmSiWIk8mzpaBujTV3u1SAAB48Zua8PQX712mODJ602/sOWgZfOTfe4//wIA5hkA3V+1zD5hL2gGlGcmr+/IDqzA0cp7NljnGnuJGUdWuQNXAyVgnlxipaWVrVsGkVTiehbbUU7u9QDvQRU5ey8mvOwVTqfypWP5UJFtrtX9/e/liJ1i2m3lHsVySZN8nWb8bJ2XjMZJT9lXOyUtTmTiU80L5JSu/pvbsYqCdYVZImmmgreE8FW2sRuprV7Nbw7WyAi/Rqb271R9OKbRx+76/Xm0t9GmH7VWUlmRjK79h5DWt/KInr+7LBZ6M52XXyLavU3u2kFk6AMBc0WxY/b8fWaL/8rY9P3GWDsCxRaCbi1In2eweOsWJjBdLrWxrflv35NusN51xkk2sbEuKa1ZJ0cwMa/vMvoWTWWCTlC1TnD4nzpZUeo1EXiORrbc3O2m0sgDXDnRuerYwSeSSRIqT7Lnp+9TU3nlTsdT5Xu1ZPidrjLy6J7/mKSh4SgrZ7GLLFDUSWVXrBXUVWvK9VHFi1YgDzSvVdGZ5h87qGtZgMKaijTSVFvR8oV9FP5JzRsMtT3GjoLhqFReltJD1xLOe1w5ytr3csr3LCwAAc8z4Ll//8BeDuuIPhw94PopIecCxRqCba5zLGmO7bEOULDxZycYytiVjrTxJMpJNAtnIk9ew7R5tUuqpfX9cezOTluTX02z2rZbIxC7bwbI9U5XdI5fKRIlMM1tSaZqtzpJKpa4zW+imN2hJU7kkbe/CmXZmvJxSmWSfUKfsuLFGamYzZ0HoKQ2MnG8lZ2TSbHZxohpoIkyz2UUrlSs1Le6e0EtKO/SK0gta4k2qZFJNOU9lW1fkPE20ihrr6lK9FCgpWqUFZctQAyvnWRm7t5UCAABzVZoYbd7Yq1/5b3u05NRm5/k7P7NIo8+fmP30gBcTAt2cNd1/rr2pRxxls2rWSHLynGTiVDYK5DU8JQWbBSVPB5l9S+XXY9lGLNNKspAzLZleTjl931mchbk4losjKZkeh2sHunbAa7dUkEv3G/U+oc45GWPl2rOLxvfl+7YdKH2ZxMrGRnHNKCkZpYGUBk5ufqRSGKkvqGtRMKFBr6olvlQyoabSSA03qW3+pCphQ4UwUj1wSv1sOWnqZbOXmn60l1rKKFtuCQDAHPTkw9360//PqVp3xzPqWxArjowadTvbwwLmBALdXDQ945WmWS/s+MBljCZ1MlF758m6Jxd4Sv1sRsoZtXeozHbGtNOzb80oC23S3h0fp0PaPkspFWf3xylpL6ts98SbbnKeBTlpb+jcf/jtcUtSHMt4Vmpms4vWSIGbXhLqyWtmS0XjQrvH3MIskFrj5JtEgUkUmlShPAXyFJhEgUnlm0S+SWRtu8u60d7HvghxAABIkn70RFF/fPnp+qNbntP4bl9f+uz82R4SMCcQ6OYy1+5FpzTbgl/TOay9UUk7fHlNX8735Pk2m4VqB7rsnH1n39q7UnbeX9kM2/SOmtNLPJOks6Qyuz/OdcYzY0OR/TcX2f+Yy4KiojjbJKXd1sBK8lMnG/nymp6SolXUZdWwymb3EqMo8VRLQk0mRU2kgSZMS5FNVU1TTaZdqqZF1ZNAUexJiZFJspBo0qzdwr4h1HXGxWYoAIC5zOjpR7v0P999iopdafY3qACOOQLdXOVcZxbNpZJRIhe3Z8PayySz3Sb9bDnjPrs5/uTZtzibgevcp6e9wWvfzU/aSynd9PM6hK7cnfdOZdK9O19OM+0dM7PZRV+2Hijp8uVsKC8ysq2sN161XtBIo1dbwvkqe3XV/DEVbaypNNSWaL62Nvq1o96rRiOUaVrZlsn65cXZzOTeHTqnQ53IcwAASHrmsfw2TAfyiEA3l7XD0fStdEZpdm9aatthpd1Ae98wZ232kk5QSzv97Fzabj3QCTbtpZ37hjpp70Yn0yHukLf5d+0x751dNJ0jrr0ZSyrFvmzi5HwjG6XyWlZeQ7J1q2Y11PZSWQUvm1EcDcsqmEi1NNT21jw9M7VAI9UeRdVAXi1rWO41pzd4ad8X6KYfpDkAAADMDgLdXNcJdU4uzVoVyLSXESZG8pIZM3PGmPbtbS4LT/vvUnmwoNb5Md3v+cMMQfvcXzdzdnFvTzuXJDJpIHmebNOX30jl11IFVaukaNUKAu32ehUnniaaRZULDYU2UTPxtafRpR3VHlXHSrJjvoJJo2Aq66XnNRKZKJGiJGuzMOMzE+oAAABwfBHoMHP5pbI176b9nEvTLMi1d67s7OTYDlV7l1VOb26S7nNPmX76PXFHLJWc3Wd2UXsblTsnZ61MFMu0Ynn1WEHBKikYpaGRs1aRQo21rKbqBRXCWNamShKrZjNQXA1kJnwFY1bhhFNQdfJr7V56zVgmjrP7DvdZfun2DbMAAADAcUCgQ2ZGEHFybm9/NWPN3u4B+wW66e/d9AzVvhuEHOtskyU4SWbm7KKc5FmZuN0w3fdk61lLg9A3clYyqZGNPcU1q3jSVxS4bDeVVDJNK79uFFSNwgmXPSYTBVNZY3S1IimKpSSWS9OsQTuzcwAAAJgFBDrMtH8gM9mukD//62ZD+546pTJZQ7hscxabyEVRtqmJ78mf7h3nfNnYyrakeMooKXpKfUm23e4gkryG5NecwqpTUE0UTsTyqi2ZekumGclFUbsFQ7J3p0tm5wAAAHCcEejw0+07E3ei2meMTtlOl86YTo8617RZjzq1/8B3WhpYxUWjpLBPw3Qn2TjbAMVvOPlTifxaLG8qkq01ZZotuVYra5UQx3Jpsvc+OgAAAOA4I9DhxcNNTym6ve0Uori9FFMyzsmmTkGcymsm8uu+ktC276kznSWXNnGyrVS2lcqrx9k9c/WWTKMl12xKrVYW5tq99KZ31iTUAQAA4Hgj0OFFxs3YJMUobveqy46adjNyLwpkmr4835MLbBbo2i0cTOJk4iRrUdCMpFYs02rJtaIszEVx1p4hTbJNY9L0Jw8HAAAAOIYIdHhxmdF43LVDXTaLZlKXtTOIE6kVywae5HmS1w50MjLTrRiSVIoTmXZ4m75nzsXZUkslyd42DdO/FwAAADjOCHR48XH73U+n9kxd6mRc1qNOnicT+VmPPWtkrFXnRWm7YXi7n53ipP21vcxy3/vmWGoJAACAWUSgw4tTJ9RNz9Rl/emUpFmzdM9mrQeskcx043S1e+m5Tqhz033m9pmRc4Q5AAAAnCAIdHjxmg517X51xpjs+zSVSYycTdpBbm/Pvc4L2o9s45O0s9FKJxju8/4AAADAbCHQ4cWtfU+dUpe1MjAuC3apZs7MSdo7Rae9M3Xtjuqd5uHcMwcAAIATCIEOL377hi/XDnaSjNk3lO2z5HKfvntu/wBHkAMAAMAJhECHuWO/UEY0AwAAQN7Z2R4AAAAAAODwEOgAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADl1SIFu3bp1eu1rX6ve3l4tWrRIb3vb2/Tkk0/OOKfRaGjt2rWaP3++enp6dMkll2hkZGTGOVu2bNGaNWvU1dWlRYsW6brrrlMcx0f+aQAAyAlqKgDgaDikQLdx40atXbtW999/v9avX68oinThhRdqamqqc8773vc+felLX9Kdd96pjRs3atu2bbr44os7x5Mk0Zo1a9RqtfSd73xHn/3sZ3XbbbfphhtuOHqfCgCAExw1FQBwNBjnnDvcF+/YsUOLFi3Sxo0b9Yu/+IsaHx/XwoULdfvtt+s3f/M3JUk//OEP9fKXv1ybNm3S+eefr7vvvlu/9mu/pm3btmlgYECS9Dd/8zf6wAc+oB07digMw5/5eycmJlSpVPTLeqt8Exzu8AEARyB2ke7TFzU+Pq5yuTzbw8k9aioAzE1HWk+P6B668fFxSVJ/f78kafPmzYqiSKtWreqcc9ZZZ2nZsmXatGmTJGnTpk06++yzO4VHklavXq2JiQk9/vjjB/09zWZTExMTMx4AALyYUFMBAIfjsANdmqa65ppr9PrXv16vfOUrJUnDw8MKw1B9fX0zzh0YGNDw8HDnnH0Lz/Tx6WMHs27dOlUqlc5j6dKlhztsAABOONRUAMDhOuxAt3btWj322GO64447juZ4Dur666/X+Ph457F169Zj/jsBADheqKkAgMPlH86Lrr76an35y1/WN7/5TZ188smd5wcHB9VqtTQ2NjbjbxRHRkY0ODjYOefBBx+c8X7TO3ZNn7O/QqGgQqFwOEMFAOCERk0FAByJQ5qhc87p6quv1l133aV7771Xp5122ozjK1asUBAE2rBhQ+e5J598Ulu2bNHQ0JAkaWhoSI8++qhGR0c756xfv17lclnLly8/ks8CAEBuUFMBAEfDIc3QrV27Vrfffru++MUvqre3t7M+v1KpqFQqqVKp6Morr9S1116r/v5+lctlvec979HQ0JDOP/98SdKFF16o5cuX6x3veIc++tGPanh4WB/60Ie0du1a/sYQADBnUFMBAEfDIbUtMMYc9Plbb71Vv/3bvy0pa4L6/ve/X//0T/+kZrOp1atX6zOf+cyMpR/PPfecrrrqKt13333q7u7WFVdcoZtvvlm+//PlS7ZYBoDZR9uCI0NNBQBIR15Pj6gP3Wyh+ADA7CPQvThQUwFgds1qHzoAAAAAwOwh0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnDinQ3XLLLTrnnHNULpdVLpc1NDSku+++u3O80Who7dq1mj9/vnp6enTJJZdoZGRkxnts2bJFa9asUVdXlxYtWqTrrrtOcRwfnU8DAEBOUFMBAEfDIQW6k08+WTfffLM2b96s7373u3rTm96kt771rXr88cclSe973/v0pS99SXfeeac2btyobdu26eKLL+68PkkSrVmzRq1WS9/5znf02c9+VrfddptuuOGGo/upAAA4wVFTAQBHg3HOuSN5g/7+fn3sYx/Tb/7mb2rhwoW6/fbb9Zu/+ZuSpB/+8Id6+ctfrk2bNun888/X3XffrV/7tV/Ttm3bNDAwIEn6m7/5G33gAx/Qjh07FIbhQX9Hs9lUs9ns/DwxMaGlS5fql/VW+SY4kuEDAA5T7CLdpy9qfHxc5XJ5tofzokBNBYC550jr6WHfQ5ckie644w5NTU1paGhImzdvVhRFWrVqVeecs846S8uWLdOmTZskSZs2bdLZZ5/dKTyStHr1ak1MTHT+RvJg1q1bp0ql0nksXbr0cIcNAMAJh5oKADhchxzoHn30UfX09KhQKOjd73637rrrLi1fvlzDw8MKw1B9fX0zzh8YGNDw8LAkaXh4eEbhmT4+fewnuf766zU+Pt55bN269VCHDQDACYeaCgA4Uv6hvuBlL3uZHnnkEY2Pj+vzn/+8rrjiCm3cuPFYjK2jUCioUCgc098BAMDxRk0FABypQw50YRjqjDPOkCStWLFCDz30kD7xiU/o0ksvVavV0tjY2Iy/URwZGdHg4KAkaXBwUA8++OCM95vesWv6HAAA5gpqKgDgSB1xH7o0TdVsNrVixQoFQaANGzZ0jj355JPasmWLhoaGJElDQ0N69NFHNTo62jln/fr1KpfLWr58+ZEOBQCAXKOmAgAO1SHN0F1//fW66KKLtGzZMk1OTur222/Xfffdp3/7t39TpVLRlVdeqWuvvVb9/f0ql8t6z3veo6GhIZ1//vmSpAsvvFDLly/XO97xDn30ox/V8PCwPvShD2nt2rUs/wAAzCnUVADA0XBIgW50dFS/9Vu/pe3bt6tSqeicc87Rv/3bv+lXfuVXJEkf//jHZa3VJZdcomazqdWrV+szn/lM5/We5+nLX/6yrrrqKg0NDam7u1tXXHGFPvKRjxzdTwUAwAmOmgoAOBqOuA/dbJiYmFClUqFnDgDMIvrQvThQUwFgds1aHzoAAAAAwOwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABAThHoAAAAACCnCHQAAAAAkFMEOgAAAADIKQIdAAAAAOQUgQ4AAAAAcopABwAAAAA5RaADAAAAgJwi0AEAAABATh1RoLv55ptljNE111zTea7RaGjt2rWaP3++enp6dMkll2hkZGTG67Zs2aI1a9aoq6tLixYt0nXXXac4jo9kKAAA5Bb1FABwuA470D300EP6X//rf+mcc86Z8fz73vc+felLX9Kdd96pjRs3atu2bbr44os7x5Mk0Zo1a9RqtfSd73xHn/3sZ3XbbbfphhtuOPxPAQBATlFPAQBH4rACXbVa1eWXX67//b//t+bNm9d5fnx8XH/3d3+nv/zLv9Sb3vQmrVixQrfeequ+853v6P7775ckfe1rX9MTTzyh//N//o9e9apX6aKLLtKf/umf6tOf/rRardbR+VQAAOQA9RQAcKQOK9CtXbtWa9as0apVq2Y8v3nzZkVRNOP5s846S8uWLdOmTZskSZs2bdLZZ5+tgYGBzjmrV6/WxMSEHn/88YP+vmazqYmJiRkPAADy7njXU4maCgAvNv6hvuCOO+7Q9773PT300EMHHBseHlYYhurr65vx/MDAgIaHhzvn7Ft8po9PHzuYdevW6cMf/vChDhUAgBPWbNRTiZoKAC82hzRDt3XrVr33ve/VP/7jP6pYLB6rMR3g+uuv1/j4eOexdevW4/a7AQA42marnkrUVAB4sTmkQLd582aNjo7qNa95jXzfl+/72rhxoz75yU/K930NDAyo1WppbGxsxutGRkY0ODgoSRocHDxgl67pn6fP2V+hUFC5XJ7xAAAgr2arnkrUVAB4sTmkQHfBBRfo0Ucf1SOPPNJ5nHfeebr88ss73wdBoA0bNnRe8+STT2rLli0aGhqSJA0NDenRRx/V6Oho55z169erXC5r+fLlR+ljAQBw4qKeAgCOlkO6h663t1evfOUrZzzX3d2t+fPnd56/8sorde2116q/v1/lclnvec97NDQ0pPPPP1+SdOGFF2r58uV6xzveoY9+9KMaHh7Whz70Ia1du1aFQuEofSwAAE5c1FMAwNFyyJui/Cwf//jHZa3VJZdcomazqdWrV+szn/lM57jnefryl7+sq666SkNDQ+ru7tYVV1yhj3zkI0d7KAAA5Bb1FADw8zDOOTfbgzhUExMTqlQq+mW9Vb4JZns4ADAnxS7SffqixsfHuQ8rx6ipADC7jrSeHlYfOgAAAADA7CPQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOHVKgu+mmm2SMmfE466yzOscbjYbWrl2r+fPnq6enR5dccolGRkZmvMeWLVu0Zs0adXV1adGiRbruuusUx/HR+TQAAOQENRUAcDT4h/qCV7ziFfr617++9w38vW/xvve9T1/5yld05513qlKp6Oqrr9bFF1+sb3/725KkJEm0Zs0aDQ4O6jvf+Y62b9+u3/qt31IQBPrzP//zo/BxAADID2oqAOBIHXKg831fg4ODBzw/Pj6uv/u7v9Ptt9+uN73pTZKkW2+9VS9/+ct1//336/zzz9fXvvY1PfHEE/r617+ugYEBvepVr9Kf/umf6gMf+IBuuukmhWF45J8IAICcoKYCAI7UId9D99RTT2nJkiU6/fTTdfnll2vLli2SpM2bNyuKIq1atapz7llnnaVly5Zp06ZNkqRNmzbp7LPP1sDAQOec1atXa2JiQo8//vhP/J3NZlMTExMzHgAA5B01FQBwpA4p0K1cuVK33Xab7rnnHt1yyy169tln9cY3vlGTk5MaHh5WGIbq6+ub8ZqBgQENDw9LkoaHh2cUnunj08d+knXr1qlSqXQeS5cuPZRhAwBwwqGmAgCOhkNacnnRRRd1vj/nnHO0cuVKnXLKKfrc5z6nUql01Ac37frrr9e1117b+XliYoICBADINWoqAOBoOKK2BX19fXrpS1+qp59+WoODg2q1WhobG5txzsjISOf+gMHBwQN26Jr++WD3EEwrFAoql8szHgAAvJhQUwEAh+OIAl21WtUzzzyjxYsXa8WKFQqCQBs2bOgcf/LJJ7VlyxYNDQ1JkoaGhvToo49qdHS0c8769etVLpe1fPnyIxkKAAC5Rk0FAByOQ1py+Qd/8Ad6y1veolNOOUXbtm3TjTfeKM/zdNlll6lSqejKK6/Utddeq/7+fpXLZb3nPe/R0NCQzj//fEnShRdeqOXLl+sd73iHPvrRj2p4eFgf+tCHtHbtWhUKhWPyAQEAOBFRUwEAR8MhBbrnn39el112mXbt2qWFCxfqDW94g+6//34tXLhQkvTxj39c1lpdcsklajabWr16tT7zmc90Xu95nr785S/rqquu0tDQkLq7u3XFFVfoIx/5yNH9VAAAnOCoqQCAo8E459xsD+JQTUxMqFKp6Jf1VvkmmO3hAMCcFLtI9+mLGh8f5z6sHKOmAsDsOtJ6esiNxU8E0xk0ViTlLo4CwItDrEjS3n8nI5+oqQAwu460nuYy0O3atUuS9C19dZZHAgCYnJxUpVKZ7WHgMFFTAeDEcLj1NJeBrr+/X5K0ZcsW/iNiH9O9hLZu3crypzauyYG4Jgfimhzcz7ouzjlNTk5qyZIlszA6HC3U1APx74QDcU0OjutyIK7JgY51Pc1loLM267ZQqVT4g3IQ9BU6ENfkQFyTA3FNDu6nXRcCQP5RU38y/p1wIK7JwXFdDsQ1OdCxqqdH1IcOAAAAADB7CHQAAAAAkFO5DHSFQkE33ngjjVP3w3U5ENfkQFyTA3FNDo7rMjfwz/lAXJMDcU0OjutyIK7JgY71NcllHzoAAAAAQE5n6AAAAAAABDoAAAAAyC0CHQAAAADkFIEOAAAAAHIql4Hu05/+tE499VQVi0WtXLlSDz744GwP6Zj55je/qbe85S1asmSJjDH6whe+MOO4c0433HCDFi9erFKppFWrVumpp56acc7u3bt1+eWXq1wuq6+vT1deeaWq1epx/BRH17p16/Ta175Wvb29WrRokd72trfpySefnHFOo9HQ2rVrNX/+fPX09OiSSy7RyMjIjHO2bNmiNWvWqKurS4sWLdJ1112nOI6P50c5am655Radc845nYaVQ0NDuvvuuzvH59r1OJibb75Zxhhdc801nefm4nW56aabZIyZ8TjrrLM6x+fiNZnL5lI9laip+6OeHhw19Wejpp5g9dTlzB133OHCMHR///d/7x5//HH3u7/7u66vr8+NjIzM9tCOia9+9avuj//4j92//Mu/OEnurrvumnH85ptvdpVKxX3hC19w//Ef/+F+/dd/3Z122mmuXq93zvnVX/1Vd+6557r777/f/fu//7s744wz3GWXXXacP8nRs3r1anfrrbe6xx57zD3yyCPuzW9+s1u2bJmrVqudc9797ne7pUuXug0bNrjvfve77vzzz3e/8Au/0Dkex7F75Stf6VatWuUefvhh99WvftUtWLDAXX/99bPxkY7Yv/7rv7qvfOUr7j//8z/dk08+6f7oj/7IBUHgHnvsMefc3Lse+3vwwQfdqaee6s455xz33ve+t/P8XLwuN954o3vFK17htm/f3nns2LGjc3wuXpO5aq7VU+eoqfujnh4cNfWno6ZmTqR6mrtA97rXvc6tXbu283OSJG7JkiVu3bp1sziq42P/4pOmqRscHHQf+9jHOs+NjY25QqHg/umf/sk559wTTzzhJLmHHnqoc87dd9/tjDHuhRdeOG5jP5ZGR0edJLdx40bnXHYNgiBwd955Z+ecH/zgB06S27Rpk3MuK+rWWjc8PNw555ZbbnHlctk1m83j+wGOkXnz5rm//du/nfPXY3Jy0p155plu/fr17pd+6Zc6xWeuXpcbb7zRnXvuuQc9NlevyVw1l+upc9TUg6Ge/mTU1Aw1da8TqZ7masllq9XS5s2btWrVqs5z1lqtWrVKmzZtmsWRzY5nn31Ww8PDM65HpVLRypUrO9dj06ZN6uvr03nnndc5Z9WqVbLW6oEHHjjuYz4WxsfHJUn9/f2SpM2bNyuKohnX5ayzztKyZctmXJezzz5bAwMDnXNWr16tiYkJPf7448dx9EdfkiS64447NDU1paGhoTl/PdauXas1a9bM+PzS3P5z8tRTT2nJkiU6/fTTdfnll2vLli2S5vY1mWuopweiplJPD4aaOhM1daYTpZ76R+GzHDc7d+5UkiQzPrgkDQwM6Ic//OEsjWr2DA8PS9JBr8f0seHhYS1atGjGcd/31d/f3zknz9I01TXXXKPXv/71euUrXykp+8xhGKqvr2/Guftfl4Ndt+ljefToo49qaGhIjUZDPT09uuuuu7R8+XI98sgjc/J6SNIdd9yh733ve3rooYcOODZX/5ysXLlSt912m172spdp+/bt+vCHP6w3vvGNeuyxx+bsNZmLqKcHmus1lXo6EzX1QNTUmU6kepqrQAfsb+3atXrsscf0rW99a7aHMute9rKX6ZFHHtH4+Lg+//nP64orrtDGjRtne1izZuvWrXrve9+r9evXq1gszvZwThgXXXRR5/tzzjlHK1eu1CmnnKLPfe5zKpVKszgyALOJejoTNXUmauqBTqR6mqsllwsWLJDneQfsEDMyMqLBwcFZGtXsmf7MP+16DA4OanR0dMbxOI61e/fu3F+zq6++Wl/+8pf1jW98QyeffHLn+cHBQbVaLY2Njc04f//rcrDrNn0sj8Iw1BlnnKEVK1Zo3bp1Ovfcc/WJT3xizl6PzZs3a3R0VK95zWvk+75839fGjRv1yU9+Ur7va2BgYE5el/319fXppS99qZ5++uk5+2dlLqKeHmgu11Tq6YGoqTNRU3+22aynuQp0YRhqxYoV2rBhQ+e5NE21YcMGDQ0NzeLIZsdpp52mwcHBGddjYmJCDzzwQOd6DA0NaWxsTJs3b+6cc++99ypNU61cufK4j/locM7p6quv1l133aV7771Xp5122ozjK1asUBAEM67Lk08+qS1btsy4Lo8++uiMwrx+/XqVy2UtX778+HyQYyxNUzWbzTl7PS644AI9+uijeuSRRzqP8847T5dffnnn+7l4XfZXrVb1zDPPaPHixXP2z8pcRD090FysqdTTnx81lZr6s8xqPT3UHV1m2x133OEKhYK77bbb3BNPPOHe9a53ub6+vhk7xLyYTE5Ouocfftg9/PDDTpL7y7/8S/fwww+75557zjmXbbHc19fnvvjFL7rvf//77q1vfetBt1h+9atf7R544AH3rW99y5155pm53WLZOeeuuuoqV6lU3H333Tdjq9hardY5593vfrdbtmyZu/fee913v/tdNzQ05IaGhjrHp7eKvfDCC90jjzzi7rnnHrdw4cLcbp37wQ9+0G3cuNE9++yz7vvf/7774Ac/6Iwx7mtf+5pzbu5dj59k3x25nJub1+X973+/u++++9yzzz7rvv3tb7tVq1a5BQsWuNHRUefc3Lwmc9Vcq6fOUVP3Rz09OGrqz2eu19QTqZ7mLtA559ynPvUpt2zZMheGoXvd617n7r///tke0jHzjW98w0k64HHFFVc457Jtlv/kT/7EDQwMuEKh4C644AL35JNPzniPXbt2ucsuu8z19PS4crns3vnOd7rJyclZ+DRHx8GuhyR36623ds6p1+vu93//9928efNcV1eX+43f+A23ffv2Ge/z4x//2F100UWuVCq5BQsWuPe///0uiqLj/GmOjt/5nd9xp5xyigvD0C1cuNBdcMEFncLj3Ny7Hj/J/sVnLl6XSy+91C1evNiFYehOOukkd+mll7qnn366c3wuXpO5bC7VU+eoqfujnh4cNfXnM9dr6olUT41zzh3anB4AAAAA4ESQq3voAAAAAAB7EegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQUwQ6AAAAAMgpAh0AAAAA5BSBDgAAAAByikAHAAAAADlFoAMAAACAnCLQAQAAAEBOEegAAAAAIKcIdAAAAACQU7MW6D796U/r1FNPVbFY1MqVK/Xggw/O1lAAAMg1aioAzF2zEuj++Z//Wddee61uvPFGfe9739O5556r1atXa3R0dDaGAwBAblFTAWBuM845d7x/6cqVK/Xa175Wf/3Xfy1JStNUS5cu1Xve8x598IMfPOD8ZrOpZrPZ+TlNU+3evVvz58+XMea4jRsAsJdzTpOTk1qyZImsZQX/bKGmAkC+HWk99Y/BmH6qVqulzZs36/rrr+88Z63VqlWrtGnTpoO+Zt26dfrwhz98vIYIADgEW7du1cknnzzbw5iTqKkA8OJxuPX0uAe6nTt3KkkSDQwMzHh+YGBAP/zhDw/6muuvv17XXntt5+fx8XEtW7ZMb9Cb5Ss4puMFABxcrEjf0lfV29s720OZs6ipAJB/R1pPj3ugOxyFQkGFQuGA530F8g3FBwBmRXvBPsv08oWaCgAnmCOsp8f9pocFCxbI8zyNjIzMeH5kZESDg4PHezgAAOQWNRUAcNwDXRiGWrFihTZs2NB5Lk1TbdiwQUNDQ8d7OAAA5BY1FQAwK0sur732Wl1xxRU677zz9LrXvU5/9Vd/pampKb3zne+cjeEAAJBb1FQAmNtmJdBdeuml2rFjh2644QYNDw/rVa96le65554DbuoGAAA/HTUVAOa2WelDd6QmJiZUqVT0y3orN3ADwCyJXaT79EWNj4+rXC7P9nBwmKipADC7jrSe0gkWAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE4R6AAAAAAgpwh0AAAAAJBTBDoAAAAAyCkCHQAAAADkFIEOAAAAAHKKQAcAAAAAOUWgAwAAAICcItABAAAAQE75sz0AoMOY/b7f9+f2V7fvC5zk9nnCzTgIAAAAvOgR6HD87RvcDnjOtL812XPTzx8Q6NphzrnsKYIdAAAA5iACHY6tGbNutv1l30BnsrCWpTJ1gpy1MsZI0+dOv890WJsOc2kq0/neqZP4CHUAAACYAwh0ODLGHPyrJLN/WDM2+9lYyZr2pNtBAp1tBzprJWtnztQ5NzPMpamUpnJJKqNUUvZ851wAAADgRYxAh8MzI8CZbDbNaJ/wtc9SSbf3NaYd1mSNZOze5ZVycs5luc/zJM+TvHaoa8/YScpCWprKpU4mTaQklUsSGZtISZKFPKk9W5fuHS/hDgAAAC9CBDocmn3Dmp0Ocvssk5wOYNPnGrM3TBkj41nJevuEuuw9nHPtpZOS8T3J9yTfl/P2naWTlGaBzqROimMpTqQoluJYLo5l4kROsYyc5IwcG6cAAADgRYxAh5/uIEsqzT6BLpt1s9mMWmeZpGkvr9x/yaWRPE/G97OQ5u1dTmnaM29yTvI8uUIgF3hyfjZT56bvpXNOJnEycSITZWHONCMpyn6vm/6VJnsv49K9SzQJdgAAAHiRIdDh4PabZTPTM3P7zMgZoyzE+X57iWQ2s9a5960TwiS5VDJGLgjkAl/yrZznZUHNSMYpm3lLUjnPKi0GSgue0tBT6hs5r33HXepkYicbpfKaiUwzlg18mUb798pIJs7C4fT9ddOzei7NQl2azpw5BAAAAHKKQIcDdcLcPjtN7r+kcjrUeVbyfZkgkHxfCtrLJPeZfcvue8vCkwt9uYKvNPDkgmzmzVnJpO2wFiVynlXS5SsuWiVFozQwSqezWirZSPJaqfy6J6/uyfOtrLWy07Nznu1slqIklZJEihO51MikqZzVzN0yAQAAgJwi0GGmfcNaO7xNL6k03vS9b/vc1+ZZmcCXCwMpDLLAFnhK/eklkNlySpNmoS4teEpKvpKCVRIYOV/ZMslUsolkW6mcMYq6reIuo7gkJQUj5ykLdIlkW5LfNPKnrIIpq9C38r1sB01jrUzSDnNx0r6vLpZsnG2aEicyqfbuhCkR6gAAAJBbBDrstX+Ys157Bs6T8fz2V69zv9z0zJ0rBHLFUGnBV1LylYZWaWDlvPY9bU4ycXbvW1qwWVgrGiUFKfXVuc/ORpLXtDJOavVIcY9R1O2UFpzSIAtdJpFs08ivGwUFozQ02SyfkQInmdCXiVOZ9mYpJoqlViRnbfa9JBe79k6Y7fvrWH4JAACAnCLQIXOwMOd7MoEv+UH2Ncg2KpHvZxuVtGfFXOAp6QoUd/mKu2y2VDLcb/YtdrKRlIRGUa8Ul4zikpML9jknkryGkY2kqNcpKqdKy4lsMZYfJjKSktgqbvhKpjwlBas0MJKsjPPlrJFNnEycyrZS2VYs04hkfF+mabPZwvbHdXEi45Qtv9x3tg4AAADIEQIdZu5gOR3mAj/b7CQMZAphtqSyEMiFgdLQk/Nt9jCSs0Zxj69Wj1XUYxSX2rNvM8KakdfMZuSiilPckyrtSqUwlbFOLjVS08rWrLyaUVRJZfoi9VZq6uuqqydsyRinRhxoT62kyWpJkV/IxpoYyVlFXSZbthk5eY1UfsOXV/Nl65Fsu8VCu3W5JGWtElInt2/TcgAAACBHCHTIGCtj9pmZmw5zxYJcsZAtqSwFSoqekqKXbVQSZPfIyWQzbq1y9oi7nJKu9jJJ66TUyLaMvFp2L1zcl8iWI3V3N1UqtOTbVHHqqdYIVa8WFE36Mr2x+vqrOqVvj07uGtM8f0rWOFWTgl4o9WlrOE/DrqIoKcg2PTnPyKRGJnHyWu0lmTWrIDDy/SywWUmm3b7AtDdMcc7JGKcZUY5gBwAAgJwg0M117XYEZp9dK2eEuVJBaXdRSXeguNtX3OUpKhklBZPNwNnsbVLfqNXn1OpL5cqx/O5IhTCWZ52S1KjVCBRNBXKJUaG/ofmVqk7uHdO8sKaCjdVIfe1q9uiFrop2FXpUKra0rDKms8sv6CXFUQ34E/JMqj1Jl34ULFJoEzVjX7taVlHLKCpn47CRkdeQ/JpVXHVKAqPQNwrbH9dOt0Zo74LZbj3eDnppthunEaEOAAAAuUCgQxZgrGk3+87ukTNhKFcIlXYVlHQHinoDtcqeWt1GcY9RXJTSUHKe6zQOj8pOmt9Sb6WuBT1VlcOGAi9RK/E11ixp52S3ms1A8ytVndG3Qy/tHtFgMK6ijVRLQ20rzFPBZhuX+F6ixaVxnVbcoZeGoxr0G/Ik7fGmZCRVk4K2l8qaKJUULZRMexxxy1Nct4onvfYMoiR5snHWv85EcbZhSpLIxEl7CWYi51KZRHI2VWe6jlAHAMgRz3fyvJ+vdiWJURKbn30igBMegW6uMyZbamlMe6ml12lD4Eqhku5QUTlQs+Kp2ZctqYx6nZKuVK6YSp7LbpSLjNSVqH9+Vcsqe3RGzw4tDCZVsJHqaajtzYp+FC7Q9mpZJ/eO6aXdIzq3tFUn+RMq2URTqacFXlVORvUkUC0O1BfUtNCf1IDX0IAXypNRaFoa8yc1z59ST9BUubem0rxYoRcrdUZTrVCTtZLqpaKaoa9swxTJizzZyMm2ArlWLBMHWZiLY8mLsxYHoqUBACA//CDVq99Q7dwc/ubLd+nVvzj5c732m1/q04bPz9N/fKdHe+8uB5BHBDpk/x43du8MXZAtuUwLgZIuX60eT82yyQJdX6q0L5bfE6lYbCnwEzln1GwFknEa7J3QmT2jemXXC1ocjKlkIk2loeb782WMFDureWFNg8G4TvIndLIfq8t4mrKxYo1rOB5XX9ivehxkw5LLeppLMjJ7n5MUeIlOKe/RYGlC3V5TsfM01irphVKfXvD6VFWXWq1ANsruqfPqVl7oyxSCLMC2vL0tDcw+LQ2c5ERLAwDAiSiri6/+xaredPEerbpkt4zd5+jBNm42e/c/m7b67bv1i28Z0zfumqe7/vdCbX260C53hDsgbwh0c90+rQqMtVlLAt+XK/hKi76irmznyqhs1JqXKu2P1Ntf06LeSS0qVVXyW0qc1USrqN2NLg0WJ3RKcZfODEd1kt9QlzGquroKJtFkUtTuYpcKNlbRRirZRF3GU9EESuVUMtnzoY0VO6uJuKhdcY92elPy1ZJnjPYkRjuTbo0nJXV7LZ3Wu1OnFXaobOuKnaeRuKy+YECStCWxqtfbSzCLRknRKil5kinKNhOZpp89Gvu1NJieqZNoaQAAOCEMnNxSeX6sX/nN3XrDr42r1JWqqzeRJG37cUHVcU/OSf/f9y3T5Jg347XnDFV1ye/tOOj7nvfLk3rDmnFFLaPP37JQjz7Qox0vBBrbGRzzzwTg6CDQzXFGykKdzR7GWjnfy3rLFaySolXUJUU9Tmk5UXdfXafM262X9OzUsuIulb0sSO2Ie7Wl3q+SF6ni1dTntTTP+iqZQIFracxrqOLVVfIiNVNftTTUVJrNzKVymnKJamlRtTRUM/FVi0Jtq1f0bLhQnkk17k/Ik9OetEs/ai7UcLOik4pjellxu84Md6piYkUymu9PSTIai7q0p54tvUyKVklBiotGmhfIa3ry66m8mifP99rLTvdraRC1d7+kpQEAYJaceU5Nr79oXJL0ugsm9JJX1mcc/+r/ma/R50P9+1cqev6Z4k98n/u+ME/3fWHewX/HuTUNXTiuy/7HqH7vpm2SpM0be/XA+rK++PcLj9InAXAsEeigzloMY7Ng51mlvlUaZEEoKRglpVRed6T5vVM6vWenXtH9gs4IR1WxTcUyGol7VbSRRloVJc4qdkaJUsVKFTun2Fklskqc1Z5Wl14ozNN8r6pY4yqZRFNpUVuifm1r9mlXs1vjtaKi2CqwiSaSkvr9qjzjNJkU9Xy9T4nzNL97uwb8CS32ElVsqNilkmra6Y+rL6ipO2zJBolS31dStGrMN/JaTl7dKqilCkMj5xt5ai/pTA9saZCtvyTMAQCOD893Wrikpd+9YZte/pqa5g9GnWOtptWuYV+7RwJ94g+XanhrqGbd/pR3+9me+o8uPf1oSfd9YZ483+kDf71FZ726prPPn9Kad+zS39x4kp5+rKSJ3fwnI3Ci4v+dc57ZOy1l2jtdtmfrnG+U+kZpKKWhU6kYaV6hpiWFMZ0S7tTpQVV91lPsUpXMmGou1J64W6NxWSPJmDxTVZdpqppajSS92hH1aqxV0rZqWaGNJRmNxPvsctns01NTi7R9sqzaRFF1U1CUeBqt96onaMoap3ocaCoKtbRnTL5J5CtVIMmXlYwUKJZvUvkmlTVZC4K04NRYlMq0WxoEU0ZJ1Sr1jULPKGx3KlCayqSpXJK1NJBLZZxhlg4AcFy8cuX/n71/j5OquvN///e+VFVfq5oGuhsiIBmNSBSdoEJNkplM7JEY4mjE81APxzCJj/gN03iiGJMwYzAmcwaP+f5yMeNlzkxG/J6JYeL8Rh1NNCEYcRIbRJQJYmQ0Q2wMVDcC3dW3uu29zh/VXVA0RptuKBb9ej4eO3Ttvapq7SUPPnn33nutPl340bSuWdFVqs3tP0lo7xvFxXc6d0f16PemDLUev2fdTOio47XiFb7PXfw+/dHH0rr1Ox2adVZGa37wG+14oVZ3ts1S15vRd/gkAJUw6l/rPPvss7rssss0ffp0OY6jRx99tOy4MUarV6/WtGnTVF1drdbWVr322mtlbQ4cOKClS5cqHo+roaFB119/vfr6+sZ0IjhGh4e5oTXpJEfGLU75b9yhteY8I88LFfMKqnFzqnVyqnVc1TpR1bpR1bmBapycjJHezEzSq9kW/To7VTtyjfp1rkk7My367eBkdQ3U62BvrX7TPUX/2f0ebUnP1ub0e/VCz+na3vMe7To4Wd3dtXK6I9L+mHr21Wt3Z6Ne75qq/+pq0m+7Jqu7v0aDQUS9QZXSYZW6Q6OeMKvuMK/u0Fc6rFZ/ULx10/FDeVOycloyCppzyjUFykwxyjY6yiYc5eo9Fep8BdURKTq0+V5xPT7XPWxcAGB8UU9xpA98uE+Lr9uv3h5PqY6ovnjVH+ibK2fo77/6Hv39V9+jR783VcN1+vhx9NxTca269r16fO0UBYGj91/Yr7++/7eqjReO4/cCOFajvkLX39+v8847T5/5zGd05ZVXjjh+11136e6779aDDz6o2bNn6ytf+YoWLVqkV155RVVVxd/+LF26VHv37tX69euVz+f16U9/WjfccIMeeuihsZ8RRscc+aK4wzHF2R6dsLgpdBSGrvKhp6yJKGMiypiMMiavgowGjaus8ZUNI/rv/inqKVRrcqR/aNHwiLqy9erobVBXd70y3VXK9UfU21+lqlhenhuqEHrKZCLK9kfl9PiKHHTl5h0F/REFMV/ZiIpLgDtSMDmn/YO12p1pVL2blZGjhDuovPHUGcS1KzNFezMJFUJXM6YeVMwrKDCu+nJR9fRXa7CqWtmIL5mhJQ1yQ0saZCNy8wU5vi+TL0huUHy+7shhAoBxQD3Fkf7fbzbr+98qTuxlJIWBVJlZJx29+mKtdm6rUS7raMkN+zTnDwf0+f/7Tf3t8tMr0B8Av8+oA92ll16qSy+99KjHjDH69re/rdtuu02XX365JOl//a//pebmZj366KO65ppr9Otf/1pPPfWUtmzZogsuuECS9N3vflcf//jH9T//5//U9OnTR3xuNptVNpstvU6n06PtNt7W0MLgZuhZsdAUbzcMjZzAyAkktyA5eUe5rK90rkr7cvXaG0mozs2pz+RUMK5SQa325ht0IFejrv46dfXVqzaaVcQNlQs99WZiSvdVK98Tk9/tyzieMjW+MlEjuUYKHSnryhtw5fc5ivZIXs4o6HcURB0Zv7jcXVBtlI/5OlBVq13RyZKk3rBKdW5GBbnan6/XbwcmK52r0qz4QU2r6lGNl1M+9HQwX6PdsUn6nWvUZ2qUz0bk5hxFBhz5GVde1JMb8SXfk7yhZRyGr9CxfAGAcVaJeipRU09mJnQUVLoThzGho7X/9zRVVYe69P84oLkX9uvchX3avqmu0l0DcJhxfYZu165dSqVSam1tLe1LJBJasGCB2tvbdc0116i9vV0NDQ2l4iNJra2tcl1Xmzdv1ic/+ckRn7tmzRrdcccd49lVlDkizAWhnHwoNx/Kyxp5GUfegKNCf0T7+ur0emyKnKEJShLeoArGVVchrl2DU9XRN0ndvTXK9UblRkM5rpEJHIVZT86Ap0ivq2iPI4XFZQTCiJFxi1cB3bwjb1CKDBpFeo38jFEYcRREJOM5Cn0p1+AojPoadKv1hiarN1elN6sbVO3lFRhXvfmYMoWI/iD+ls6qTWl2bJ/q3KzyxlOqkFDcz0iS3ii4ygx68jKeCr2OCjFXkagn4w/daum6coYmijFi6QIAJ9bxqqcSNRWjk8u4uvcr79H02Tn94Yd7ddHFab3yQq2CAo8jACeLcQ10qVRKktTc3Fy2v7m5uXQslUqpqampvBO+r8bGxlKbI61atUorV64svU6n05oxY8Z4dn1iG75CF4alQOcWQrm5UH7WyB808gccBb2+eqM1esNrVC7wtb+6VjVecR26nny19gzEleqJK9cTk3uwuNC4cSSFkj+0uLffL0XTxSt/YVQKh668OUZy80Zervh9kf5QXiYYCnKujCcValwZrziZSU6+BsNq7c1EdKCqVr4fKDSOHEeaNWm/ZlXv15lVnTojsl9xN1DOOGrwirdlHsjXaH9NrTJVVcWlGaJSGClOAGM8V6bsylyl/+MAmIiOVz2VqKkYvULe1Y/+38mal+zT/7a8S309nv7l75rf+Y0ATggrZrmMxWKKxWKV7sYpyRgjxxSDnAlDKQjkFApSriAv48sfCBSJOQqikok4yimqA2Fc/ZmYUtVxRb2CQuNoMBfVwGBU+Z6YvG5f0YOOvJxTHtaGwmGkL5SbN8VZND2nODVPKLmBkZsz8rKBvMFAbrYgOSqGrIgnt+DLuI5kJLfgKJfxFfR6GoxFJc9IUaP6pl7FI1lNjvSp2Utrmhcq7saUM4GMBtTpp9UQGVRNNCcnGhZv5fQdGc8UP/vw9fjcoQfPmRQFwCmEmopj8YsfJXRn2yz9n3e+qQv/tJdAB5xExjXQtbS0SJI6Ozs1bdq00v7Ozk6df/75pTZdXV1l7ysUCjpw4EDp/TjBjGSGpuxXEEj5gpTNy4148gc8RSPFdemM68oJHOXyEWX6PGWqquR4pjhhSM6Vk3Hl97qK9jqKdhtFBk1pnhW3IHm5UF7GyB8syM2FMl5xNk05TvGZvdDIzYdy8oGcbEFObmjtHdeVqY6UJiZxQk9e3pWXUekKWxAzyjcV5EhyHSNPoTzHyHMcuXLkqbjenCcj1zFyhj/NeYcJT8hyACqAeoqTjTGOnn28QUEgfXzp/kp3B8BhxjXQzZ49Wy0tLdqwYUOp4KTTaW3evFnLly+XJCWTSXV3d2vr1q2aP3++JOnpp59WGIZasGDBeHYH74YxMjJyjCmGuUIg4w6FqYwnz/cUcR0Zxy/OCJl35GVdFapchVEj46kU2Nyso8iA5PcbxdKhIn1hcWIVIzlBMay5uUBOpiA3Xyiu7+YeNuFIaOQUhq4S5gvFYBmGxUlKwlC+GZp9MzDyMp78AVdBzKhQ7Sgz2VE+cFQoeBooRJQOatQdVOuAm1XBzSpnjA6EUR0MatRfiClb8GUCR06heGXQCYufPWKCGHNo5k8AOFGopzhZ/fLHCb32q5pKdwPAYUYd6Pr6+vT666+XXu/atUvbtm1TY2OjZs6cqZtuukl/8zd/ozPPPLM0zfL06dN1xRVXSJLOPvtsfexjH9NnP/tZ3X///crn81qxYoWuueaat52RC8dbMbiYMJQKheLthrmcHNeR6zjFvyTGyC348jJu8Xm62KHJSoohS6Xn3/zBUJG+QP5AQU4uGFr2IJRTCOUUilcAnVzxaprcwy6BDc2uqSCQGQqXMqHkF8OkjJEXhHJyEXmDvvwqT0GVq8HJvtyc5GZcZQYjemuwTh3Vjar1MgrlHDYpSly/zU7R3sG4egerpIxXfF++eEuoUzByglBOaGTCw4IceQ7AcUA9hZ0cFhgHTjKjDnQvvPCC/vRP/7T0evjB6mXLlmnt2rX64he/qP7+ft1www3q7u7Whz70IT311FOlNXMk6fvf/75WrFihiy++WK7rasmSJbr77rvH4XQwakNT8RefpStOjGIKBTmuI+M4chxHriTfGLmFUF7WVyHjKoy4CiMqPdPmBEZe3sjLhvIyobzBvNzBgpxM7tDVt+FbOguBTKFQ3H/4kgBlyyYEMkEomeKtmEbDV+eKodDN+XJzEUnRYpDMSN6go3xfRG9V1+o3kSkKjaPuqhrVelnlQ1/783XaNTBZe3oTGuirktvvyh905GVNcR26fCgVwtLkMKYU7ABg/FFPAQDjwTHGvsW10um0EomEPqLL5TuRSnfHfsOTfriuHNeT47nFq2KRiBSNyIlFZWJRmVhEJuorjHoyEXdoRkgVA11YvMLl5oOh2yrzUi4vJ5eThoKZKc2iGUhBKDMU6IoLdx92u2NoioEuLC4k7vi+HN+TfF/yI3IivhSNKKyrViEeU3ZyVJlGT4OTHWWnGAWNBVVNGlRjXb8mVQ+qysurELrqzVdpf1+t0j010sGIom95qjpgVP1WqNjBgqIHs3J7B+X0DcoMZmRyOZlcfihcBqxDBxyhYPJ6Ro+pp6dH8Xi80t3BMaKmAkBljbWeWjHLJY6z4Stlw1foJDkKhv4cuno3dGXM5Dy5vi8zNEmKXKd0FU1B8bZKFYq3VCqfl8nniwHOSDLFq16l5RGGrw6WdeWwK3XD+1QYCnnFfpgwKF7Yy/lys8WJW4ozcboyQ0saZIJqpQaLSxp4XqjQOMrnfBUGInLSviI9jqJpKdJn5A+E8gaHJ2IpFMNbGAwF0aHgCQAAAJyECHQoKoWr8NAtjjLFMBeGQ8+0FeR4nuR5clynOPvk0NU9ZzigBcUrcKZQOHRr5fDVLTMc2MJDoc2RhmJjWbIzZngx76EreMNB0A+Lrz1PTjYv1/fkR7xDM2aa4gLl+UFfQY2nbDR6aOKWobXwIv2OIn1G0Z6wOHlLb0HeQL54e2g+L+ULMoWgeEWROVEAAABwEiPQ4ZDDrpg5Q1fqSguOB17xCp3nSu7QNvSMXbHZYVfehhYnN0FQDHeHXY0rhrrw0PeFpS8f2Rdn6GbMcPiuUCNTUPHW0Hxe8j05GVee70nO0Jp3wWFLGlQNPed32EycXkZDC5cX18OL9Bbk9+flDubk5PIy+YIUDIfQ8NAGAAAAnIQIdChXmiQlLK7VZpxDYS0IjghzKl6hG3r27dDtkocmFRm+Glc+a6QZ8X1v2xfHGbrt0ZGjUJJTnP3SdWSyueL1O8eRZ4yipji5iZfx5Fc7CmOOAn9o4XIjuYHk5oz8TCh/MJQ/EMgbyMvtz8oZzMpki1foTKFQet6vdLslt10CAADgJESgw0imeCtkcVKS4rIEctxiyHHc4kQljiMj59DC24fNlnn4Gm5maEkEHWswGm7vFBc1dYyRCQOp4Mhx8qXn/IaXNHBzEXkZX5EBT2HEUegXb8UsXwsvlJcN5A7m5WTzcgazUjYn5XLFK3SFoeUTShmUMAcAAICTE4EOR3dY8CrORlmMTo4zFPYk6SiBrtR+OAiN5xUuExZvv9TQRCkqduvwJQ1MPpCT9WUiXnHiFs8tXaFTWFx6wckHcvKBlM3LyecPXZkbWsy8OClKWAywRzzbBwAAAJxMCHT4/Y4IZMOToLzr941nP4afqTOhnOCwUCdTXLOuUJCTL8jJejK+Jw0/7zc058rwpC3OUNvi5CeH/VkoFD8nDIee8zPjfx4AAADAOCLQYXQqGXAOvwqow0Ld8OyXYShTCIqTpQw/6+cOL1yu4vN84dB6eEMLnJdm5AzD8jBnCHMAAAA4+RHoYJeyWzvD8iUNvHBoBszD1shzDg90pjzUDc/GGQaH1uAbDnKEOQAAAFiAQAf7lMLWYUsaGHfoWT+nNAtn2abDFisfDm/hoStxprSYOWEOAAAA9iDQwU5lSxpIcowc4xYPuUPLG5QWLS+96dB7D1/ofLwnbwEAAABOEAId7HVE+DLDU2CGh0Kcc9j/msOnqzwywBHkAAAAYCECHU4NpSttR+yuSGcAAACAE8OtdAcAAAAAAMeGQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWGpUgW7NmjW68MILVV9fr6amJl1xxRXauXNnWZtMJqO2tjZNnjxZdXV1WrJkiTo7O8vadHR0aPHixaqpqVFTU5NuvfVWFQqFsZ8NAACWoKYCAMbDqALdxo0b1dbWpk2bNmn9+vXK5/O65JJL1N/fX2pz88036/HHH9fDDz+sjRs3as+ePbryyitLx4Mg0OLFi5XL5fTcc8/pwQcf1Nq1a7V69erxOysAAE5y1FQAwHhwjDHmWN+8b98+NTU1aePGjfrjP/5j9fT0aOrUqXrooYd01VVXSZJeffVVnX322Wpvb9fChQv15JNP6hOf+IT27Nmj5uZmSdL999+vL33pS9q3b5+i0eg7fm86nVYikdBHdLl8J3Ks3QcAjEHB5PWMHlNPT4/i8Xilu2M9aioATExjradjeoaup6dHktTY2ChJ2rp1q/L5vFpbW0tt5syZo5kzZ6q9vV2S1N7ernPPPbdUeCRp0aJFSqfT2rFjx1G/J5vNKp1Ol20AAJxKqKkAgGNxzIEuDEPddNNN+uAHP6hzzjlHkpRKpRSNRtXQ0FDWtrm5WalUqtTm8MIzfHz42NGsWbNGiUSitM2YMeNYuw0AwEmHmgoAOFbHHOja2tr08ssva926dePZn6NatWqVenp6Stvu3buP+3cCAHCiUFMBAMfKP5Y3rVixQk888YSeffZZnXbaaaX9LS0tyuVy6u7uLvuNYmdnp1paWkptnn/++bLPG56xa7jNkWKxmGKx2LF0FQCAkxo1FQAwFqO6QmeM0YoVK/TII4/o6aef1uzZs8uOz58/X5FIRBs2bCjt27lzpzo6OpRMJiVJyWRS27dvV1dXV6nN+vXrFY/HNXfu3LGcCwAA1qCmAgDGw6iu0LW1temhhx7SY489pvr6+tL9+YlEQtXV1UokErr++uu1cuVKNTY2Kh6P68Ybb1QymdTChQslSZdcconmzp2r6667TnfddZdSqZRuu+02tbW18RtDAMCEQU0FAIyHUS1b4DjOUfc/8MAD+ou/+AtJxUVQb7nlFv3gBz9QNpvVokWLdO+995bd+vHGG29o+fLleuaZZ1RbW6tly5bpzjvvlO+/u3zJFMsAUHksWzA21FQAgDT2ejqmdegqheIDAJVHoDs1UFMBoLIqug4dAAAAAKByCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgqVEFuvvuu0/z5s1TPB5XPB5XMpnUk08+WTqeyWTU1tamyZMnq66uTkuWLFFnZ2fZZ3R0dGjx4sWqqalRU1OTbr31VhUKhfE5GwAALEFNBQCMh1EFutNOO0133nmntm7dqhdeeEEf/ehHdfnll2vHjh2SpJtvvlmPP/64Hn74YW3cuFF79uzRlVdeWXp/EARavHixcrmcnnvuOT344INau3atVq9ePb5nBQDASY6aCgAYD44xxozlAxobG/WNb3xDV111laZOnaqHHnpIV111lSTp1Vdf1dlnn6329nYtXLhQTz75pD7xiU9oz549am5uliTdf//9+tKXvqR9+/YpGo2+q+9Mp9NKJBL6iC6X70TG0n0AwDEqmLye0WPq6elRPB6vdHdOCdRUAJh4xlpPj/kZuiAItG7dOvX39yuZTGrr1q3K5/NqbW0ttZkzZ45mzpyp9vZ2SVJ7e7vOPffcUuGRpEWLFimdTpd+I3k02WxW6XS6bAMA4FRBTQUAHKtRB7rt27errq5OsVhMn/vc5/TII49o7ty5SqVSikajamhoKGvf3NysVColSUqlUmWFZ/j48LG3s2bNGiUSidI2Y8aM0XYbAICTDjUVADBWow50Z511lrZt26bNmzdr+fLlWrZsmV555ZXj0beSVatWqaenp7Tt3r37uH4fAAAnAjUVADBW/mjfEI1GdcYZZ0iS5s+fry1btug73/mOrr76auVyOXV3d5f9RrGzs1MtLS2SpJaWFj3//PNlnzc8Y9dwm6OJxWKKxWKj7SoAACc1aioAYKzGvA5dGIbKZrOaP3++IpGINmzYUDq2c+dOdXR0KJlMSpKSyaS2b9+urq6uUpv169crHo9r7ty5Y+0KAABWo6YCAEZrVFfoVq1apUsvvVQzZ85Ub2+vHnroIT3zzDP6yU9+okQioeuvv14rV65UY2Oj4vG4brzxRiWTSS1cuFCSdMkll2ju3Lm67rrrdNdddymVSum2225TW1sbvy0EAEwo1FQAwHgYVaDr6urSpz71Ke3du1eJRELz5s3TT37yE/3Zn/2ZJOlb3/qWXNfVkiVLlM1mtWjRIt17772l93uepyeeeELLly9XMplUbW2tli1bpq997Wvje1YAAJzkqKkAgPEw5nXoKoE1cwCg8liH7tRATQWAyqrYOnQAAAAAgMoi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClxhTo7rzzTjmOo5tuuqm0L5PJqK2tTZMnT1ZdXZ2WLFmizs7Osvd1dHRo8eLFqqmpUVNTk2699VYVCoWxdAUAAGtRTwEAx+qYA92WLVv093//95o3b17Z/ptvvlmPP/64Hn74YW3cuFF79uzRlVdeWToeBIEWL16sXC6n5557Tg8++KDWrl2r1atXH/tZAABgKeopAGAsjinQ9fX1aenSpfqHf/gHTSrRW3cAAQAASURBVJo0qbS/p6dH3/ve9/TNb35TH/3oRzV//nw98MADeu6557Rp0yZJ0k9/+lO98sor+ud//medf/75uvTSS/X1r39d99xzj3K53PicFQAAFqCeAgDG6pgCXVtbmxYvXqzW1tay/Vu3blU+ny/bP2fOHM2cOVPt7e2SpPb2dp177rlqbm4utVm0aJHS6bR27Nhx1O/LZrNKp9NlGwAAtjvR9VSipgLAqcYf7RvWrVunF198UVu2bBlxLJVKKRqNqqGhoWx/c3OzUqlUqc3hxWf4+PCxo1mzZo3uuOOO0XYVAICTViXqqURNBYBTzaiu0O3evVuf//zn9f3vf19VVVXHq08jrFq1Sj09PaVt9+7dJ+y7AQAYb5WqpxI1FQBONaMKdFu3blVXV5c+8IEPyPd9+b6vjRs36u6775bv+2publYul1N3d3fZ+zo7O9XS0iJJamlpGTFL1/Dr4TZHisViisfjZRsAALaqVD2VqKkAcKoZVaC7+OKLtX37dm3btq20XXDBBVq6dGnp50gkog0bNpTes3PnTnV0dCiZTEqSksmktm/frq6urlKb9evXKx6Pa+7cueN0WgAAnLyopwCA8TKqZ+jq6+t1zjnnlO2rra3V5MmTS/uvv/56rVy5Uo2NjYrH47rxxhuVTCa1cOFCSdIll1yiuXPn6rrrrtNdd92lVCql2267TW1tbYrFYuN0WgAAnLyopwCA8TLqSVHeybe+9S25rqslS5Yom81q0aJFuvfee0vHPc/TE088oeXLlyuZTKq2tlbLli3T1772tfHuCgAA1qKeAgDeDccYYyrdidFKp9NKJBL6iC6X70Qq3R0AmJAKJq9n9Jh6enp4Dsti1FQAqKyx1tNjWocOAAAAAFB5BDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACw1qkD31a9+VY7jlG1z5swpHc9kMmpra9PkyZNVV1enJUuWqLOzs+wzOjo6tHjxYtXU1KipqUm33nqrCoXC+JwNAACWoKYCAMaDP9o3vP/979fPfvazQx/gH/qIm2++WT/60Y/08MMPK5FIaMWKFbryyiv1y1/+UpIUBIEWL16slpYWPffcc9q7d68+9alPKRKJ6G//9m/H4XQAALAHNRUAMFajDnS+76ulpWXE/p6eHn3ve9/TQw89pI9+9KOSpAceeEBnn322Nm3apIULF+qnP/2pXnnlFf3sZz9Tc3Ozzj//fH3961/Xl770JX31q19VNBo96ndms1lls9nS63Q6PdpuAwBw0qGmAgDGatTP0L322muaPn263vve92rp0qXq6OiQJG3dulX5fF6tra2ltnPmzNHMmTPV3t4uSWpvb9e5556r5ubmUptFixYpnU5rx44db/uda9asUSKRKG0zZswYbbcBADjpUFMBAGM1qkC3YMECrV27Vk899ZTuu+8+7dq1Sx/+8IfV29urVCqlaDSqhoaGsvc0NzcrlUpJklKpVFnhGT4+fOztrFq1Sj09PaVt9+7do+k2AAAnHWoqAGA8jOqWy0svvbT087x587RgwQLNmjVLP/zhD1VdXT3unRsWi8UUi8WO2+cDAHCiUVMBAONhTMsWNDQ06H3ve59ef/11tbS0KJfLqbu7u6xNZ2dn6fmAlpaWETN0Db8+2jMEAABMFNRUAMCxGFOg6+vr029+8xtNmzZN8+fPVyQS0YYNG0rHd+7cqY6ODiWTSUlSMpnU9u3b1dXVVWqzfv16xeNxzZ07dyxdAQDAatRUAMCxGNUtl1/4whd02WWXadasWdqzZ49uv/12eZ6na6+9VolEQtdff71WrlypxsZGxeNx3XjjjUomk1q4cKEk6ZJLLtHcuXN13XXX6a677lIqldJtt92mtrY2bv8AAEwo1FQAwHgYVaB78803de2112r//v2aOnWqPvShD2nTpk2aOnWqJOlb3/qWXNfVkiVLlM1mtWjRIt17772l93uepyeeeELLly9XMplUbW2tli1bpq997Wvje1YAAJzkqKkAgPHgGGNMpTsxWj09PWpoaNCH9HH5ilS6OwAwIRWU1y/0Y3V3dyuRSFS6OzhG1FQAqKyx1tNRLyx+Mti/f78k6Rf6cYV7AgDo7e0l0FmMmgoAJ4djradWBrrGxkZJUkdHB/8n4jDpdFozZszQ7t27FY/HK92dkwJjMhJjMhJjcnTvNC7GGPX29mr69OkV6B3GCzV1JP5NGIkxOTrGZSTGZKTjXU+tDHSuW5ycM5FI8BflKOLxOONyBMZkJMZkJMbk6H7fuBAA7EdNfXv8mzASY3J0jMtIjMlIx6uejmnZAgAAAABA5RDoAAAAAMBSVga6WCym22+/nXV2jsC4jMSYjMSYjMSYHB3jMjHw33kkxmQkxuToGJeRGJORjveYWLlsAQAAAADA0it0AAAAAAACHQAAAABYi0AHAAAAAJYi0AEAAACApQh0AAAAAGApKwPdPffco9NPP11VVVVasGCBnn/++Up36bh59tlnddlll2n69OlyHEePPvpo2XFjjFavXq1p06apurpara2teu2118raHDhwQEuXLlU8HldDQ4Ouv/569fX1ncCzGF9r1qzRhRdeqPr6ejU1NemKK67Qzp07y9pkMhm1tbVp8uTJqqur05IlS9TZ2VnWpqOjQ4sXL1ZNTY2ampp06623qlAonMhTGTf33Xef5s2bp3g8rng8rmQyqSeffLJ0fKKNx9HceeedchxHN910U2nfRByXr371q3Icp2ybM2dO6fhEHJOJbCLVU4maeiTq6dFRU98ZNfUkq6fGMuvWrTPRaNT80z/9k9mxY4f57Gc/axoaGkxnZ2elu3Zc/PjHPzZ//dd/bf7t3/7NSDKPPPJI2fE777zTJBIJ8+ijj5r//M//NH/+539uZs+ebQYHB0ttPvaxj5nzzjvPbNq0yfzHf/yHOeOMM8y11157gs9k/CxatMg88MAD5uWXXzbbtm0zH//4x83MmTNNX19fqc3nPvc5M2PGDLNhwwbzwgsvmIULF5o/+qM/Kh0vFArmnHPOMa2treall14yP/7xj82UKVPMqlWrKnFKY/bv//7v5kc/+pH5r//6L7Nz507zV3/1VyYSiZiXX37ZGDPxxuNIzz//vDn99NPNvHnzzOc///nS/ok4Lrfffrt5//vfb/bu3Vva9u3bVzo+Ecdkoppo9dQYauqRqKdHR039/aipRSdTPbUu0F100UWmra2t9DoIAjN9+nSzZs2aCvbqxDiy+IRhaFpaWsw3vvGN0r7u7m4Ti8XMD37wA2OMMa+88oqRZLZs2VJq8+STTxrHcczvfve7E9b346mrq8tIMhs3bjTGFMcgEomYhx9+uNTm17/+tZFk2tvbjTHFou66rkmlUqU29913n4nH4yabzZ7YEzhOJk2aZP7xH/9xwo9Hb2+vOfPMM8369evNn/zJn5SKz0Qdl9tvv92cd955Rz02UcdkoprI9dQYaurRUE/fHjW1iJp6yMlUT6265TKXy2nr1q1qbW0t7XNdV62trWpvb69gzypj165dSqVSZeORSCS0YMGC0ni0t7eroaFBF1xwQalNa2urXNfV5s2bT3ifj4eenh5JUmNjoyRp69atyufzZeMyZ84czZw5s2xczj33XDU3N5faLFq0SOl0Wjt27DiBvR9/QRBo3bp16u/vVzKZnPDj0dbWpsWLF5edvzSx/5689tprmj59ut773vdq6dKl6ujokDSxx2SioZ6ORE2lnh4NNbUcNbXcyVJP/XE4lxPmrbfeUhAEZScuSc3NzXr11Vcr1KvKSaVSknTU8Rg+lkql1NTUVHbc9301NjaW2tgsDEPddNNN+uAHP6hzzjlHUvGco9GoGhoaytoeOS5HG7fhYzbavn27ksmkMpmM6urq9Mgjj2ju3Lnatm3bhBwPSVq3bp1efPFFbdmyZcSxifr3ZMGCBVq7dq3OOuss7d27V3fccYc+/OEP6+WXX56wYzIRUU9Hmug1lXpajpo6EjW13MlUT60KdMCR2tra9PLLL+sXv/hFpbtScWeddZa2bdumnp4e/eu//quWLVumjRs3VrpbFbN79259/vOf1/r161VVVVXp7pw0Lr300tLP8+bN04IFCzRr1iz98Ic/VHV1dQV7BqCSqKflqKnlqKkjnUz11KpbLqdMmSLP80bMENPZ2amWlpYK9apyhs/5941HS0uLurq6yo4XCgUdOHDA+jFbsWKFnnjiCf385z/XaaedVtrf0tKiXC6n7u7usvZHjsvRxm34mI2i0ajOOOMMzZ8/X2vWrNF5552n73znOxN2PLZu3aquri594AMfkO/78n1fGzdu1N133y3f99Xc3Dwhx+VIDQ0Net/73qfXX399wv5dmYiopyNN5JpKPR2JmlqOmvrOKllPrQp00WhU8+fP14YNG0r7wjDUhg0blEwmK9izypg9e7ZaWlrKxiOdTmvz5s2l8Ugmk+ru7tbWrVtLbZ5++mmFYagFCxac8D6PB2OMVqxYoUceeURPP/20Zs+eXXZ8/vz5ikQiZeOyc+dOdXR0lI3L9u3bywrz+vXrFY/HNXfu3BNzIsdZGIbKZrMTdjwuvvhibd++Xdu2bSttF1xwgZYuXVr6eSKOy5H6+vr0m9/8RtOmTZuwf1cmIurpSBOxplJP3z1qKjX1nVS0no52RpdKW7dunYnFYmbt2rXmlVdeMTfccINpaGgomyHmVNLb22teeukl89JLLxlJ5pvf/KZ56aWXzBtvvGGMKU6x3NDQYB577DHzq1/9ylx++eVHnWL5D//wD83mzZvNL37xC3PmmWdaO8WyMcYsX77cJBIJ88wzz5RNFTswMFBq87nPfc7MnDnTPP300+aFF14wyWTSJJPJ0vHhqWIvueQSs23bNvPUU0+ZqVOnWjt17pe//GWzceNGs2vXLvOrX/3KfPnLXzaO45if/vSnxpiJNx5v5/AZuYyZmONyyy23mGeeecbs2rXL/PKXvzStra1mypQppquryxgzMcdkoppo9dQYauqRqKdHR019dyZ6TT2Z6ql1gc4YY7773e+amTNnmmg0ai666CKzadOmSnfpuPn5z39uJI3Yli1bZowpTrP8la98xTQ3N5tYLGYuvvhis3PnzrLP2L9/v7n22mtNXV2dicfj5tOf/rTp7e2twNmMj6ONhyTzwAMPlNoMDg6av/zLvzSTJk0yNTU15pOf/KTZu3dv2ef89re/NZdeeqmprq42U6ZMMbfccovJ5/Mn+GzGx2c+8xkza9YsE41GzdSpU83FF19cKjzGTLzxeDtHFp+JOC5XX321mTZtmolGo+Y973mPufrqq83rr79eOj4Rx2Qim0j11Bhq6pGop0dHTX13JnpNPZnqqWOMMaO7pgcAAAAAOBlY9QwdAAAAAOAQAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiqooHunnvu0emnn66qqiotWLBAzz//fCW7AwCAlainADBxVSzQ/cu//ItWrlyp22+/XS+++KLOO+88LVq0SF1dXZXqEgAA1qGeAsDE5hhjTCW+eMGCBbrwwgv1d3/3d5KkMAw1Y8YM3Xjjjfryl7/8e98bhqH27Nmj+vp6OY5zIroLADiCMUa9vb2aPn26XJc7+CtlLPV0uD01FQAqZ6z11D8OfXpHuVxOW7du1apVq0r7XNdVa2ur2tvbR7TPZrPKZrOl17/73e80d+7cE9JXAMDvt3v3bp122mmV7saENNp6KlFTAeBkdaz1tCKB7q233lIQBGpubi7b39zcrFdffXVE+zVr1uiOO+4Ysf9D+rh8RY5bPwEAb6+gvH6hH6u+vr7SXZmwRltPJWoqAJxsxlpPKxLoRmvVqlVauXJl6XU6ndaMGTPkKyLfofgAQEUM3bDPbXp2oaYCwElmjPW0IoFuypQp8jxPnZ2dZfs7OzvV0tIyon0sFlMsFjtR3QMAwAqjracSNRUATjUVeYo9Go1q/vz52rBhQ2lfGIbasGGDkslkJboEAIB1qKcAgIrdcrly5UotW7ZMF1xwgS666CJ9+9vfVn9/vz796U9XqksAAFiHegoAE1vFAt3VV1+tffv2afXq1UqlUjr//PP11FNPjXiwGwAAvD3qKQBMbBVbh24s0um0EomEPqLLeYAbACqkYPJ6Ro+pp6dH8Xi80t3BMaKmAkBljbWeshIsAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWGnWge/bZZ3XZZZdp+vTpchxHjz76aNlxY4xWr16tadOmqbq6Wq2trXrttdfK2hw4cEBLly5VPB5XQ0ODrr/+evX19Y3pRAAAsAn1FAAwHkYd6Pr7+3XeeefpnnvuOerxu+66S3fffbfuv/9+bd68WbW1tVq0aJEymUypzdKlS7Vjxw6tX79eTzzxhJ599lndcMMNx34WAABYhnoKABgPjjHGHPObHUePPPKIrrjiCknF3yZOnz5dt9xyi77whS9Iknp6etTc3Ky1a9fqmmuu0a9//WvNnTtXW7Zs0QUXXCBJeuqpp/Txj39cb775pqZPn/6O35tOp5VIJPQRXS7fiRxr9wEAY1AweT2jx9TT06N4PF7p7litUvVUoqYCQKWNtZ6O6zN0u3btUiqVUmtra2lfIpHQggUL1N7eLklqb29XQ0NDqfhIUmtrq1zX1ebNm4/6udlsVul0umwDAOBUdbzqqURNBYBTzbgGulQqJUlqbm4u29/c3Fw6lkql1NTUVHbc9301NjaW2hxpzZo1SiQSpW3GjBnj2W0AAE4qx6ueStRUADjVWDHL5apVq9TT01Padu/eXekuAQBgJWoqAJxaxjXQtbS0SJI6OzvL9nd2dpaOtbS0qKurq+x4oVDQgQMHSm2OFIvFFI/HyzYAAE5Vx6ueStRUADjVjGugmz17tlpaWrRhw4bSvnQ6rc2bNyuZTEqSksmkuru7tXXr1lKbp59+WmEYasGCBePZHQAArEQ9BQC8W/5o39DX16fXX3+99HrXrl3atm2bGhsbNXPmTN100036m7/5G5155pmaPXu2vvKVr2j69OmlmbvOPvtsfexjH9NnP/tZ3X///crn81qxYoWuueaadz0jFwAAtqOeAgDGw6gD3QsvvKA//dM/Lb1euXKlJGnZsmVau3atvvjFL6q/v1833HCDuru79aEPfUhPPfWUqqqqSu/5/ve/rxUrVujiiy+W67pasmSJ7r777nE4HQAA7EA9BQCMhzGtQ1cprJkDAJXHOnSnBmoqAFTWSbUOHQAAAADgxCHQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKVGFejWrFmjCy+8UPX19WpqatIVV1yhnTt3lrXJZDJqa2vT5MmTVVdXpyVLlqizs7OsTUdHhxYvXqyamho1NTXp1ltvVaFQGPvZAABgCWoqAGA8jCrQbdy4UW1tbdq0aZPWr1+vfD6vSy65RP39/aU2N998sx5//HE9/PDD2rhxo/bs2aMrr7yydDwIAi1evFi5XE7PPfecHnzwQa1du1arV68ev7MCAOAkR00FAIwHxxhjjvXN+/btU1NTkzZu3Kg//uM/Vk9Pj6ZOnaqHHnpIV111lSTp1Vdf1dlnn6329nYtXLhQTz75pD7xiU9oz549am5uliTdf//9+tKXvqR9+/YpGo2+4/em02klEgl9RJfLdyLH2n0AwBgUTF7P6DH19PQoHo9XujvWo6YCwMQ01no6pmfoenp6JEmNjY2SpK1btyqfz6u1tbXUZs6cOZo5c6ba29slSe3t7Tr33HNLhUeSFi1apHQ6rR07dhz1e7LZrNLpdNkGAMCphJoKADgWxxzowjDUTTfdpA9+8IM655xzJEmpVErRaFQNDQ1lbZubm5VKpUptDi88w8eHjx3NmjVrlEgkStuMGTOOtdsAAJx0qKkAgGN1zIGura1NL7/8statWzee/TmqVatWqaenp7Tt3r37uH8nAAAnCjUVAHCs/GN504oVK/TEE0/o2Wef1WmnnVba39LSolwup+7u7rLfKHZ2dqqlpaXU5vnnny/7vOEZu4bbHCkWiykWix1LVwEAOKlRUwEAYzGqK3TGGK1YsUKPPPKInn76ac2ePbvs+Pz58xWJRLRhw4bSvp07d6qjo0PJZFKSlEwmtX37dnV1dZXarF+/XvF4XHPnzh3LuQAAYA1qKgBgPIzqCl1bW5seeughPfbYY6qvry/dn59IJFRdXa1EIqHrr79eK1euVGNjo+LxuG688UYlk0ktXLhQknTJJZdo7ty5uu6663TXXXcplUrptttuU1tbG78xBABMGNRUAMB4GNWyBY7jHHX/Aw88oL/4i7+QVFwE9ZZbbtEPfvADZbNZLVq0SPfee2/ZrR9vvPGGli9frmeeeUa1tbVatmyZ7rzzTvn+u8uXTLEMAJXHsgVjQ00FAEhjr6djWoeuUig+AFB5BLpTAzUVACqrouvQAQAAAAAqh0AHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClRhXo7rvvPs2bN0/xeFzxeFzJZFJPPvlk6Xgmk1FbW5smT56suro6LVmyRJ2dnWWf0dHRocWLF6umpkZNTU269dZbVSgUxudsAACwBDUVADAeRhXoTjvtNN15553aunWrXnjhBX30ox/V5Zdfrh07dkiSbr75Zj3++ON6+OGHtXHjRu3Zs0dXXnll6f1BEGjx4sXK5XJ67rnn9OCDD2rt2rVavXr1+J4VAAAnOWoqAGA8OMYYM5YPaGxs1De+8Q1dddVVmjp1qh566CFdddVVkqRXX31VZ599ttrb27Vw4UI9+eST+sQnPqE9e/aoublZknT//ffrS1/6kvbt26doNHrU78hms8pms6XX6XRaM2bM0Ed0uXwnMpbuAwCOUcHk9YweU09Pj+LxeKW7c0qgpgLAxDPWenrMz9AFQaB169apv79fyWRSW7duVT6fV2tra6nNnDlzNHPmTLW3t0uS2tvbde6555YKjyQtWrRI6XS69BvJo1mzZo0SiURpmzFjxrF2GwCAkw41FQBwrEYd6LZv3666ujrFYjF97nOf0yOPPKK5c+cqlUopGo2qoaGhrH1zc7NSqZQkKZVKlRWe4ePDx97OqlWr1NPTU9p279492m4DAHDSoaYCAMbKH+0bzjrrLG3btk09PT3613/9Vy1btkwbN248Hn0ricViisVix/U7AAA40aipAICxGnWgi0ajOuOMMyRJ8+fP15YtW/Sd73xHV199tXK5nLq7u8t+o9jZ2amWlhZJUktLi55//vmyzxuesWu4DQAAEwU1FQAwVmNehy4MQ2WzWc2fP1+RSEQbNmwoHdu5c6c6OjqUTCYlSclkUtu3b1dXV1epzfr16xWPxzV37tyxdgUAAKtRUwEAozWqK3SrVq3SpZdeqpkzZ6q3t1cPPfSQnnnmGf3kJz9RIpHQ9ddfr5UrV6qxsVHxeFw33nijksmkFi5cKEm65JJLNHfuXF133XW66667lEqldNttt6mtrY3bPwAAEwo1FQAwHkYV6Lq6uvSpT31Ke/fuVSKR0Lx58/STn/xEf/ZnfyZJ+ta3viXXdbVkyRJls1ktWrRI9957b+n9nufpiSee0PLly5VMJlVbW6tly5bpa1/72vieFQAAJzlqKgBgPIx5HbpKSKfTSiQSrJkDABXEOnSnBmoqAFRWxdahAwAAAABUFoEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALDWmQHfnnXfKcRzddNNNpX2ZTEZtbW2aPHmy6urqtGTJEnV2dpa9r6OjQ4sXL1ZNTY2ampp06623qlAojKUrAABYi3oKADhWxxzotmzZor//+7/XvHnzyvbffPPNevzxx/Xwww9r48aN2rNnj6688srS8SAItHjxYuVyOT333HN68MEHtXbtWq1evfrYzwIAAEtRTwEAY3FMga6vr09Lly7VP/zDP2jSpEml/T09Pfre976nb37zm/roRz+q+fPn64EHHtBzzz2nTZs2SZJ++tOf6pVXXtE///M/6/zzz9ell16qr3/967rnnnuUy+XG56wAALAA9RQAMFbHFOja2tq0ePFitba2lu3funWr8vl82f45c+Zo5syZam9vlyS1t7fr3HPPVXNzc6nNokWLlE6ntWPHjqN+XzabVTqdLtsAALDdia6nEjUVAE41/mjfsG7dOr344ovasmXLiGOpVErRaFQNDQ1l+5ubm5VKpUptDi8+w8eHjx3NmjVrdMcdd4y2qwAAnLQqUU8laioAnGpGdYVu9+7d+vznP6/vf//7qqqqOl59GmHVqlXq6ekpbbt37z5h3w0AwHirVD2VqKkAcKoZVaDbunWrurq69IEPfEC+78v3fW3cuFF33323fN9Xc3Ozcrmcuru7y97X2dmplpYWSVJLS8uIWbqGXw+3OVIsFlM8Hi/bAACwVaXqqURNBYBTzagC3cUXX6zt27dr27Ztpe2CCy7Q0qVLSz9HIhFt2LCh9J6dO3eqo6NDyWRSkpRMJrV9+3Z1dXWV2qxfv17xeFxz584dp9MCAODkRT0FAIyXUT1DV19fr3POOadsX21trSZPnlzaf/3112vlypVqbGxUPB7XjTfeqGQyqYULF0qSLrnkEs2dO1fXXXed7rrrLqVSKd12221qa2tTLBYbp9MCAODkRT0FAIyXUU+K8k6+9a1vyXVdLVmyRNlsVosWLdK9995bOu55np544gktX75cyWRStbW1WrZsmb72ta+Nd1cAALAW9RQA8G44xhhT6U6MVjqdViKR0Ed0uXwnUunuAMCEVDB5PaPH1NPTw3NYFqOmAkBljbWeHtM6dAAAAACAyiPQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKUIdAAAAABgKQIdAAAAAFiKQAcAAAAAliLQAQAAAIClCHQAAAAAYCkCHQAAAABYikAHAAAAAJYi0AEAAACApQh0AAAAAGApAh0AAAAAWIpABwAAAACWItABAAAAgKVGFei++tWvynGcsm3OnDml45lMRm1tbZo8ebLq6uq0ZMkSdXZ2ln1GR0eHFi9erJqaGjU1NenWW29VoVAYn7MBAMAS1FQAwHjwR/uG97///frZz3526AP8Qx9x880360c/+pEefvhhJRIJrVixQldeeaV++ctfSpKCINDixYvV0tKi5557Tnv37tWnPvUpRSIR/e3f/u04nA4AAPagpgIAxmrUgc73fbW0tIzY39PTo+9973t66KGH9NGPflSS9MADD+jss8/Wpk2btHDhQv30pz/VK6+8op/97Gdqbm7W+eefr69//ev60pe+pK9+9auKRqNjPyMAACxBTQUAjNWon6F77bXXNH36dL33ve/V0qVL1dHRIUnaunWr8vm8WltbS23nzJmjmTNnqr29XZLU3t6uc889V83NzaU2ixYtUjqd1o4dO972O7PZrNLpdNkGAIDtqKkAgLEaVaBbsGCB1q5dq6eeekr33Xefdu3apQ9/+MPq7e1VKpVSNBpVQ0ND2Xuam5uVSqUkSalUqqzwDB8fPvZ21qxZo0QiUdpmzJgxmm4DAHDSoaYCAMbDqG65vPTSS0s/z5s3TwsWLNCsWbP0wx/+UNXV1ePeuWGrVq3SypUrS6/T6TQFCABgNWoqAGA8jGnZgoaGBr3vfe/T66+/rpaWFuVyOXV3d5e16ezsLD0f0NLSMmKGruHXR3uGYFgsFlM8Hi/bAAA4lVBTAQDHYkyBrq+vT7/5zW80bdo0zZ8/X5FIRBs2bCgd37lzpzo6OpRMJiVJyWRS27dvV1dXV6nN+vXrFY/HNXfu3LF0BQAAq1FTAQDHYlS3XH7hC1/QZZddplmzZmnPnj26/fbb5Xmerr32WiUSCV1//fVauXKlGhsbFY/HdeONNyqZTGrhwoWSpEsuuURz587Vddddp7vuukupVEq33Xab2traFIvFjssJAgBwMqKmAgDGw6gC3Ztvvqlrr71W+/fv19SpU/WhD31ImzZt0tSpUyVJ3/rWt+S6rpYsWaJsNqtFixbp3nvvLb3f8zw98cQTWr58uZLJpGpra7Vs2TJ97WtfG9+zAgDgJEdNBQCMB8cYYyrdidFKp9NKJBL6iC6X70Qq3R0AmJAKJq9n9Jh6enp4Dsti1FQAqKyx1tNRLyx+MhjOoAXlJeviKACcGgrKSzr0bzLsRE0FgMoaaz21MtDt379fkvQL/bjCPQEA9Pb2KpFIVLobOEbUVAA4ORxrPbUy0DU2NkqSOjo6+D8RhxleS2j37t3c/jSEMRmJMRmJMTm6dxoXY4x6e3s1ffr0CvQO44WaOhL/JozEmBwd4zISYzLS8a6nVgY61y2utpBIJPiLchSsKzQSYzISYzISY3J0v29cCAD2o6a+Pf5NGIkxOTrGZSTGZKTjVU/HtA4dAAAAAKByCHQAAAAAYCkrA10sFtPtt9/OwqlHYFxGYkxGYkxGYkyOjnGZGPjvPBJjMhJjcnSMy0iMyUjHe0ysXIcOAAAAAGDpFToAAAAAAIEOAAAAAKxFoAMAAAAASxHoAAAAAMBSVga6e+65R6effrqqqqq0YMECPf/885Xu0nHz7LPP6rLLLtP06dPlOI4effTRsuPGGK1evVrTpk1TdXW1Wltb9dprr5W1OXDggJYuXap4PK6GhgZdf/316uvrO4FnMb7WrFmjCy+8UPX19WpqatIVV1yhnTt3lrXJZDJqa2vT5MmTVVdXpyVLlqizs7OsTUdHhxYvXqyamho1NTXp1ltvVaFQOJGnMm7uu+8+zZs3r7RgZTKZ1JNPPlk6PtHG42juvPNOOY6jm266qbRvIo7LV7/6VTmOU7bNmTOndHwijslENpHqqURNPRL19Oioqe+MmnqS1VNjmXXr1ploNGr+6Z/+yezYscN89rOfNQ0NDaazs7PSXTsufvzjH5u//uu/Nv/2b/9mJJlHHnmk7Pidd95pEomEefTRR81//ud/mj//8z83s2fPNoODg6U2H/vYx8x5551nNm3aZP7jP/7DnHHGGebaa689wWcyfhYtWmQeeOAB8/LLL5tt27aZj3/842bmzJmmr6+v1OZzn/ucmTFjhtmwYYN54YUXzMKFC80f/dEflY4XCgVzzjnnmNbWVvPSSy+ZH//4x2bKlClm1apVlTilMfv3f/9386Mf/cj813/9l9m5c6f5q7/6KxOJRMzLL79sjJl443Gk559/3px++ulm3rx55vOf/3xp/0Qcl9tvv928//3vN3v37i1t+/btKx2fiGMyUU20emoMNfVI1NOjo6b+ftTUopOpnloX6C666CLT1tZWeh0EgZk+fbpZs2ZNBXt1YhxZfMIwNC0tLeYb3/hGaV93d7eJxWLmBz/4gTHGmFdeecVIMlu2bCm1efLJJ43jOOZ3v/vdCev78dTV1WUkmY0bNxpjimMQiUTMww8/XGrz61//2kgy7e3txphiUXdd16RSqVKb++67z8TjcZPNZk/sCRwnkyZNMv/4j/844cejt7fXnHnmmWb9+vXmT/7kT0rFZ6KOy+23327OO++8ox6bqGMyUU3kemoMNfVoqKdvj5paRE095GSqp1bdcpnL5bR161a1traW9rmuq9bWVrW3t1ewZ5Wxa9cupVKpsvFIJBJasGBBaTza29vV0NCgCy64oNSmtbVVrutq8+bNJ7zPx0NPT48kqbGxUZK0detW5fP5snGZM2eOZs6cWTYu5557rpqbm0ttFi1apHQ6rR07dpzA3o+/IAi0bt069ff3K5lMTvjxaGtr0+LFi8vOX5rYf09ee+01TZ8+Xe9973u1dOlSdXR0SJrYYzLRUE9HoqZST4+GmlqOmlruZKmn/jicywnz1ltvKQiCshOXpObmZr366qsV6lXlpFIpSTrqeAwfS6VSampqKjvu+74aGxtLbWwWhqFuuukmffCDH9Q555wjqXjO0WhUDQ0NZW2PHJejjdvwMRtt375dyWRSmUxGdXV1euSRRzR37lxt27ZtQo6HJK1bt04vvviitmzZMuLYRP17smDBAq1du1ZnnXWW9u7dqzvuuEMf/vCH9fLLL0/YMZmIqKcjTfSaSj0tR00diZpa7mSqp1YFOuBIbW1tevnll/WLX/yi0l2puLPOOkvbtm1TT0+P/vVf/1XLli3Txo0bK92titm9e7c+//nPa/369aqqqqp0d04al156aennefPmacGCBZo1a5Z++MMfqrq6uoI9A1BJ1NNy1NRy1NSRTqZ6atUtl1OmTJHneSNmiOns7FRLS0uFelU5w+f8+8ajpaVFXV1dZccLhYIOHDhg/ZitWLFCTzzxhH7+85/rtNNOK+1vaWlRLpdTd3d3Wfsjx+Vo4zZ8zEbRaFRnnHGG5s+frzVr1ui8887Td77znQk7Hlu3blVXV5c+8IEPyPd9+b6vjRs36u6775bv+2pubp6Q43KkhoYGve9979Prr78+Yf+uTETU05Emck2lno5ETS1HTX1nlaynVgW6aDSq+fPna8OGDaV9YRhqw4YNSiaTFexZZcyePVstLS1l45FOp7V58+bSeCSTSXV3d2vr1q2lNk8//bTCMNSCBQtOeJ/HgzFGK1as0COPPKKnn35as2fPLjs+f/58RSKRsnHZuXOnOjo6ysZl+/btZYV5/fr1isfjmjt37ok5keMsDENls9kJOx4XX3yxtm/frm3btpW2Cy64QEuXLi39PBHH5Uh9fX36zW9+o2nTpk3YvysTEfV0pIlYU6mn7x41lZr6TipaT0c7o0ulrVu3zsRiMbN27VrzyiuvmBtuuME0NDSUzRBzKunt7TUvvfSSeemll4wk881vftO89NJL5o033jDGFKdYbmhoMI899pj51a9+ZS6//PKjTrH8h3/4h2bz5s3mF7/4hTnzzDOtnWLZGGOWL19uEomEeeaZZ8qmih0YGCi1+dznPmdmzpxpnn76afPCCy+YZDJpkslk6fjwVLGXXHKJ2bZtm3nqqafM1KlTrZ0698tf/rLZuHGj2bVrl/nVr35lvvzlLxvHccxPf/pTY8zEG4+3c/iMXMZMzHG55ZZbzDPPPGN27dplfvnLX5rW1lYzZcoU09XVZYyZmGMyUU20emoMNfVI1NOjo6a+OxO9pp5M9dS6QGeMMd/97nfNzJkzTTQaNRdddJHZtGlTpbt03Pz85z83kkZsy5YtM8YUp1n+yle+Ypqbm00sFjMXX3yx2blzZ9ln7N+/31x77bWmrq7OxONx8+lPf9r09vZW4GzGx9HGQ5J54IEHSm0GBwfNX/7lX5pJkyaZmpoa88lPftLs3bu37HN++9vfmksvvdRUV1ebKVOmmFtuucXk8/kTfDbj4zOf+YyZNWuWiUajZurUqebiiy8uFR5jJt54vJ0ji89EHJerr77aTJs2zUSjUfOe97zHXH311eb1118vHZ+IYzKRTaR6agw19UjU06Ojpr47E72mnkz11DHGmNFd0wMAAAAAnAyseoYOAAAAAHAIgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAAS1U00N1zzz06/fTTVVVVpQULFuj555+vZHcAALAS9RQAJq6KBbp/+Zd/0cqVK3X77bfrxRdf1HnnnadFixapq6urUl0CAMA61FMAmNgcY4ypxBcvWLBAF154of7u7/5OkhSGoWbMmKEbb7xRX/7yl8vaZrNZZbPZ0uswDHXgwAFNnjxZjuOc0H4DAIqMMert7dX06dPlutzBXymjqacSNRUATjZjraf+cejTO8rlctq6datWrVpV2ue6rlpbW9Xe3j6i/Zo1a3THHXecyC4CAN6l3bt367TTTqt0Nyak0dZTiZoKACerY62nFQl0b731loIgUHNzc9n+5uZmvfrqqyPar1q1SitXriy97unp0cyZM/UhfVy+Ise9vwCAkQrK6xf6serr6yvdlQlrtPVUoqYCwMlmrPW0IoFutGKxmGKx2Ij9viLyHYoPAFTE0A373KZnF2oqAJxkxlhPK/LQw5QpU+R5njo7O8v2d3Z2qqWlpRJdAgDAOtRTAEBFAl00GtX8+fO1YcOG0r4wDLVhwwYlk8lKdAkAAOtQTwEAFbvlcuXKlVq2bJkuuOACXXTRRfr2t7+t/v5+ffrTn65UlwAAsA71FAAmtooFuquvvlr79u3T6tWrlUqldP755+upp54a8WA3AAB4e9RTAJjYKrYO3Vik02klEgl9RJfzADcAVEjB5PWMHlNPT4/i8Xilu4NjRE0FgMoaaz1lJVgAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABLEegAAAAAwFIEOgAAAACwFIEOAAAAACxFoAMAAAAASxHoAAAAAMBSBDoAAAAAsBSBDgAAAAAsRaADAAAAAEsR6AAAAADAUgQ6AAAAALAUgQ4AAAAALEWgAwAAAABL+ZXuwIThOEf/+e0Yc/SfAQAAAGAIgW4s3k0wO9RYcp2htznF144O/Wk0/D/FP0w4tItgBwAAAODoCHSjMRzgnCOCmXQonEllwcsM/ew4w4HOkVy3+BFlwe7Q+0xoJOPIMUYypvgZBDsAAAAARyDQvRuHBznHORTkhgOa45RdrCvlLRMOhTIVQ5zrFt/jeYcC3uGh0BjJhFJopDCUwlAmDOWEYTHYhUPBzhGhDgAAAACB7h0NJzXXlaNDIawYztxSyDsU9DQUzIa2MJQxptje9+S4nuR5xfe6Q5/jOKX2pQAXhFIYSIVACgKZ0MhRKGPC0p2ZhDoAAABgYiPQ/T6Hh7Wh4OW4bvEK23Ao81zJOSzYyZRuldRQMHOMKbbzI3J8T/J9yXNlPFfGPWyi0dAcCnOFgkwhkOMVpEKhGOoKBTmBZBQeeg+hDgAAAJiwCHRv58gw53pyPFfy/WKY84dC3WFX20pX8w6/ZTIIij97npxoRCbiS5GITMST8Q97n5FkjJxCIKcQSvmCnFxeynsyOVdOIS9JMjos1Blz6OoeAAAAgAmHQHc0R4Y5z5Pj+3J8vxjoIr4Ujcj4vuR7kj90pW34ObrQyAmGrs7li1fX5HkyVVGZmK8w5iuMegojroznyLiOHCM5gZFTCOXmArnZQG7Gl7J5Oa4jky22kQ4LdU7xVXEnoQ4AAACYaAh0RzpsApTSlbnhMBeNyIlFZaJRKRaRiRaDmYkM3T45/NZwKJjlQzm5gpxcQcb3FNZEFVT7Cqo9FapchVFHoe/IuJKM5AaSmzPys6G8wUDegCdv0Cs+a+e4MjJDd3Wa0sW54efuisyh5+sAAAAAnPIIdEfjunKc4TDnDYW5qJyqqExVTKY6qrAqoqDKU1DtKYwMB7PirZNuaOTmjdxsKC/jy8sUZDxXhfqI8rWe8rWu8tWOgiopjBQDnRMWr9B5WUf+oKNIv6vIUFAc/o/khGExyIVDaS4IipOoSIdmwDz8+ToAAAAApzQC3bDDr8wNL0XgueVhrrpKYW1MQW1EhVpf+RpPhRpHQdRRGFXpSpsTSF5O8jNG/oCnSL8n40q5hK9svat8vaN8nRRUGYVRI+MZKZTcgiNv0JE/4Awdc2Q8R46MPEkaDm+uIydfGJokZWiyFIUyoSS5kkKu1AEAAAATAIFOOsrSBG5xAhSvOCOlE43IxKLFWyZro8rHfeXqPeXqHOVrh660RY2Mp+IVuoIjNyv5A1Ik5in0i5+fjbvKNjjKJYwK9UamNpATC+R6oUzoqJD3VBjwFPS6h92K6cktRIpX7/KBzFDQHJ6IxeSdYsgrhToz9HAdiQ4AAAA41RHojro0wdAslqUwF5GpLoa5XNxXtsFTtsEpXmmLGwXVoUxVKHlDYSrvyM248vscBb2OQt+VG0jZBkfZRqNCYyC/Iav6uoziVRlFvIKC0FV/Lqae/mplq2MKfV9yXDmh5OU9OYEvoyq5Wb84WYrvycm4OjQTi4rLHEiHnqljohQAAADglDaxA93bLE3g+H7x6lxkaBbLaKT4zFyNr3ydp1y9o1yDo1wiVNhQkF+XV3V1Tr4XyBhH2Zyv7GBUuVhEoe9JxpGbk/J1RoV4qMikrJompXVafbeaY2lVe3nlQk8H8zXaHZukvW5CA2GN8nmn9EydFJEfceVlPHm+J9crhrnStThTXP/OmJClDAAAAIAJYuIGuqOFucjQbJaRoaUJIsV140zUV1jlK1/jKlfnKJdwlGsIFU7OK97Yr6b6XjVV96nGy6lgXKXz1ersr9e+aL1yfkxO6MsfcFSoM3ISeU1p6NX7Grp0Vm1Ks6L7VetmlTO+UoWE6vysHEfqKHjKZVzlM56c0FW+xigyMDRZiu8q4jkqLklu5MhIJpQZWszcMZJxWM4AAAAAONVNzEB3tKUJIr9naYIqX0HMVaHaVaHGUaHWKEwEqm0Y1KxJB/QHdW9pZtV+1bsZBXK1Lx/XrshkOTJKhQkVMq5kPIVVRlXVOU2t6dPp1ft1VlVK740cUL0bKGNcTfL6lTOeevLV2l9To2x1TPmEoyBWvEoX9BUnYDFusf8RY+SFoRQYqRAMrX0XFJ+j4yodAOAU9ceXdeuMcwfK9mUGXD30nWaV1hACgAliYgY66ehLE8SixTBXHZOpiiqojiis8lWodhVGXQXR4gQoQY2RV5vXlLo+/UHdW3p/ze90RrRLCS+rgnGV8usVc/MaDKLqz0V1sDeqMONKkVDRaEHxSEZTIr1q9tKa7oWqc6PKmkDGDCjlp9UQGVRNNK/+REZBjafCoK9gwFNQ5SqMOJJcOcYvLkSeD+UWAjmFiEwQSIFXXNDccWQIdQCAU4DrGbXMzCkaC/Xle95Q02l51dYHZW2CgqOLlxzUP3+zRc882iBDsAMwQUy8QOc4Kj57duTSBJFSmAtrq0YuTRBzFMSkMFKc0bImltekqkFNj3VrVnS/Zkf61eB6Kpi8qpxu9YcxvRmbpD1VCXXHAhnfkxzJdYw8J5TvhPIdI99x5MmTLyPfKchzQnlOqMbqfiWqBpUp+OoerFG6t1p5PybjenICZ2gmTU9e1peTi8jJ5iXPK15x9NzDFhsHAMBecz7Qr4suTut/v6mzdIPN0Xi+0Wl/kNUXvt2h5tNy2rQ+rt++Wn3iOgoAFTLxAp1UnBjSdaSypQmiQ0sTxBTURZWv95WNe8rXOsrXDV2ZixmFESO5Rp4XKuYWVO3mVOPkVOe4qnWiKjiB6kxONW5W1V5eES+Q4xkFNaGcWKhC6GowiCodVKknjKk7zKngZJQ1Rj1hVOmgWtVeXucn3pTnhOoLqvS7wYR2RycppYQKQZXyGU9expE/4Mof8ORGfRnfl+N5MkMzdcpxilfpKj3WAAAcg6qaQLd+p0Nnnjeo5tNy7/p9fsTo06v26s+uPqCv/B/v1VupiHIZ9zj2FAAqa2IFulLQcUvPzzl+8fk5Ez1saYL68qUJcvFiIFNVKPlGcozC0FEu9JQNI8qYiAZNRjGTV16hBkNXGRNRNvRVCF3JNYpNGVRD3aDqYxnljavfZSepzs0oMK7q3JyyxlOqkFBvWK33VaXU7PfId0L1BNX670iTYl5BuYKvfTlPhQFXhQFHQZWjMOrK+MWrcsNr05UmfAEAwEKTpuZ1y7d264I/TR9zOTvtvVl97z9e1X88kdC3vzhDA73e+HYSAE4Sp3agO2zyk+Ifxdst5Uhy3ENX6CK+FPUVxiIKqr3ypQkaiksTROpyqq7OKeoHMkbKB556c1XqytdrbyShWjenPpNX3jhKBbVK5Rt0IFervmxUVVV5NcfTmlV/UFOifYq5eRWMp//ONKknqFGNm1PW+OoPYzotclDvi3aqxc8qIqNur1+OjPrCmFLVcXVXVysfiyiMegojjsKIc1igI8wBAOzlukbRqlBf+HYxzI358zyjP7m8W4WCo//fzTMVFKiPAE49p2agOzzIDd16OPQA26Fn6Dy3uID40C2XJhpRWO2rUOspV+coHz+0NEGisV/N8bSaq/tU62UVyFFPrlpvZWr1m76pciT1BlWKe4MqGE9dhbj+e2CqOvomqT8bU0s8rTkNnTq7Zq/eEz2oaienQRPV73KT9Ppgsw7ka5QPPc2qOaAp1b1q8rJqcX35jquYk9NBv0+Nfp/qIllFI4FyvlHoSaEnGXdo8hPHKYbU0s8i2AEArOF6Rktv7tRV/6NLsZrxfQ78o5/slutJf7fqPerrOTX/rw+AievU+1dtOMS4bnHiE7cYdBzXKd6SeNj6c3JdOa4r43kyEVdB1FUh5iqolvK1RmE8UE1iUDMaDuqM+n2aVbVfCW9AgXG1r1CvN6KT9d+9U7SjZ5reqq5T7dAslz35GnUN1mmwEFF1NK/mml7Nqtqvs2IpzYj0qsYJ1W9c1TpZ9YcxdWXrdCBbo1k1++UMrSvnOM7w1C1D+4ZP7ShPxTlv+wIAAAsYLblhn/73z3fK9Ub59Ld5NxM6G8UbCopEebIcwKnn1Ap0Ry4W7jjFq3D+0OyPh2/Dbb2hWSF9T2HEVRCTClWOguqwuDRBfb/+oO4tnVPzO50R69IkN6NAjjoLdapxcxoMotp5sEmpvriqInnF/IIaooOaXtujmXUHNRhElIgMamqkV81+v1o8qcaJacDklTP9muqnFY9k1DVYr3S+WvuDOu0PexUJcoo4jg4GjvYHteou1Kg/H1W+4BdnuQwkJ5Sc0MgJh6qZCYc2U8x9LFkAADjJzXxfRh9e3K1r/89jCHOStvw8rm/eMuMd22X6XQ308RwdgFPPqRPoDr+90nVLU/g7vi/5xVsrHd8/LNQdfqWuuFi38aTQdxRGJBM1isUKSsQyao716LTIAc3y+9XoegoUKqa0+sOYOqKT9Wa0QW8eaFA0XtCM2m7NrtmnqX6vIk6g3rBKBwu1chXKlZEnR65ceXLkych1jFwZ5UJPezNx/TY2VREnUI+flq9QPWG1fpOdqt2ZRu0frFVuMCI348rNSV7eyC2Y4oLiYSiVgh1BDgBghy999w2dce7gqN/X+WZUT/7zZD3+4GRuowQwoZ0a/wIeEeac4aUIfH9oSYKIFClO7S/fk3xXZjjQGQ0tY6ChfcM/S64XKuoWVO3mVePmVes4qnaiChUWlyVwc6ry8oq4geqqs5pR162zalM6u2qPWvxeRRSoN4zpN/mpGgyjOhjGVB8OqMbJaMAYHQxr1BPUqD+Iqj8T02A2oogTqq8QU2Okf2jZgpjeHJykjr5JOpiulen15Q1IfsbIyxq5uVBOPpQIdQAAaxhNnZ7XxVcd1Mwzs+/+XWExyP3b/zNVm9bH1bk7dhz7CAB2sD/QHT4ByuFhLuJL0ejQ+nIRKRpRGPNlIsXn5YznyjiSY1QMQY4zdOuipLC4hYGrXOgpE0Y0EEY0YAYUMzkFMhowrgbD4tIE+dBVXSyrpqpezYju1+zIQU33QkUcVz1hv/Jy9Upmul7PNWkwPKhqN6/BMKI38416IzNZnYP16uuPqZDzlQ887RusVX00K9cxygQRHRyoVndfjfIHquT3eIr2Oor0G/kDobxMICdfkFMIZIKgGOqGAh2ZDgBwMjrvj/q0+h9/q7qG4F2/Z9cr1Xr+6Xo9eNc0BQWJZ8YBoGjUK20+++yzuuyyyzR9+nQ5jqNHH3207LgxRqtXr9a0adNUXV2t1tZWvfbaa2VtDhw4oKVLlyoej6uhoUHXX3+9+vr6xnAWxclNdGSYq4rJVMdkaqsUxKtUSMSUmxRTtjGqzOSIMpOLf2YnFxcSlxy5BSO3ILl5R7msr3S2Sl25uH5XmKTdhWp1FIw6Co7ezNdrT36S3srWqS8bk+8GqnLzqnVzqnMC1boR1TpR1bmuap2cfCfUrwem68XB07V1oLht7z9Nr/dOVWc6rnxfVKY7ovS+Or3Z1ajXu6bqv7qatKtzst7al1B+X5X8A56i3Y4ivUaRvlD+YCg3W5CTLUj5ghSEMmFxG3qI7tjHFABwXJ2U9fQEOOPcAX3xux3vOszlMq72/Damv/kfs/RPfzt9aOkBwhwADBv1Fbr+/n6dd955+sxnPqMrr7xyxPG77rpLd999tx588EHNnj1bX/nKV7Ro0SK98sorqqqqkiQtXbpUe/fu1fr165XP5/XpT39aN9xwgx566KHRdWb4VksdmgjF8cvDXFgTU1AXVaHWU77GU6HaURBzFPrF2yplJDeQvKzkZUK5BcnLSN6Ao3x/RG/11un12JTiWnBBVXGWS7nal6/XbzNT9EZfo3oGqlUVKSgb+soYX4PGVcYUFCjUYBgOLTIe0ZuDDXo13ayoFygXeEpnq/RWX50GeqrkHvQV6XWLE7NU+cpGJCMjJ3DkZR15g44ifVK01yjaEyraG8jvz8sdzMvJ5WXyBalQGLr10hyaGAUAcFI6qerpCfL+i/q04OK0pkzLv2Pb//rPGu1+PaZN6+P6xY8aFL77i3kAMKE4xhz7jXmO4+iRRx7RFVdcIan428Tp06frlltu0Re+8AVJUk9Pj5qbm7V27Vpdc801+vWvf625c+dqy5YtuuCCCyRJTz31lD7+8Y/rzTff1PTp00d8TzabVTZ76B77dDqtGTNm6CPOFfLdWHFNOc+TE41K0Yic6upimKurUlAXVS7uK1fvKV/nKF/jKKiSwqhk3GLocQuOvIzkDxp5WSlf7ygXl3KTQplJeTU09qmlPq3m6l7V+jmFxlFPvlqpgXqluhMaHIhqcmOv5k5J6QPxDr2/6ndq8foVcUKlw4hez03V9oHT9OKBmfpdT0IyUhC6ymd9Bf0RuWlP0YOuomkj4zoKopIpXjCUE6g4AUrWKNJf3KK9gfzevLz+rJz+jJzBrEwmK5PLyeTzQ1fqAp6lA3BcFUxez+gx9fT0KB6PV7o7VjtR9VT6PTVVl8t3IsfpDI3mJfv1xbs7NPU9ubdtFYaO8llH3111ml7ZUqvf7eIZOQCnvrHW03F9hm7Xrl1KpVJqbW0t7UskElqwYIHa29t1zTXXqL29XQ0NDaXiI0mtra1yXVebN2/WJz/5yRGfu2bNGt1xxx0jv9BxiuvLOcO3W3pyIhGZWESmOloKc9lJnrJxR7m4o3y9UVgTysRCyTNS6Eh5R+6gK7/PkT9QbFNIhDL1BfmxgrJ5X3vSCb01WCvPMQpCR5lcRJnBqAo9MZnAUTparY7YJNV4OeWNpyY/XZrl8o3MFL3eP1VdfXXqP1gt9fvFJQdyjiKDjiL9jqJpo0ivkRsYhREp9Iq3kzhh8RZQL2vkD4byBgP5A3m5A3k5A1k5w0GuUJCGnqEzJiTMAYDFjlc9lX5PTT2Ozl3Yr6/9r/9Wde3bLxj+X/9Zo83r4/r///1UDQ64kuG2SgB4N8Y10KVSKUlSc3Nz2f7m5ubSsVQqpaampvJO+L4aGxtLbY60atUqrVy5svR6+LeJwxx3eD05T4r4xQlQqnwVajzl6zxl6x1lG5ziFbdEQZG6vKqqcvK9UGHoKJvzlR2IKlcVUdjrqhAP5Tbk1JDo16SaQdVFsnIkDRQiOjhYo/RAlbK9Mbm9niK9xclV8tGYOv24HEfqK1QpERlQxAk1EESVytRrb29c6Z4aOWlfkYOu3LwjN1+crdIfNIr0GUX6A3nZUKHvygwtleOEklMwcvOhvGwgN1uQm8lLmZycTE4mm5fyealQkAkIcgBwKjhe9VR655o6vozO+6M+ffG7HW8f5oz0q011uuvGmdq3J3qc+gEApy4rZrmMxWKKxUbeduE4Q1fnXFeO68nxfJmIrzDqK6jyla/xlKt3lEsUw5wm55Ro7FdzXZ+mVPepys0rbzylc9VK9dVrf7RO+UhMfn1OUxt79d6Gt3Ra1UFNigzIlVFPUK03Byfpt5FG7Sk0qNDvyc0Wg5nxfGXCar2Z93Swv0bV0bxcJ1Qu8NU/GFOmLyp1RxQ56Cp2UIr0G7l5Iy8n+ZlQ/kAgbzCQlykUl09wneIsnKGRExg5hVDKF+TkCnJyeSmXL95emcvLFArFK3TDE6IQ6AAAb+PtaurxcO7Cfq3+3m9Vlzj6A3AHuiL67atV+r/+xyzWkgOAYzSu/3q2tLRIkjo7OzVt2rTS/s7OTp1//vmlNl1dXWXvKxQKOnDgQOn979rwwuBDi4MPX6UzUU9BrDgBSqHaUaHOyCQKik8a0OxJB/QHdft0Wuygat2s8sZTVz6u30SmynWNuiTV12U0I35Qc+v26g9iXWry03JkdCCoU8IbkCQN5KPan/EV9LryBx3FDjjKF3wVMq56qqPqiYRyXMkUHCnryh1wFUm7iqalWE+oaDosriOXD+XlQrmDBbnZvJzs0IPijlucxMuY0hpzTiGQCsHQBCh5mUJQvDJXGLrVMjxsIhRCHQBY64TX0+PgvD/q1ar73jh6mDPSv/3DVLX/JKFftded+M4BwClkXAPd7Nmz1dLSog0bNpQKTjqd1ubNm7V8+XJJUjKZVHd3t7Zu3ar58+dLkp5++mmFYagFCxaM7gtdT45XvEJX3JziouG+qzBanM2yUCUFNaH82rya6nv1B3X7dE7N7/Te6D7VOXlljadUpF6+EygT+hrIR9RQPaj3VHfrvbEuvS+6T81eXq7j6K0gI8moJ6jR3uq4eqqrVYhFFHqOYt1GXtZRod9TUOUqHJ7UJJTcbHHSlUi/UbTPKJoOFU0X5A0W5OSD4pYrSMNX34wZCqoqzVhpwrC4zlwQSsHQmnOFoHhFLgyGwtzQUgWEOQCw2gmvp+OoflJBX/l/fqtZ78uoYWrhqG3+5Z4mPfiNaQryPCcHAGM16kDX19en119/vfR6165d2rZtmxobGzVz5kzddNNN+pu/+RudeeaZpWmWp0+fXpq56+yzz9bHPvYxffazn9X999+vfD6vFStW6JprrnnbGbnezv/H3r/Hx1Xd9/7/e+3LjK4zsnyRcLCBlATjgEljwFaTtGlwcYmTkuI8vpSff8RNOckvVPAImFLilkAu59R8yTlJQwukjzbFeZyGuKGPEhoSCI4JThNkLg5uDAQXKEUGW5IxSKPbzOzL+v0xo7HGEiGyZI+39Xqexz6y9t4jrb3qB5+8vdZey/iujJ8qvTvnupLjyDqOrGtk3dLWBHFKsimrurpAc9Mjelv6DZ3iv6a3eyNqdlwVbKh6J1Quqtf+dIt60hnVe4Ga3bxa3WHNdQPNc9OlrRFU0GvusLLuqBq8QJ4XKfCsrCs5oeQfjBUNHVql0pY3K3eL5amVI7H8kVjeUFjacmC4UJpGGZWmUyoMS6NvNj60YfrY9gO2PJ2yPFpXCnJxJeyVRuYIcwCQFMdTPZ1J66/v0TnvffO98A68mtITD2cIcwAwQ6Yc6J588kn97u/+buX7sRer169fr82bN+vP//zPNTw8rE996lPq7+/X+973Pj344IOVPXMk6Vvf+pauuuoqXXDBBXIcR2vXrtVtt9025cablC/5qdJG4n7p/bmxKZjWUfmwkmvlupHSbqgGp6gmJyhv+J2Sb0I1xaXzdW4g343KW3IbWRnFkmJZOZJia8vnTHlm46FiZKyUGoqlISnyTWlRk3Kgc0LJKcZy86VVKt3RQM5oUWa0UHoHLopKK1RGUWX6ZFWgG/sa20PvyFk7cTVLwhwAJMbxVE9nQmNzpBtuf1m/8a7RSa+HgdHdf92mHVszevHphmPcOgA4cU1rH7payeVyymazWtX2SXn1TbIpv3SkPVnPUVTvqTjH13Cbq9H5RoWFoZpPGtRZC/ZrZcuL+s36vTrdH1HG+CrYSK9GRv9ROEmPDb5duw6eLCOrc+bu03lN/6V3pvvU5hbkSDoY+frP4nw9NbxYT75+irr7WhW/Wq+6PkcNvbHqX4vkD4blIFmaMmmsZMJYJozlFEpTK035XTlbLErFYnkK5WEjb5WwOC6s2dJXOzYSR5ADUEPsQ3diGKup092HbuMdL+sDF78x/t86K8LA6Bv/a6Hu/ft5smxHAABVjqt96I65upRsfZ3iOl9xvae4zlOUchT7RrFjSiNjoWSC0tYEA8U6HQgy2u9nVW8C5ZxQBeuoJ2xSb5DVG8UGDRdTiiJHr45kNddfIMmov7IoSqP+q7BAr4zO0Rsj9QpHPXkFI6coOYHkhFZOPpBTjMqBzkixlYlLgU5hJBOEh1aoHJtiORboxkbc4vK7cDKl8DamHOiqQh4AADVV2jT8XecNTwhz1kpRaPStr7YR5gDgKEl0oLP1dYqa6xQ1egobPAUNjqI6oyhVen/OuiqFrRFHxeGUeocyej61QJLVQLpeTU5egfX0RtSg/cWsgthVY6qog0ON6s7NkSQdbGhSizciI6tcVKd9oy3am5ujgYFGmZwnb9jIG7Xy8lZOMZJTjGSG8zJxeVKmtaURt9iOW8wkLC1oEoZVo3OSytMoJUIbACAJzl45rC988yU1NE1czfK1fSn9/y44Q/lhhzAHAEdJogNd1OBLzb6CZk/FJkdBU2mbgqhOlVUmFUtuQYpynvpTDXrJaVUh8vR6fZNOSg9ojjesZjevd9b3ao43oiavqP+UdCDXpBfDeXpttFGNqaKMpNHQV/9IvQYH6xX3p+TnHPlDkj9i5eUjOfmxFSuD0iIn1sqOTY0cm0oZxbLx+BUqS9cIcgCAZDm0afiEMFd+S+D+/ztXwzlHk87DBADMiGQHusaUooynQtYtbR7eLIVNVnF9LOtbybFSZGSKjpyCo6g/rTe8WJm6guqbinpb6nWdnjqgjFNQYB31+M1KOaFGI1/DhZTeeL1ZQwP1cv1YMlZR4CrOuzJDnlIDRqmcUSpn5Q/FckciOfnSdEqFkWyhKMVROdSpKtRVFjaprFLJdgMAgGRZ8LZAn/uH/1Zzy8Qw99i2jP72L07W671j/7oKADhaEh3ogkZXYcZRscWoMMeq2BJLmVCphqJS6VCOsYpiR4VRX+GwLxs6SvmhMqm82lMDWuS/rlO9EWUdV4ENlTYDGvTrtDfdqqZ0Vv1qkj2YVljOWSaU/IKRO2qUGrTyh6zSuUipwUjuSFDaGPzw9+PK77xVQt3YSJyNy6N3EmEOAJA0F6x9Y2KYU6ms3XbDyXptf+rYNwoAZqFkB7oGR2GTUTFjVZwTy20tKNsyoramQWX8vHwnUj7y9Hq+UQeGmjQ0WCfHtUo7oeqdohpNoEbjqMGkFJhIjXGxtH2BU9q+wDhWCqX0QUcmlkyk0p5yeSt/xMofjuUPhvKGArkjRZl8sTxCF8qOvS8Xxzo0jVKlEDc+wBHkAAAJcso78/rzv3lZi99RqDpvrfR6r6/vbZ6nN1478tUyAQBTk+hAF9WX3psLMrGclqLmtg7q7S0H9RuNBzTfH1TahBqJU3qlMEcvpubrv02rothRMXaVj32NWk8jNi/fBgoUa8Q6Go1TKsSewtiVjY2c2MjNS+kBKycoHW7RyhuN5Y2WR+ZGizIjBSlfkC0Gpb3kymHu0F5xEiNxAIBks3r/h/t1+tkT95p7fFtG//OTp6pYMGKaJQAcO8kOdCkprLOKG2I1NBW0sDmndzT26V0Nr+okb0BpE2koTinrjkoyGg5S2p/LaKBQr74go1f9OWpwAuXiQIEc9YSN2h9k9XqxUcOFlGzRlSlvR+CNWqVzoZzAyhRjuYVITiGUyRdlCkE5zBUPTbcctwF41Z5xAAAkkONaXfLJA/qjq3urzlsrPbEto69et0jFglOj1gHA7JXoQBenSofSsZrrCmqry2lx+qBO91/TQi9QnXE0FBfkyCoX12lffVZ9Q806MNykF9ILJCsNRnVqdvMKrKsDQbNeHJmv7qE5yg3Vyww78kaN3IKVW4zlDUdyh4qllSyDUArC8jtzh+0tFx4+OkeYAwAk2/LfHtQVf7lfjltd0x7fltGX/sepCoqEOQCohUQHOmuMrCsZN5bvRmpwAzW7eTU7oTLGV9p4cpyimp2CGp2C6t1AromVG6rXy84cFSJPrwVNanCLCmNXA0G99g1n1NffrGAgLW/IkTcieXkrt1DeZy4flN6VC0IpKi98EoalPeXCQ+/NWUbmAAAnCD8d6+IrXqsKc9ZKTzyc0Vc2LCLMAUANJTrQyUomlqw1iqyjwLoqWk9F66ioSEZGBRuraH0F1lMYO4qtUTzk62Aho6GROu2vz8j3IsXWKF/0NTKcVpRLye13lR4YW80yljcSyYxtS1CeXqkoqrwvV9kcnJE5AMAJ5tr/vVfn/m6u8n1Pd0p7nmrQ/9mwWIVRwhwA1FKiA52xViaUFDgaLfrqL5bejevxBmQ0pDoTaNC66okyOhA0ayCoU6HoS0VHTr+rwrCnQjoteVaKSz/HjLryh4z8QaPUgJU/GMsfjuSOhuVtCcqjccWgNBoXlfeVG9tTjjAHADiBvPPdIzrzPSMy49Y5efDuufr2bW21axQAoCLRgS6sN4rqrKyR8kVfvflm/Zc/X46J1efllDaBhuO0uotz9V8j89Q71KziiC9nxCj9hiObk6KUU5q2aUv7zLl5I29E8oetUrlYqcFI3lAoZ6QoFQIpCKSgvC1BGE6+OThhDgBwgjjlnXktPK28RYGVHvtRRv+2eV5tGwUAqEh0oAsyVnFLpIbWEbVnc2qvH5RrYh0IMuoPG5WPPQ2HafXmm/XqUIteH2iSzflKDRulclZOIMW+ZB1JVnIiySmWVrT0RmP5Q5G8kVDucEFmtCBTKMgGQSnIjb0rFx82IkeYAwCcINJ1sc6/oDTVct9LaW3/txb9898u0OiwW+OWAQDGJDrQhU2x6rIFtWdzWtLSq3fU92mBPyDfRBqK6/RyYa72hy16ZahFB15vVvRGWn6/Iz9nSlMpR6ysI1lT2jHHRCrtM1eI5eYjuSNhaRGUkYJMoSg7NkIXRWxLAAA44c1bWNT7PjSgoGD0xf9xql76ZX2tmwQAOEyiA53qIzU3FrSoqV9nNPTorLpX1e4OK2WscrGnRqegyDo6MNqo191GxaGRN2JK0ymHrVL9gUxsZY2RsZJiKyeMZYJITjGSKQSlPeYKxdIiKEFpi4LKtgSHj84BAHAC2fB/9mrff6f08580a++L6Vo3BwAwiUQHOuPHakgV1eKPqM3L6SR3WCd5UkqempxAQ3ZAPX5WmVReqXSoom8Ve5KMZCIrJ4jlDhVLP8yWFllRGMtEUWmPucr+cuWtCarCHEEOAHBiM0Z69slG3f6XJ9e6KQCAN5HoQCdHch2rlBMp5YRKG6s648uXqzpFSptIKRPKd2I5xpbnVZamWFojSaa0SfhoQWYsoMWxFMXjtiQor2oZxeUwF1WHOUIdAOAEtfuxJr3em+z/qQAAJ7pE/1faRkZB5Go08jUcpTVoXQ3GgVIm1GAcayhOaSROKx95iiJHikv71o0dsra09UEQScXioSmU5VBn43HBzsaHRuY0bkVLAABOUHdtOqnWTQAAvIVEBzoVXA2OptWbz+jl9Fw1OgUNezmlTKzBOKWXivP1SmGODuYblc+nZAqOnKLkBJITWpnISnEpwNkgLL0jZw+N1NloXMAbv8ecRJgDAAAAUHOJDnRmxNHwcJ1ercuq3gsUWlfz/EH5JtJwlFZ3oVX/NTRPrw02Khr25I0YuXnJLZbenzNhaWPwyuhbFJVXsKxevdLaw0bkCHMAAAAAjgOJDnTeoFH0hq8DpllR7OiNQr0yqbw8Eykf+XpttEkHhpo09EaDnAFP/pCRP1LaY84txHKKkTQ+1FlbHpWLyyN1EkEOAAAAwPEq0YEulTMK33AVxHU6UHQ10FivdCqQMVZh5Kow6isc9uX0e0r1O0rlrPwhK28klpMPZYqllSxtGMlG8aEwx3YEAAAAABIg0YEunbNy00ZO4CjMp1So91Xw49JqlpGRKTilfecGjVKDVqmcVWooklfeMFzFQApDKYrK78nFh344YQ4AAADAcS7RgS7VH8lzYrl5o3DYUZSWrOfKGisTG7lFyc1L/nBpZC41FMnPBXKHijKjRZlCIFsMytsSRKUpl+wvBwAAACAhkh3ocqFkInkFR+GIUZQysm5pjzkTWzlBaQEUf8TKGymNzLnDgZyRokyhKFsMpCgsL4QSl1a8FGEOAAAAQDIkOtD5uaKcyJc34ipOO4o8R9aVZMp7zYVWTmDl5iO5hVDOaFAemSvK5gtSMZANwtK7c7E9tGUBI3QAAAAAEiDRgc4ZGpUbu3LynqzvKvYdyTGyUmnD8MjKhKXVLE0xkAqBTDGQLZTen7NhaUEUxVF5j7n4LX8nAAAAABwvEh3ozEheTuTKeq7kuXJdR9aY0qIoVjJRXNqSIIxkwlAKQtmgtBCKDcaFuZgNwwEAAAAkT6IDnc0XZCNHxnMlx5EcR8YYyZhSMBt7Ly6KSpuGh5FsFJa/xtVhjqmWAAAAABIm2YGuWJRiRzYohTkZIxmnPEJnx4W68t5yUXxoARRrCXMAAAAAEi3hgS6UjYNykDvsGB/UrK1sGl4KeWMLoJTfmSPMAQAAAEigRAc6xZFsEEpOOcRJKi1xqfLuA7b0dVx4s2NbE/DOHAAAAICES3Sgs3EsayIZ6xw6OZbrxuU0O1mAI8gBAAAASLhEBzrFsWRiWfMW2w2Q3QAAAACcgJId6MYQ2AAAAADMQs5b3wIAAAAAOB4R6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABJqSoFu06ZNOu+889Tc3KwFCxboox/9qPbs2VN1Tz6fV2dnp+bOnaumpiatXbtWvb29Vfd0d3drzZo1amho0IIFC3T99dcrDMPpPw0AAAlBTQUAzIQpBbrt27ers7NTO3bs0NatWxUEgS688EINDw9X7rn22mv1ve99T/fcc4+2b9+uffv26ZJLLqlcj6JIa9asUbFY1KOPPqpvfvOb2rx5s2666aaZeyoAAI5z1FQAwEww1lp7pB8+cOCAFixYoO3bt+u3f/u3NTAwoPnz5+vuu+/Wxz72MUnSc889pzPPPFNdXV1auXKlHnjgAX34wx/Wvn371NbWJkn6+te/rhtuuEEHDhxQKpV6y9+by+WUzWb1AV0sz/hH2nwAwDSENtAjuk8DAwPKZDK1bk7iUVMBYHaabj2d1jt0AwMDkqTW1lZJ0s6dOxUEgVatWlW5Z8mSJVq8eLG6urokSV1dXTr77LMrhUeSVq9erVwup2eeeWbS31MoFJTL5aoOAABOJNRUAMCROOJAF8exrrnmGr33ve/VWWedJUnq6elRKpVSS0tL1b1tbW3q6emp3DO+8IxdH7s2mU2bNimbzVaORYsWHWmzAQA47lBTAQBH6ogDXWdnp55++mlt2bJlJtszqY0bN2pgYKBy7N2796j/TgAAjhVqKgDgSHlH8qGrrrpK999/v37yk5/o5JNPrpxvb29XsVhUf39/1b8o9vb2qr29vXLP448/XvXzxlbsGrvncOl0Wul0+kiaCgDAcY2aCgCYjimN0FlrddVVV+nee+/Vww8/rNNOO63q+vLly+X7vrZt21Y5t2fPHnV3d6ujo0OS1NHRod27d6uvr69yz9atW5XJZLR06dLpPAsAAIlBTQUAzIQpjdB1dnbq7rvv1n333afm5ubK/PxsNqv6+npls1ldccUV2rBhg1pbW5XJZHT11Vero6NDK1eulCRdeOGFWrp0qS6//HLdeuut6unp0Y033qjOzk7+xRAAMGtQUwEAM2FK2xYYYyY9f9ddd+mP//iPJZU2Qb3uuuv07W9/W4VCQatXr9Ydd9xRNfXj5Zdf1pVXXqlHHnlEjY2NWr9+vW655RZ53q+XL1liGQBqj20LpoeaCgCQpl9Pp7UPXa1QfACg9gh0JwZqKgDUVk33oQMAAAAA1A6BDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASikAHAAAAAAlFoAMAAACAhCLQAQAAAEBCEegAAAAAIKEIdAAAAACQUAQ6AAAAAEgoAh0AAAAAJBSBDgAAAAASakqB7s4779SyZcuUyWSUyWTU0dGhBx54oHI9n8+rs7NTc+fOVVNTk9auXave3t6qn9Hd3a01a9aooaFBCxYs0PXXX68wDGfmaQAASAhqKgBgJkwp0J188sm65ZZbtHPnTj355JP64Ac/qIsvvljPPPOMJOnaa6/V9773Pd1zzz3avn279u3bp0suuaTy+SiKtGbNGhWLRT366KP65je/qc2bN+umm26a2acCAOA4R00FAMwEY6210/kBra2t+vKXv6yPfexjmj9/vu6++2597GMfkyQ999xzOvPMM9XV1aWVK1fqgQce0Ic//GHt27dPbW1tkqSvf/3ruuGGG3TgwAGlUqlf63fmcjlls1l9QBfLM/50mg8AOEKhDfSI7tPAwIAymUytm3NCoKYCwOwz3Xp6xO/QRVGkLVu2aHh4WB0dHdq5c6eCINCqVasq9yxZskSLFy9WV1eXJKmrq0tnn312pfBI0urVq5XL5Sr/IjmZQqGgXC5XdQAAcKKgpgIAjtSUA93u3bvV1NSkdDqtT3/607r33nu1dOlS9fT0KJVKqaWlper+trY29fT0SJJ6enqqCs/Y9bFrb2bTpk3KZrOVY9GiRVNtNgAAxx1qKgBguqYc6M444wzt2rVLjz32mK688kqtX79ezz777NFoW8XGjRs1MDBQOfbu3XtUfx8AAMcCNRUAMF3eVD+QSqV0+umnS5KWL1+uJ554Ql/72td06aWXqlgsqr+/v+pfFHt7e9Xe3i5Jam9v1+OPP17188ZW7Bq7ZzLpdFrpdHqqTQUA4LhGTQUATNe096GL41iFQkHLly+X7/vatm1b5dqePXvU3d2tjo4OSVJHR4d2796tvr6+yj1bt25VJpPR0qVLp9sUAAASjZoKAJiqKY3Qbdy4URdddJEWL16swcFB3X333XrkkUf0wx/+UNlsVldccYU2bNig1tZWZTIZXX311ero6NDKlSslSRdeeKGWLl2qyy+/XLfeeqt6enp04403qrOzk38tBADMKtRUAMBMmFKg6+vr08c//nHt379f2WxWy5Yt0w9/+EP93u/9niTpq1/9qhzH0dq1a1UoFLR69Wrdcccdlc+7rqv7779fV155pTo6OtTY2Kj169fri1/84sw+FQAAxzlqKgBgJkx7H7paYM8cAKg99qE7MVBTAaC2arYPHQAAAACgtgh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQ0wp0t9xyi4wxuuaaayrn8vm8Ojs7NXfuXDU1NWnt2rXq7e2t+lx3d7fWrFmjhoYGLViwQNdff73CMJxOUwAASCzqKQDgSB1xoHviiSf0d3/3d1q2bFnV+WuvvVbf+973dM8992j79u3at2+fLrnkksr1KIq0Zs0aFYtFPfroo/rmN7+pzZs366abbjrypwAAIKGopwCA6TiiQDc0NKR169bp7//+7zVnzpzK+YGBAX3jG9/QV77yFX3wgx/U8uXLddddd+nRRx/Vjh07JEkPPfSQnn32Wf3TP/2T3v3ud+uiiy7Sl770Jd1+++0qFosz81QAACQA9RQAMF1HFOg6Ozu1Zs0arVq1qur8zp07FQRB1fklS5Zo8eLF6urqkiR1dXXp7LPPVltbW+We1atXK5fL6Zlnnpn09xUKBeVyuaoDAICkO9b1VKKmAsCJxpvqB7Zs2aKf//zneuKJJyZc6+npUSqVUktLS9X5trY29fT0VO4ZX3zGro9dm8ymTZv0hS98YapNBQDguFWLeipRUwHgRDOlEbq9e/fqM5/5jL71rW+prq7uaLVpgo0bN2pgYKBy7N2795j9bgAAZlqt6qlETQWAE82UAt3OnTvV19en97znPfI8T57nafv27brtttvkeZ7a2tpULBbV399f9bne3l61t7dLktrb2yes0jX2/dg9h0un08pkMlUHAABJVat6KlFTAeBEM6VAd8EFF2j37t3atWtX5Tj33HO1bt26yp9939e2bdsqn9mzZ4+6u7vV0dEhSero6NDu3bvV19dXuWfr1q3KZDJaunTpDD0WAADHL+opAGCmTOkduubmZp111llV5xobGzV37tzK+SuuuEIbNmxQa2urMpmMrr76anV0dGjlypWSpAsvvFBLly7V5ZdfrltvvVU9PT268cYb1dnZqXQ6PUOPBQDA8Yt6CgCYKVNeFOWtfPWrX5XjOFq7dq0KhYJWr16tO+64o3LddV3df//9uvLKK9XR0aHGxkatX79eX/ziF2e6KQAAJBb1FADw6zDWWlvrRkxVLpdTNpvVB3SxPOPXujkAMCuFNtAjuk8DAwO8h5Vg1FQAqK3p1tMj2ocOAAAAAFB7BDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQXq0bgAQwb3HdHpNWAAAAADgMgQ4TGVP11ZhxA7lj4a4qxFlZWz5x+FcAAAAARw2BDoeMD3LGyBgjyUiOOXRNphTqrEr/n5VkrYyNJUk2tqpKewQ7AAAA4Kgh0KFkfIgzRjJO6XvHORToxh/WVh02jqU4ljFWiq2sKV8bu3cyhD0AAABgWgh0GBfmHMkpBznXkVy3FOjcsfNO+V4dCnOxleJYiiMpiqUokjWxzNj1sRE9qSrAWWvHjfIxTRMAAAA4EgS62e6wMGc8t/zVkzy3FOpcd1yoGzdCF8elQBdFpSOMZKNIJgxL10q/YEKgs7E9FPjsuNE8Vd8HAAAA4Fcj0M1m48Oc65SCm+eVwpzvyfi+5HuynlsOd47suEBn4rg0KhdGMkEoBaEUBJLjyEZR+VeMe//OlhZPMZUwGJfDXSkYWsVvPU0TAAAAQAWBbrZ6szCX8mVSKSnly6Z82bQvm/JkfVexXxqhs0Yy1spEViaM5RQjqRhKhUCm6MoWA5koOjR9sxzoDoW38lGeolmZphkbWRszBRMAAAD4NRHoZqPy6pWVaZZjYc4vh7l0SrY+rbjOV1zvK6pzFaccRb4j66o0i9JKJrRyAis3H8nNu3J8Vxp1Sj/XxqVA55RG9YysTHxoZO7Q9MxINgxlokg2jGRilULdJO/dAQAAAKhGoJutjErBzjGl9+R8XyadkurTsvVpRY1pRY2+ggZXYYOjsM4oShtZV6URulhyQsktWHmjrvwRV96wJ9d15DiO5EjWdSXXlKZpSqVAF8UyYSQFkUwQlKdpOqWvxpTCnVRaNXOsnYQ6AAAAYFIEutmmsll4KcwZ1y0thOJ7pWmWdWlFDWmFzSkVm10FTY6CJqOw3iisk6wnWWNlYiOnKHl5I2/EKk4ZxZ5RykhyjKznKPYcWc+UR+gkxVZOGMsUYznFUCq4UjGUcRxZle+xVqW1MW1pTzuyHAAAAPCmCHSzkXEOHePenbPplOKGlMImX8Wsp0LGUSFrFGSswsZYUYOV/PJ0yNjIFIzcEUf+oFGUkmLPlSS5KUdx2lHkG8W+kXXKUzQjyQmt3EIsN+/JHfHk5EuLqBin/G5eqYGltVE0bqSOUToAAABgAgLdbFR6hU7GcUr7zXmerF9aACWq9xQ2uio2l8JcodUqaIllMqHSDUWl06EcEyuMXOXzvsJhX3Hak3UdSZITugrrHIUNpSmasS9Zp/xrQ8ktSl7ekTfqyPcdeZ4jV4emZNryVgYmjmTtuC0SAAAAAExAoJuFStMtxzYML+0zZ31PNu0pqvcUNLoqNknFrFUwJ5Y7t6A52SG1NQ0qm8rLN5Hyka/X8o06MNSkQa9RRfkykSMnlGSMgkajqF6KUra0kIode+fOyBsx8ofLo3duKcy5spKNS1shxLFs5JaCnbWVd/AIdgAAAEA1At2sMzY8Vz5cR/Lc0rYEqfLoWr0pvTfXHMtpKWrenEH9RstrOr3xgOb7OaVMpOE4pVfyrXoxNU8vScqFTQoKvkxoFKekIGMVNcRSXSTj2VIWCxyZUUfekKOozige29cuLo3OuWFp9cvKwilxXJpyySgdAAAAMCkC3SxlZGQcU3qPzikFu9h3FKeMorQU1VnFjbGamgp6W/OA3tnYq3fVv6qTvFKgG4pTyrqjkqShYlojI2lF9a7CwFHQbGVbAqWbimqsLyjlRYqtlC/6GhlNK6hLKfY9yRqZWHIDV27gyRQ8OUVPJghLK2RGUWkfO7E2CgAAADAZAt1sVB6kUznUWceRdR1Zt7RSZexLcUpSOlJTXV5tdTktTh/Ub6QOaqEbKW2MBuOiJGmgrl6v1rWoty6jobq0AlmptajWuUNqb86pvS6nRq+oyDrqD+rVM5LRfj+jUbdexciXiYzcgintY5f35BT80iblrlPemHxsRRXLKB0A4ITynt8e1LyTAlkr/cfPmtTQHOm/n6uvdbMAJAyBblYqv5M2Nu1S5eUlyytNWsfIOlbGtfLdSHVOoEanoCYTqdl4ShlPcgpqcopqdIqqcwO5biTrWqk5VHN2VIuzb+gdTX06pe6gMu6IIuvqQNisl/x5iq3RvshRcdSVO+oqqjOK6hzFvivrlRdqKa98KcfIxrXsKwAAjo4olD7z/+6V61vteapBdQ2x9r2UVtdDGT3y3TmKIqMoNLVuJoDjHIFuVrKHvlpb/ioptjLlb0trlBhF1lFgXRWtp4I1yiuStVLBxipYV4XYU2BdxXFpKUuvMdC8piGd3nRAZzW8qnek+tTiFhVao56oUXUm0EiY0nAxpQODaUX1jsI6KfKNrO/Ieq6s45T2pjNOdbOZewkAOIH8cmej/vMXDVp67rCWvGdEknTqkrzOX5VT5/96Vbt+2qTv/995kqSXflmnA/tStWwugOMUgW42Gh/arJWJbSnMxZKJrJzQygmlMHA0Wkipv9ig3iCj/V5O0pDSJtRQ7KknzOhA2KyBYp2KRU+yUioVKpPOa76f00l+v0728mpxPIWK5WpIA36/WlPz1JQq6GAqUux55U3IbWnFy/KG55XRw7ERxMpBogMAnBiKBUe3dJ6iz/7ty1p67nBlAo3nW3m+1coLc1p5YU6StHtHkx7f1qzv3L5AlRsBQAS6WczKjtsmwESRTBjLCazcouSOGjkjjoaG67S3vkUNXlGSUa8/oJQJNRTXqbswVy8Oz1fvULOKBU/GtXKcWCknUp0Tqt4EqjdG9cZXqFj1TkF1TqC0E8pzYhnHyjqSLWc1W8ltY2FOla/GGNmxAsa7dACAE0Tv3pRuWn+a/vFnzykzJ3zT+85eOaQzlw+reU6k//vldhULzpveC2B2IdDNSrZqZE5xXApzxUhuIS5t/D1iFA05CupT6vUzkqSRMKWW1Fz5JtJonFJfvlmvDmY1XEyrsSkvNxvLcawKkafR2NdInNKwHZVviwqt1XDsaCROKR/7CmJXNh7bsmDcuidjIc4xkuOW36VzZOOxi4Q5AMCJZWjA1Y/+ZY4u+eSBX3mf51v9P3/apx9uadUrL9Qdo9YBON4R6Gad8WEuluKotPdbEMophvJGfUXDsVJ1pY2/Y89TXvXaF7gaGK1XQ6oo14kVRK5GgpRcE+vkbL9a0yNKu6GKsavRyNf+YlZzvValTKgWt6DQOuqNmrW32KoDhWYN5tOKi6688svesStFaSM37clJezJFXyaKpTCUjSLJxGxHBwA4IVlrtHnTSWpsjrT6j15/y/v/v9f26pbOxWLqJQCJQDd72XKgi2LZMJQphlI+lDsayPeN4lRpOwPJKAg9haOO3mhIqd8vTZWUZ9WSGdapLa/r9KYDWpjuV71TVCH21Rtk9Gq+RU+PvE2DcZ0yzqgiuToQNOuVwhy9XmxQFDsyqVhhY6wg78gJjNyiK7dg5RR9mUIoE47bvsApz8kk1QEATkCFvKNHH8jqvRcNqCkb/cp7/+tZRucAHEKgm43KK1taa6UokgkjKQikoitn1JVX3pNOkkxcDlsjbmlrgZQUNcfy546qrWlQv1FezXKxf1CNTqBR62mfn5UkvTA8X68XG5X1RzXHH1HKhJrvD8prKm2F8LJj9YaaFAQpOQVH3qjkjThy064c35VxXclxZRxHGv8OHQAAJ6AdW7P639cs1mdvf1l1DW++Z8/v/39eLy+OAgAEutmnPLpljS0tiBJFsmEoBY5M+d01t3yriaycoitv1FFYbxQ0GBXmWEVzYtXXFzWvbliL0m/o7akDOs0bVaPjaNQWVW9CDaQbdKDYrELkaWF6QKel+9TqDiu2jvrCjOb68yVJYeQoN+oqHDEKh0vTLuOx7Qtc99DonOOUXrYDAOAE1vXDjO7+Wpv+ZOP+WjcFQEIQ6GYrW9qDzpZXuFQQysqURsMkuZJMFMsJfLkFV07oKEo7kiPJtfLcWPVuoEYnryYnULPjqsGk5ClQsxOq0Smo3ilqXmpQb0/36Z2pA5rrhIoltbijspJeq2/Sa/VNGqxrUJz2FKfG3ttzylMtjYxjZA0jcwCA2cLoZz/I6oJL3tApZ+Qnv6O8blj8q2dmApglWPN2NhoX5hTHsmEkGwRSUJTNF2RG8jJDebkDeXkDeXkjoUyoQ/vXxUZxbMZtOO6qYGMVFZY3HHcUWE+RHLW4I1rgDqrNDdXmptXmptTmFrTAG1SLP6oGvyjXjxR7VrFbWhxFrmSdsZUujWScQ9sYMO0SAHCCe+XFOn3u8rcrjievee2Li/r4n/Uc41YBOF4R6GYzW36PLo5lo0g2CKUgkC0WZUbzMqMFmSCSia2c2MqJJCc0UmBUKPoaKNbpQJBRT9isfZGjfWGofZHR/rBJvUFGhdgr5TFZOTLl/ze2RbgtHcZOyGgseQIAmO3eeM3Tw//aMmlRdByr81fldNIphWPeLgDHH6ZczlbWVlaMtDaW0bjFI+PSu2rGdWWiWCaI5RStnILk5iVn1FF+OKX9Qxk1+fPlmlj9UYManKLy1ldPkNULIwt0sNCotlROB6NGHYjyilVQbK1ei3wdjJqUC+s0GqQUB45MZEqBsbIv3dgeeVaycXlUUSLuAQBmg2Le0W03LFJh1NFF616X41TXv99416jedd6w9r+cErNXgNmNQDebjSU4o1Koi61spNLiKOXpmAojOUEspxjLy9vSSpRDRsW0r4PpJhkj5SNf+9ItqnMCFWJPbwQN2js4R0HsKOvPUdYblSS1uiOKZdQbZvRSYb72jbaof7ROcd6TX1ApNAZWTmilKJbi8ggiGQ4AMAsVRh3d/pcny09ZXXjpxP3pPnXzPj187xzepQNmOQLdbDcW6qyVNeZQmItK0zBNGMkUQ7l5T/6IqyhdWhzFuo4Cp059oaPhfFqv1LXIdyOFsaORQkpDw3Vy3Fiv+C1KuZEKsa+MOyIro4Nhk7pHW7V/OKPh4TqZEUdu3sgtBzoTxqWRwTguvec3NlpHsgMAzDJRaPTwv87R+z/cr/rG6tWeHVfKzAnV/5pfo9YBOB4Q6HBo+qUkWVUWSyntTxfKFAK5o668lKOU5yn2Spt8m9hVkK9TbiilXLpBxrGysZENHDmpSNn5I3pb44B+o75Pb08fKG1bIKO+MCNPsQaDtIbyaQ00pEpBMSXFvpH1SoHROuVNxcvbKShiSgkAYPZ56t+b9NfXL9KG/7NX6fpDoa65JdT/uHG//vc1i2vYOgC1RqBDSWWkLpaskaJIikLZIJAZ23Dcc2UdI+sYmdiRiSR31FE0ZBSnXFlHUizFdVZepqA59SM6ue4NvT19oLxtQaRYUtbJK5bRgaBJrzU0KTd+2wKvdFS2LTBGlhwHAJjVjB75bovSdbGu2vSqUmn2ZQVwCIEOVay15XfpIil0ZJxAckqbjjuOkW+tjJXcoiu34Ciqk8J0eWTNkcJGKd8Yy/cjNfpFtfgjmu8OaoEba66TViyrWEUddAeV9UbV4JW2LYg8q9g1il3JOirtPce2BQAAlBn98J9bVSw4+sDFb2jlhblaNwjAcYJAh2pWh95ZK4c6awIZU9rk27FWnpWcwJNTdBXVOYp8I+sZBY1GYaMpTduc6u8ch8gGAMAkrNGP752jHQ9ldP6qnP7wf7ym7//fubVuFYAaI9DhEGsPrXhpJVtZNau0IImxtrRYSRjLKXhyRn3ZlKPYdxU2uorSnkwomdAoDFwNB2m9ETToQKpZc6K8IltQLKkvSum1qFkDYb2Gg5Si0JUTlrctiCTFkonZtgAAgMmMDrvaft8c7Xgoq8Io/wwKzHYEOlQrv0tnYyujWFaqbAduJSkuhToFntxiKOu5MvW+olSdnMDKLRq5BaMw7+uN0Xq9kh+/bcHwoW0L8vO1bzSr3Gi97KgrZ2zbgrC8bUHMtgUAAPwqhVGn1k0AcBwg0GEiayXFsrFTDnWhpFLIMmPbGQSuVPSktC/Hc+UGsdyClTdq5Y0YhTlP/alG/Zc3V1Hs6GB9kzJeXrE1eiNs0CsjLeoeaNVgrl7OkCtvxMjLW7kFK6cYyQTRoW0Lxg5LsgMAAADGI9BhchNCncpTIOPyu3Wu5McyriMFoZx8JG+0FMz8QaOozlHgptSrrEaDlHrqm9XgBbIyGiqm1D9ar8H+BsX9KaVyRv6QlTdi5Y3Gcgql/e8UhlIUycZxaaSOoToAAACgCoEOb64S6oyMlWRseRXM0siZcUphTsVQTj6UN+IqlXZkPavYN1LsKozq9Pqor1x9g1wvkrVSFLiKRj2ZQU+pnFG63yg1GMsfiuWOhnIKpZ+pMJKiuDL9svQeHaEOAAAAGEOgw6829k6dSvvTGWtlbWkbA0WhbOjKFILStEvfke8ZWeNJcuQERkHBVdjgKE57itzSjzSB5BeMvGEjf9gqlYuVHoiVGgrljgQy+UCmGMgGYWn7hPJ0S7IcAAAAUI1Ah7dWSVJWVkbGGtkolsJIxgklN5ApOHJcR75TXkLFunICR27eKKozilJGthzonFByipI3auWPWPlDsfzBUO5QUc5IUaZQlA2CqimXYsolAAAAMAGBDr+eccNjY9saKIpkw1AqmtLG4+XrXhTLBL68UVd+vasobRT7UjwW9iIrJ5C8fCw3H8sbCeWOhHJGCjKjBSlfkIqBbBiWgmNsZStbFxDqAAAAgDEEOkxdOVjZOC4tXmJMaeROkiNV7VXn5l3FvqPYczSW+ExkZUIrt1haAMXJBzKFQCZflPIF2XKY07jplgzOAQAAABMR6DA1lX3qYhnp0JYGpbMy5ZDnBKGcgic76sl6jqzrSKa8+Wk8tkF5aXsCFQKZIJAtBlJQendO496fszYu/Q5G5wAAAIAqBDpM3ZtsPm6tLa1GWQ5rKnqS55a2NnBMVaArhbqotJJlGJZG5IKwMjJXFeaYagkAAABMikCHIzPJ5uPGlrcziCLZKJQcV3Kd0vYGjpGMo9IG5eUpm1EsxdGhABdG5XMxYQ4AAAD4NRDocOTG71On0ohd1ebjTinMWcdIMqVQJ43bUy4ufWZsNG7cfnOEOQAAAOCtEegwPePeqStPvCyFMWNKYc6Up1qa8VMu48pnS9M043ELrYyFOMIcAAAA8Fact77lkM9//vMyxlQdS5YsqVzP5/Pq7OzU3Llz1dTUpLVr16q3t7fqZ3R3d2vNmjVqaGjQggULdP311ysMw5l5GtSGHT/iVh5pK29pYMOwtEF4MZAtFktHEFaOyl5zUflzLIACYJagpgIAZsKUR+je9a536Uc/+tGhH+Ad+hHXXnutvv/97+uee+5RNpvVVVddpUsuuUQ/+9nPJElRFGnNmjVqb2/Xo48+qv379+vjH/+4fN/XX/3VX83A46Bmxgcwa0vrXo4flftVnzvsswAwW1BTAQDTNeVA53me2tvbJ5wfGBjQN77xDd1999364Ac/KEm66667dOaZZ2rHjh1auXKlHnroIT377LP60Y9+pLa2Nr373e/Wl770Jd1www36/Oc/r1QqNenvLBQKKhQKle9zudxUm41jhXAGAL82aioAYLqmNOVSkp5//nktXLhQb3/727Vu3Tp1d3dLknbu3KkgCLRq1arKvUuWLNHixYvV1dUlSerq6tLZZ5+ttra2yj2rV69WLpfTM88886a/c9OmTcpms5Vj0aJFU202AADHHWoqAGC6phToVqxYoc2bN+vBBx/UnXfeqZdeeknvf//7NTg4qJ6eHqVSKbW0tFR9pq2tTT09PZKknp6eqsIzdn3s2pvZuHGjBgYGKsfevXun0mwAAI471FQAwEyY0pTLiy66qPLnZcuWacWKFTrllFP0ne98R/X19TPeuDHpdFrpdPqo/XwAAI41aioAYCZMecrleC0tLXrnO9+pF154Qe3t7SoWi+rv76+6p7e3t/J+QHt7+4QVusa+n+wdAgAAZgtqKgDgSEwr0A0NDenFF1/USSedpOXLl8v3fW3btq1yfc+ePeru7lZHR4ckqaOjQ7t371ZfX1/lnq1btyqTyWjp0qXTaQoAAIlGTQUAHIkpTbn8sz/7M33kIx/RKaecon379unmm2+W67q67LLLlM1mdcUVV2jDhg1qbW1VJpPR1VdfrY6ODq1cuVKSdOGFF2rp0qW6/PLLdeutt6qnp0c33nijOjs7mf4BAJhVqKkAgJkwpUD3yiuv6LLLLtPBgwc1f/58ve9979OOHTs0f/58SdJXv/pVOY6jtWvXqlAoaPXq1brjjjsqn3ddV/fff7+uvPJKdXR0qLGxUevXr9cXv/jFmX0qAACOc9RUAMBMMNYmb7OwgYEBtbS06H36kDz5tW4OAMxKoQL9VD9Qf3+/stlsrZuDI0RNBYDamm49nfLG4seDgwcPSpJ+qh/UuCUAgMHBQQJdglFTAeD4cKT1NJGBrrW1VZLU3d3N/4gYJ5fLadGiRdq7d68ymUytm3NcoE8mok8mok8m91b9Yq3V4OCgFi5cWIPWYaZQUyfivwkT0SeTo18mok8mOtr1NJGBznFKi3Nms1n+okwik8nQL4ehTyaiTyaiTyb3q/qFAJB81NQ3x38TJqJPJke/TESfTHS06um0ti0AAAAAANQOgQ4AAAAAEiqRgS6dTuvmm29mn53D0C8T0ScT0ScT0SeTo19mB/7vPBF9MhF9Mjn6ZSL6ZKKj3SeJ3LYAAAAAAJDQEToAAAAAAIEOAAAAABKLQAcAAAAACUWgAwAAAICEItABAAAAQEIlMtDdfvvtOvXUU1VXV6cVK1bo8ccfr3WTjpqf/OQn+shHPqKFCxfKGKPvfve7Vdettbrpppt00kknqb6+XqtWrdLzzz9fdc/rr7+udevWKZPJqKWlRVdccYWGhoaO4VPMrE2bNum8885Tc3OzFixYoI9+9KPas2dP1T35fF6dnZ2aO3eumpqatHbtWvX29lbd093drTVr1qihoUELFizQ9ddfrzAMj+WjzJg777xTy5YtUyaTUSaTUUdHhx544IHK9dnWH5O55ZZbZIzRNddcUzk3G/vl85//vIwxVceSJUsq12djn8xms6meStTUw1FPJ0dNfWvU1OOsntqE2bJli02lUvYf//Ef7TPPPGM/+clP2paWFtvb21vrph0VP/jBD+xf/uVf2n/913+1kuy9995bdf2WW26x2WzWfve737X/8R//Yf/gD/7AnnbaaXZ0dLRyz+///u/bc845x+7YscP++7//uz399NPtZZdddoyfZOasXr3a3nXXXfbpp5+2u3btsh/60Ifs4sWL7dDQUOWeT3/603bRokV227Zt9sknn7QrV660v/Vbv1W5HoahPeuss+yqVavsU089ZX/wgx/YefPm2Y0bN9bikabt3/7t3+z3v/99+5//+Z92z5499i/+4i+s7/v26aefttbOvv443OOPP25PPfVUu2zZMvuZz3ymcn429svNN99s3/Wud9n9+/dXjgMHDlSuz8Y+ma1mWz21lpp6OOrp5Kipvxo1teR4qqeJC3Tnn3++7ezsrHwfRZFduHCh3bRpUw1bdWwcXnziOLbt7e32y1/+cuVcf3+/TafT9tvf/ra11tpnn33WSrJPPPFE5Z4HHnjAGmPsq6++eszafjT19fVZSXb79u3W2lIf+L5v77nnnso9v/zlL60k29XVZa0tFXXHcWxPT0/lnjvvvNNmMhlbKBSO7QMcJXPmzLH/8A//MOv7Y3Bw0L7jHe+wW7dutb/zO79TKT6ztV9uvvlme84550x6bbb2yWw1m+uptdTUyVBP3xw1tYSaesjxVE8TNeWyWCxq586dWrVqVeWc4zhatWqVurq6atiy2njppZfU09NT1R/ZbFYrVqyo9EdXV5daWlp07rnnVu5ZtWqVHMfRY489dszbfDQMDAxIklpbWyVJO3fuVBAEVf2yZMkSLV68uKpfzj77bLW1tVXuWb16tXK5nJ555plj2PqZF0WRtmzZouHhYXV0dMz6/ujs7NSaNWuqnl+a3X9Pnn/+eS1cuFBvf/vbtW7dOnV3d0ua3X0y21BPJ6KmUk8nQ02tRk2tdrzUU28GnuWYee211xRFUdWDS1JbW5uee+65GrWqdnp6eiRp0v4Yu9bT06MFCxZUXfc8T62trZV7kiyOY11zzTV673vfq7POOktS6ZlTqZRaWlqq7j28Xybrt7FrSbR79251dHQon8+rqalJ9957r5YuXapdu3bNyv6QpC1btujnP/+5nnjiiQnXZuvfkxUrVmjz5s0644wztH//fn3hC1/Q+9//fj399NOztk9mI+rpRLO9plJPq1FTJ6KmVjue6mmiAh1wuM7OTj399NP66U9/Wuum1NwZZ5yhXbt2aWBgQP/yL/+i9evXa/v27bVuVs3s3btXn/nMZ7R161bV1dXVujnHjYsuuqjy52XLlmnFihU65ZRT9J3vfEf19fU1bBmAWqKeVqOmVqOmTnQ81dNETbmcN2+eXNedsEJMb2+v2tvba9Sq2hl75l/VH+3t7err66u6HoahXn/99cT32VVXXaX7779fP/7xj3XyySdXzre3t6tYLKq/v7/q/sP7ZbJ+G7uWRKlUSqeffrqWL1+uTZs26ZxzztHXvva1WdsfO3fuVF9fn97znvfI8zx5nqft27frtttuk+d5amtrm5X9criWlha9853v1AsvvDBr/67MRtTTiWZzTaWeTkRNrUZNfWu1rKeJCnSpVErLly/Xtm3bKufiONa2bdvU0dFRw5bVxmmnnab29vaq/sjlcnrssccq/dHR0aH+/n7t3Lmzcs/DDz+sOI61YsWKY97mmWCt1VVXXaV7771XDz/8sE477bSq68uXL5fv+1X9smfPHnV3d1f1y+7du6sK89atW5XJZLR06dJj8yBHWRzHKhQKs7Y/LrjgAu3evVu7du2qHOeee67WrVtX+fNs7JfDDQ0N6cUXX9RJJ500a/+uzEbU04lmY02lnv76qKnU1LdS03o61RVdam3Lli02nU7bzZs322effdZ+6lOfsi0tLVUrxJxIBgcH7VNPPWWfeuopK8l+5StfsU899ZR9+eWXrbWlJZZbWlrsfffdZ3/xi1/Yiy++eNIlln/zN3/TPvbYY/anP/2pfcc73pHYJZattfbKK6+02WzWPvLII1VLxY6MjFTu+fSnP20XL15sH374Yfvkk0/ajo4O29HRUbk+tlTshRdeaHft2mUffPBBO3/+/MQunfvZz37Wbt++3b700kv2F7/4hf3sZz9rjTH2oYcestbOvv54M+NX5LJ2dvbLddddZx955BH70ksv2Z/97Gd21apVdt68ebavr89aOzv7ZLaabfXUWmrq4aink6Om/npme009nupp4gKdtdb+zd/8jV28eLFNpVL2/PPPtzt27Kh1k46aH//4x1bShGP9+vXW2tIyy5/73OdsW1ubTafT9oILLrB79uyp+hkHDx60l112mW1qarKZTMZ+4hOfsIODgzV4mpkxWX9IsnfddVflntHRUfunf/qnds6cObahocH+4R/+od2/f3/Vz/nv//5ve9FFF9n6+no7b948e91119kgCI7x08yMP/mTP7GnnHKKTaVSdv78+faCCy6oFB5rZ19/vJnDi89s7JdLL73UnnTSSTaVStm3ve1t9tJLL7UvvPBC5fps7JPZbDbVU2upqYejnk6Omvrrme019Xiqp8Zaa6c2pgcAAAAAOB4k6h06AAAAAMAhBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASKiaBbrbb79dp556qurq6rRixQo9/vjjtWoKAACJRk0FgNmrJoHun//5n7VhwwbdfPPN+vnPf65zzjlHq1evVl9fXy2aAwBAYlFTAWB2M9Zae6x/6YoVK3Teeefpb//2byVJcRxr0aJFuvrqq/XZz372LT8fx7H27dun5uZmGWOOdnMBAJOw1mpwcFALFy6U4zCDv1aoqQCQbNOtp95RaNOvVCwWtXPnTm3cuLFyznEcrVq1Sl1dXZN+plAoqFAoVL5/9dVXtXTp0qPeVgDAW9u7d69OPvnkWjdjVqKmAsCJ40jr6TEPdK+99pqiKFJbW1vV+ba2Nj333HOTfmbTpk36whe+MOH8+/QhefKPSjsBAL9aqEA/1Q/U3Nxc66bMWtRUAEi+6dbTYx7ojsTGjRu1YcOGyve5XE6LFi2SJ1+eofgAQE2UJ+wzTS9ZqKkAcJyZZj095oFu3rx5cl1Xvb29Ved7e3vV3t4+6WfS6bTS6fSxaB4AAIlBTQUAHPO32FOplJYvX65t27ZVzsVxrG3btqmjo+NYNwcAgMSipgIAajLlcsOGDVq/fr3OPfdcnX/++frrv/5rDQ8P6xOf+EQtmgMAQGJRUwFgdqtJoLv00kt14MAB3XTTTerp6dG73/1uPfjggxNe6gYAAL8aNRUAZrea7EM3XblcTtlsVh/QxbzADQA1EtpAj+g+DQwMKJPJ1Lo5OELUVACorenWU3aCBQAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEJNOdD95Cc/0Uc+8hEtXLhQxhh997vfrbpurdVNN92kk046SfX19Vq1apWef/75qntef/11rVu3TplMRi0tLbriiis0NDQ0rQcBACBJqKcAgJkw5UA3PDysc845R7fffvuk12+99Vbddttt+vrXv67HHntMjY2NWr16tfL5fOWedevW6ZlnntHWrVt1//336yc/+Yk+9alPHflTAACQMNRTAMBMMNZae8QfNkb33nuvPvrRj0oq/WviwoULdd111+nP/uzPJEkDAwNqa2vT5s2b9Ud/9Ef65S9/qaVLl+qJJ57QueeeK0l68MEH9aEPfUivvPKKFi5c+Ja/N5fLKZvN6gO6WJ7xj7T5AIBpCG2gR3SfBgYGlMlkat2cRKtVPZWoqQBQa9OtpzP6Dt1LL72knp4erVq1qnIum81qxYoV6urqkiR1dXWppaWlUnwkadWqVXIcR4899tikP7dQKCiXy1UdAACcqI5WPZWoqQBwopnRQNfT0yNJamtrqzrf1tZWudbT06MFCxZUXfc8T62trZV7Drdp0yZls9nKsWjRoplsNgAAx5WjVU8laioAnGgSscrlxo0bNTAwUDn27t1b6yYBAJBI1FQAOLHMaKBrb2+XJPX29lad7+3trVxrb29XX19f1fUwDPX6669X7jlcOp1WJpOpOgAAOFEdrXoqUVMB4EQzo4HutNNOU3t7u7Zt21Y5l8vl9Nhjj6mjo0OS1NHRof7+fu3cubNyz8MPP6w4jrVixYqZbA4AAIlEPQUA/Lq8qX5gaGhIL7zwQuX7l156Sbt27VJra6sWL16sa665Rv/zf/5PveMd79Bpp52mz33uc1q4cGFl5a4zzzxTv//7v69PfvKT+vrXv64gCHTVVVfpj/7oj37tFbkAAEg66ikAYCZMOdA9+eST+t3f/d3K9xs2bJAkrV+/Xps3b9af//mfa3h4WJ/61KfU39+v973vfXrwwQdVV1dX+cy3vvUtXXXVVbrgggvkOI7Wrl2r2267bQYeBwCAZKCeAgBmwrT2oasV9swBgNpjH7oTAzUVAGrruNqHDgAAAABw7BDoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChphToNm3apPPOO0/Nzc1asGCBPvrRj2rPnj1V9+TzeXV2dmru3LlqamrS2rVr1dvbW3VPd3e31qxZo4aGBi1YsEDXX3+9wjCc/tMAAJAQ1FQAwEyYUqDbvn27Ojs7tWPHDm3dulVBEOjCCy/U8PBw5Z5rr71W3/ve93TPPfdo+/bt2rdvny655JLK9SiKtGbNGhWLRT366KP65je/qc2bN+umm26auacCAOA4R00FAMwEY621R/rhAwcOaMGCBdq+fbt++7d/WwMDA5o/f77uvvtufexjH5MkPffcczrzzDPV1dWllStX6oEHHtCHP/xh7du3T21tbZKkr3/967rhhht04MABpVKpt/y9uVxO2WxWH9DF8ox/pM0HAExDaAM9ovs0MDCgTCZT6+YkHjUVAGan6dbTab1DNzAwIElqbW2VJO3cuVNBEGjVqlWVe5YsWaLFixerq6tLktTV1aWzzz67UngkafXq1crlcnrmmWcm/T2FQkG5XK7qAADgREJNBQAciSMOdHEc65prrtF73/tenXXWWZKknp4epVIptbS0VN3b1tamnp6eyj3jC8/Y9bFrk9m0aZOy2WzlWLRo0ZE2GwCA4w41FQBwpI440HV2durpp5/Wli1bZrI9k9q4caMGBgYqx969e4/67wQA4FihpgIAjpR3JB+66qqrdP/99+snP/mJTj755Mr59vZ2FYtF9ff3V/2LYm9vr9rb2yv3PP7441U/b2zFrrF7DpdOp5VOp4+kqQAAHNeoqQCA6ZjSCJ21VldddZXuvfdePfzwwzrttNOqri9fvly+72vbtm2Vc3v27FF3d7c6OjokSR0dHdq9e7f6+voq92zdulWZTEZLly6dzrMAAJAY1FQAwEyY0ghdZ2en7r77bt13331qbm6uzM/PZrOqr69XNpvVFVdcoQ0bNqi1tVWZTEZXX321Ojo6tHLlSknShRdeqKVLl+ryyy/Xrbfeqp6eHt14443q7OzkXwwBALMGNRUAMBOmtG2BMWbS83fddZf++I//WFJpE9TrrrtO3/72t1UoFLR69WrdcccdVVM/Xn75ZV155ZV65JFH1NjYqPXr1+uWW26R5/16+ZIllgGg9ti2YHqoqQAAafr1dFr70NUKxQcAao9Ad2KgpgJAbdV0HzoAAAAAQO0Q6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQBDoAAAAASCgCHQAAAAAkFIEOAAAAABKKQAcAAAAACUWgAwAAAICEItABAAAAQEIR6AAAAAAgoQh0AAAAAJBQUwp0d955p5YtW6ZMJqNMJqOOjg498MADlev5fF6dnZ2aO3eumpqatHbtWvX29lb9jO7ubq1Zs0YNDQ1asGCBrr/+eoVhODNPAwBAQlBTAQAzYUqB7uSTT9Ytt9yinTt36sknn9QHP/hBXXzxxXrmmWckSddee62+973v6Z577tH27du1b98+XXLJJZXPR1GkNWvWqFgs6tFHH9U3v/lNbd68WTfddNPMPhUAAMc5aioAYCYYa62dzg9obW3Vl7/8ZX3sYx/T/Pnzdffdd+tjH/uYJOm5557TmWeeqa6uLq1cuVIPPPCAPvzhD2vfvn1qa2uTJH3961/XDTfcoAMHDiiVSk36OwqFggqFQuX7XC6nRYsW6QO6WJ7xp9N8AMARCm2gR3SfBgYGlMlkat2cEwI1FQBmn+nW0yN+hy6KIm3ZskXDw8Pq6OjQzp07FQSBVq1aVblnyZIlWrx4sbq6uiRJXV1dOvvssyuFR5JWr16tXC5X+RfJyWzatEnZbLZyLFq06EibDQDAcYeaCgA4UlMOdLt371ZTU5PS6bQ+/elP695779XSpUvV09OjVCqllpaWqvvb2trU09MjSerp6akqPGPXx669mY0bN2pgYKBy7N27d6rNBgDguENNBQBMlzfVD5xxxhnatWuXBgYG9C//8i9av369tm/ffjTaVpFOp5VOp4/q7wAA4FijpgIApmvKgS6VSun000+XJC1fvlxPPPGEvva1r+nSSy9VsVhUf39/1b8o9vb2qr29XZLU3t6uxx9/vOrnja3YNXYPAACzBTUVADBd096HLo5jFQoFLV++XL7va9u2bZVre/bsUXd3tzo6OiRJHR0d2r17t/r6+ir3bN26VZlMRkuXLp1uUwAASDRqKgBgqqY0Qrdx40ZddNFFWrx4sQYHB3X33XfrkUce0Q9/+ENls1ldccUV2rBhg1pbW5XJZHT11Vero6NDK1eulCRdeOGFWrp0qS6//HLdeuut6unp0Y033qjOzk6mfwAAZhVqKgBgJkwp0PX19enjH/+49u/fr2w2q2XLlumHP/yhfu/3fk+S9NWvflWO42jt2rUqFApavXq17rjjjsrnXdfV/fffryuvvFIdHR1qbGzU+vXr9cUvfnFmnwoAgOMcNRUAMBOmvQ9dLeRyOWWzWfbMAYAaYh+6EwM1FQBqq2b70AEAAAAAaotABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJNa1Ad8stt8gYo2uuuaZyLp/Pq7OzU3PnzlVTU5PWrl2r3t7eqs91d3drzZo1amho0IIFC3T99dcrDMPpNAUAgMSingIAjtQRB7onnnhCf/d3f6dly5ZVnb/22mv1ve99T/fcc4+2b9+uffv26ZJLLqlcj6JIa9asUbFY1KOPPqpvfvOb2rx5s2666aYjfwoAABKKegoAmI4jCnRDQ0Nat26d/v7v/15z5sypnB8YGNA3vvENfeUrX9EHP/hBLV++XHfddZceffRR7dixQ5L00EMP6dlnn9U//dM/6d3vfrcuuugifelLX9Ltt9+uYrE4M08FAEACUE8BANN1RIGus7NTa9as0apVq6rO79y5U0EQVJ1fsmSJFi9erK6uLklSV1eXzj77bLW1tVXuWb16tXK5nJ555plJf1+hUFAul6s6AABIumNdTyVqKgCcaLypfmDLli36+c9/rieeeGLCtZ6eHqVSKbW0tFSdb2trU09PT+We8cVn7PrYtcls2rRJX/jCF6baVAAAjlu1qKcSNRUATjRTGqHbu3evPvOZz+hb3/qW6urqjlabJti4caMGBgYqx969e4/Z7wYAYKbVqp5K1FQAONFMKdDt3LlTfX19es973iPP8+R5nrZv367bbrtNnuepra1NxWJR/f39VZ/r7e1Ve3u7JKm9vX3CKl1j34/dc7h0Oq1MJlN1AACQVLWqpxI1FQBONFMKdBdccIF2796tXbt2VY5zzz1X69atq/zZ931t27at8pk9e/aou7tbHR0dkqSOjg7t3r1bfX19lXu2bt2qTCajpUuXztBjAQBw/KKeAgBmypTeoWtubtZZZ51Vda6xsVFz586tnL/iiiu0YcMGtba2KpPJ6Oqrr1ZHR4dWrlwpSbrwwgu1dOlSXX755br11lvV09OjG2+8UZ2dnUqn0zP0WAAAHL+opwCAmTLlRVHeyle/+lU5jqO1a9eqUCho9erVuuOOOyrXXdfV/fffryuvvFIdHR1qbGzU+vXr9cUvfnGmmwIAQGJRTwEAvw5jrbW1bsRU5XI5ZbNZfUAXyzN+rZsDALNSaAM9ovs0MDDAe1gJRk0FgNqabj09on3oAAAAAAC1R6ADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgISaUqD7/Oc/L2NM1bFkyZLK9Xw+r87OTs2dO1dNTU1au3atent7q35Gd3e31qxZo4aGBi1YsEDXX3+9wjCcmacBACAhqKkAgJngTfUD73rXu/SjH/3o0A/wDv2Ia6+9Vt///vd1zz33KJvN6qqrrtIll1yin/3sZ5KkKIq0Zs0atbe369FHH9X+/fv18Y9/XL7v66/+6q9m4HEAAEgOaioAYLqmHOg8z1N7e/uE8wMDA/rGN76hu+++Wx/84AclSXfddZfOPPNM7dixQytXrtRDDz2kZ599Vj/60Y/U1tamd7/73frSl76kG264QZ///OeVSqWm/0QAACQENRUAMF1Tfofu+eef18KFC/X2t79d69atU3d3tyRp586dCoJAq1atqty7ZMkSLV68WF1dXZKkrq4unX322Wpra6vcs3r1auVyOT3zzDNv+jsLhYJyuVzVAQBA0lFTAQDTNaVAt2LFCm3evFkPPvig7rzzTr300kt6//vfr8HBQfX09CiVSqmlpaXqM21tberp6ZEk9fT0VBWesetj197Mpk2blM1mK8eiRYum0mwAAI471FQAwEyY0pTLiy66qPLnZcuWacWKFTrllFP0ne98R/X19TPeuDEbN27Uhg0bKt/ncjkKEAAg0aipAICZMK1tC1paWvTOd75TL7zwgtrb21UsFtXf3191T29vb+X9gPb29gkrdI19P9k7BGPS6bQymUzVAQDAiYSaCgA4EtMKdENDQ3rxxRd10kknafny5fJ9X9u2batc37Nnj7q7u9XR0SFJ6ujo0O7du9XX11e5Z+vWrcpkMlq6dOl0mgIAQKJRUwEAR2JKUy7/7M/+TB/5yEd0yimnaN++fbr55pvluq4uu+wyZbNZXXHFFdqwYYNaW1uVyWR09dVXq6OjQytXrpQkXXjhhVq6dKkuv/xy3Xrrrerp6dGNN96ozs5OpdPpo/KAAAAcj6ipAICZMKVA98orr+iyyy7TwYMHNX/+fL3vfe/Tjh07NH/+fEnSV7/6VTmOo7Vr16pQKGj16tW64447Kp93XVf333+/rrzySnV0dKixsVHr16/XF7/4xZl9KgAAjnPUVADATDDWWlvrRkxVLpdTNpvVB3SxPOPXujkAMCuFNtAjuk8DAwO8h5Vg1FQAqK3p1tMpbyx+PBjLoKECKXFxFABODKECSYf+m4xkoqYCQG1Nt54mMtAdPHhQkvRT/aDGLQEADA4OKpvN1roZOELUVAA4PhxpPU1koGttbZUkdXd38z8ixhnbS2jv3r1MfyqjTyaiTyaiTyb3Vv1irdXg4KAWLlxYg9ZhplBTJ+K/CRPRJ5OjXyaiTyY62vU0kYHOcUq7LWSzWf6iTIJ9hSaiTyaiTyaiTyb3q/qFAJB81NQ3x38TJqJPJke/TESfTHS06um09qEDAAAAANQOgQ4AAAAAEiqRgS6dTuvmm29m49TD0C8T0ScT0ScT0SeTo19mB/7vPBF9MhF9Mjn6ZSL6ZKKj3SeJ3IcOAAAAAJDQEToAAAAAAIEOAAAAABKLQAcAAAAACUWgAwAAAICESmSgu/3223Xqqaeqrq5OK1as0OOPP17rJh01P/nJT/SRj3xECxculDFG3/3ud6uuW2t100036aSTTlJ9fb1WrVql559/vuqe119/XevWrVMmk1FLS4uuuOIKDQ0NHcOnmFmbNm3Seeedp+bmZi1YsEAf/ehHtWfPnqp78vm8Ojs7NXfuXDU1NWnt2rXq7e2tuqe7u1tr1qxRQ0ODFixYoOuvv15hGB7LR5kxd955p5YtW1bZsLKjo0MPPPBA5fps64/J3HLLLTLG6Jprrqmcm4398vnPf17GmKpjyZIlleuzsU9ms9lUTyVq6uGop5Ojpr41aupxVk9twmzZssWmUin7j//4j/aZZ56xn/zkJ21LS4vt7e2tddOOih/84Af2L//yL+2//uu/Wkn23nvvrbp+yy232Gw2a7/73e/a//iP/7B/8Ad/YE877TQ7Ojpauef3f//37TnnnGN37Nhh//3f/92efvrp9rLLLjvGTzJzVq9ebe+66y779NNP2127dtkPfehDdvHixXZoaKhyz6c//Wm7aNEiu23bNvvkk0/alStX2t/6rd+qXA/D0J511ll21apV9qmnnrI/+MEP7Lx58+zGjRtr8UjT9m//9m/2+9//vv3P//xPu2fPHvsXf/EX1vd9+/TTT1trZ19/HO7xxx+3p556ql22bJn9zGc+Uzk/G/vl5ptvtu9617vs/v37K8eBAwcq12djn8xWs62eWktNPRz1dHLU1F+NmlpyPNXTxAW6888/33Z2dla+j6LILly40G7atKmGrTo2Di8+cRzb9vZ2++Uvf7lyrr+/36bTafvtb3/bWmvts88+ayXZJ554onLPAw88YI0x9tVXXz1mbT+a+vr6rCS7fft2a22pD3zft/fcc0/lnl/+8pdWku3q6rLWloq64zi2p6encs+dd95pM5mMLRQKx/YBjpI5c+bYf/iHf5j1/TE4OGjf8Y532K1bt9rf+Z3fqRSf2dovN998sz3nnHMmvTZb+2S2ms311Fpq6mSop2+OmlpCTT3keKqniZpyWSwWtXPnTq1atapyznEcrVq1Sl1dXTVsWW289NJL6unpqeqPbDarFStWVPqjq6tLLS0tOvfccyv3rFq1So7j6LHHHjvmbT4aBgYGJEmtra2SpJ07dyoIgqp+WbJkiRYvXlzVL2effbba2toq96xevVq5XE7PPPPMMWz9zIuiSFu2bNHw8LA6OjpmfX90dnZqzZo1Vc8vze6/J88//7wWLlyot7/97Vq3bp26u7slze4+mW2opxNRU6mnk6GmVqOmVjte6qk3A89yzLz22muKoqjqwSWpra1Nzz33XI1aVTs9PT2SNGl/jF3r6enRggULqq57nqfW1tbKPUkWx7GuueYavfe979VZZ50lqfTMqVRKLS0tVfce3i+T9dvYtSTavXu3Ojo6lM/n1dTUpHvvvVdLly7Vrl27ZmV/SNKWLVv085//XE888cSEa7P178mKFSu0efNmnXHGGdq/f7++8IUv6P3vf7+efvrpWdsnsxH1dKLZXlOpp9WoqRNRU6sdT/U0UYEOOFxnZ6eefvpp/fSnP611U2rujDPO0K5duzQwMKB/+Zd/0fr167V9+/ZaN6tm9u7dq8985jPaunWr6urqat2c48ZFF11U+fOyZcu0YsUKnXLKKfrOd76j+vr6GrYMQC1RT6tRU6tRUyc6nuppoqZczps3T67rTlghpre3V+3t7TVqVe2MPfOv6o/29nb19fVVXQ/DUK+//nri++yqq67S/fffrx//+Mc6+eSTK+fb29tVLBbV399fdf/h/TJZv41dS6JUKqXTTz9dy5cv16ZNm3TOOefoa1/72qztj507d6qvr0/vec975HmePM/T9u3bddttt8nzPLW1tc3KfjlcS0uL3vnOd+qFF16YtX9XZiPq6USzuaZSTyeiplajpr61WtbTRAW6VCql5cuXa9u2bZVzcRxr27Zt6ujoqGHLauO0005Te3t7VX/kcjk99thjlf7o6OhQf3+/du7cWbnn4YcfVhzHWrFixTFv80yw1uqqq67Svffeq4cfflinnXZa1fXly5fL9/2qftmzZ4+6u7ur+mX37t1VhXnr1q3KZDJaunTpsXmQoyyOYxUKhVnbHxdccIF2796tXbt2VY5zzz1X69atq/x5NvbL4YaGhvTiiy/qpJNOmrV/V2Yj6ulEs7GmUk9/fdRUaupbqWk9neqKLrW2ZcsWm06n7ebNm+2zzz5rP/WpT9mWlpaqFWJOJIODg/app56yTz31lJVkv/KVr9innnrKvvzyy9ba0hLLLS0t9r777rO/+MUv7MUXXzzpEsu/+Zu/aR977DH705/+1L7jHe9I7BLL1lp75ZVX2mw2ax955JGqpWJHRkYq93z605+2ixcvtg8//LB98sknbUdHh+3o6KhcH1sq9sILL7S7du2yDz74oJ0/f35il8797Gc/a7dv325feukl+4tf/MJ+9rOftcYY+9BDD1lrZ19/vJnxK3JZOzv75brrrrOPPPKIfemll+zPfvYzu2rVKjtv3jzb19dnrZ2dfTJbzbZ6ai019XDU08lRU389s72mHk/1NHGBzlpr/+Zv/sYuXrzYplIpe/7559sdO3bUuklHzY9//GMracKxfv16a21pmeXPfe5ztq2tzabTaXvBBRfYPXv2VP2MgwcP2ssuu8w2NTXZTCZjP/GJT9jBwcEaPM3MmKw/JNm77rqrcs/o6Kj90z/9Uztnzhzb0NBg//AP/9Du37+/6uf893//t73oootsfX29nTdvnr3uuutsEATH+Glmxp/8yZ/YU045xaZSKTt//nx7wQUXVAqPtbOvP97M4cVnNvbLpZdeak866SSbSqXs2972NnvppZfaF154oXJ9NvbJbDab6qm11NTDUU8nR0399cz2mno81VNjrbVTG9MDAAAAABwPEvUOHQAAAADgEAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEqpmge7222/Xqaeeqrq6Oq1YsUKPP/54rZoCAECiUVMBYPaqSaD753/+Z23YsEE333yzfv7zn+ucc87R6tWr1dfXV4vmAACQWNRUAJjdjLXWHutfumLFCp133nn627/9W0lSHMdatGiRrr76an32s5+dcH+hUFChUKh8H8exXn/9dc2dO1fGmGPWbgDAIdZaDQ4OauHChXIcZvDXCjUVAJJtuvXUOwpt+pWKxaJ27typjRs3Vs45jqNVq1apq6tr0s9s2rRJX/jCF45VEwEAU7B3716dfPLJtW7GrERNBYATx5HW02Me6F577TVFUaS2traq821tbXruuecm/czGjRu1YcOGyvcDAwNavHix3qcPyZN/VNsLAJhcqEA/1Q/U3Nxc66bMWtRUAEi+6dbTYx7ojkQ6nVY6nZ5w3pMvz1B8AKAmyhP2maaXLNRUADjOTLOeHvOXHubNmyfXddXb21t1vre3V+3t7ce6OQAAJBY1FQBwzANdKpXS8uXLtW3btsq5OI61bds2dXR0HOvmAACQWNRUAEBNplxu2LBB69ev17nnnqvzzz9ff/3Xf63h4WF94hOfqEVzAABILGoqAMxuNQl0l156qQ4cOKCbbrpJPT09eve7360HH3xwwkvdAADgV6OmAsDsVpN96KYrl8spm83qA7qYF7gBoEZCG+gR3aeBgQFlMplaNwdHiJoKALU13XrKTrAAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACQUgQ4AAAAAEopABwAAAAAJRaADAAAAgIQi0AEAAABAQhHoAAAAACChCHQAAAAAkFAEOgAAAABIKAIdAAAAACSUV+sGAEfMmLe+x9qj3w4AAACgRgh0OH5UBTQjVeW18vfj8plxxt0w9lmrqptsbMf+cOheQh4AAABOEAQ6HB+M0VhoM5U/j4W6ceFufBZzSveYyufH7rGlzGatjIlLn7GSHQtyxlSHOgIeAAAAEopAh9oaC2LGyBinHOKM5JhSsDNOKcxVRuDGhS/HKX9uXPgrBzlZK8WxFMelUTprZMY+O34Uz0p2bPSOkAcAAICEIdDh2KuMppW+Gqcc3Bwj4ziloOY45T+bQyFP5lBYkyTXqXxOjlPKc1aSjWXisUAXSVEsRZEU23HTNseN4llTDoJxaRTPlptGqAMAAMBxjkCHo2v8VMjyn40Zt7jq2OjbWIDzPBnXkVy3OtiNjcDFpUBnJRnXLYW6cvCzMjKypXviWIpi2TCUiSIpDMuBzpSnZNrSiF15JM/GcWkUL44PTdmUCHUAAAA4rhHocPSMm055aErloe+r3n9zXRnPLQU6z5M8T/JcWdeRHRupk0qjZ2Ohy/NkPad037gFUkxsZcJICmMpCGSCULYYatzQWynMladkKip/DSNZUxrJM3Esa8rhsDI9k3AHAACA4wuBDkdHeYqkqUyZLE+pNE55quSh996MTOmc78v4vpTyZVO+rO+OC3Uq/Txrpag0pdL6ruKUq9hzJNfIGslYyURWJojlBJFMwZMKgYwbHFpgZfw7dlEsG0alUTwnlEJTOieVfpdTCnS2KszZ6sVZAAAAgBoh0GHmVE2vdEqLlTjj3o3zXBnn0FTK8e/HGWOkVEq2LiWb9hXX+YrTruKUI+uVAp01koklJ7QyUawo5SpOO4pSRtaVrGNKo3OR5Bat3EIsdzSUO+rJFP1DIdKWRt5KUzFjmSCUglC2GMi4jmwQloKotaWpmPHY9My48o4e79gBAADgeECgw8yoLFwybtsBx6m852bKUyhLUyu9Q4HOcSqft2lfcUNacb2vsMFVVOcqrDOK/XJgUznQBVZuYBWlHYV1RlFair1Dgc4JJbcgeXlH/pCR5ztyQl/WqPQ7Y1sKfpVRvFCmGJbe3SuU2+46h97Fi2PZKJLi0ghgaVFMpmECAACg9gh0mJ7Ke3LOuO0DzLhROU/G98pffcn3ZP1D78eV3o0rvddmfVdhU0pBk6egyVXYYBTWqzQC5x0KdKXRNylKq3RPnVXsS3KsTCyZQPJGjbwRKUq58lOOjLWK3fIUz/K0TKc8iueNhnLyoRyvtACLcZzKQikmikorZIaOFEWlcxq31YFEqAMAAEDNEOhw5MZPl3yzbQc8TyblS+nSVEqb8mXTXun9N88pLWbiSIolOUbFjKdixlExYxQ0GoWNVlHaKvZLoclEklswcvNGUcoqaooVN8RSKpZxrGxspKKjcNiRN2QU+46ilC1N2fR06D27UPIKkpuP5Q878oZdea4jx5hSAI3iyuqYNohknECKwtLCKQplIsmKUAcAAIDaItDhyIwPc44jOe6h9+Tc0tTKylTLdOnduLg+pbjOU1TvKUo7in1TGTWTLa1OGTQ5KrQYFVqMgkysuDmSqYvkpiLJSHHoKBj1FI44sr6VkwnU1FRQQ7oo14kVxo5G8imNDqVVrPNlHVdR2ij2VQqF5fDoBEbeqOSNlt7BS/mmPNPSyESxTBjLBFFpKmYxkFxHNnBkFEhSdaizh7ZDAAAAAI4lAh1+fWOrRKo8ddGMe0/O86q3HShPs7SuI6V9RY1phY2+wkZXQYOjqM6Ugta4UTMnlGJfKrQYFedGUkugppZRZetH1ZQqyhirfOirf7ReQ0N1chyrudlBndw8oNbUsOqcUPnY08FCk15pyOpgqlmBrVPUaBTXl0bx5FgpNlLBUTBSGsWLfEexVwqobr0rE1o5QSynGMvNhzJ5TybvyhQcWWMqs0wroc5o7MU6AAAA4Jgi0OGtVVavHAty5YVMHHMozJXfjzOpVOk9ubQv67myviubchU2+ipmPAVNjorNRmG9UVRXGjWrrF4ZGBkrBc2x1BIo2zqsxS1v6G0N/WrxRuQaq6EorVdHW/RqKitZ6TdaXtM7G3t1kj+gOqeo0Tilfek5SrmhrDXqKzqy1qi+qaD6dCDXiRVFjkYLKeWHUiqm/fLCLKVpo07kyIRWbsHKy8fyRl25viu3vNWCsSpvSq5xG5QbWTs20sgoHQD8/9n79zjLqvrO/3+ttfbe51LXrr5UdwsNKCoQQRNU6IlJTOyBIDEayUT9EkMSRkfTOCqOiSQGL8kEx+Sbi8bLTCYj5jcaEuc76miiETHCGBtUlAioiNrQDd1Vfamuy6lz2Ze1fn/sU6eq6AZtuunq0/V+Pjx01dn7nNpnCyzetdb6fERE5MRRoJPHdqSiJ912A8basmplXO6RM5UjtR1w+MiQ1x2dUUtn2JCOBPKBhb1vYdmsmW0b/KBncKTF6aOHOH/kYZ5c3c94NIMjMF3U+UG8nqrLaBcxTxvYxzNruzktnqFmCpo+Yl3UIACtPKaZxtSTjM2DM4xVmlRsTsdHHOzU2VMfZaoyQEoVgiWvm16wjNqBqGWJG544scTO4IyhjH7dvnTelw3IQ7dhuVeYExEREZETS4FOHl2vFUE3vPWWWC4peuIcJHEZ5moVfL1CUYsp6o685sqllXHZeqAzbEjXBNI1HjOcUx3oUKlkOBu6s2YxaSMBFxiut9lcm+Gs6n6enkyw0XWITGDKNzAmMO8rHEgHGY9n2BzNcporqJmIps3JmWEiHmFN0mK03uK0gRmeNjjJxmSamslo+YS91VGqLgdgf8eREpdtCbzBpgbXgnjelIVbXNnQ3ISy/x2Fx+RFr+ol3mMwBO2jExGRvhSw7rCn8N4c8WwRObko0MmRLWlBYHpVK93yoidRtxBKHJdhbqBCPrTYdiBbaDtQKdsO5LVAOuaJ1rZZMzLPpqFZ1iRNElt0Z80G2FsfptGqMBCnjMYtxqNZNroOm1yEM5bEpMy4WcaieRp5hYrJqJmCqnFUTUQgUDMFFZuRuJwNtQZPG5zkmfVdnBbNUDc58yFidzRLANpFTKOdkNczrAl4b8naEcV8RDFXzi56B8a7MvBlHpeX1S/JC3C+/NOEXms6ERGRk1m1XvCUH2v3vq/UPG9+zy6cWxzIJh9K+OD1T1r2upkpx0Pfr56w6xSRH40CnSzXW2K5UMWyG+YWip1E3SWW3cInwZWVLX29Qj6YkA7Hi20HBg3ZQMB32w4EFzDDGWNrGjx55CBPHdzHeDxD1ZazZns6a6i5jAfsGqwJWLoPE7DGYDE46B3LgqMZKsyHiPmQEgjMh4L5UKHpE1IfMZY02ZRMc1o0w5Yoo24c8yEFZtiXT/NwMsqG4Rq1KCO2Bal3zLRrHJqr006qpMSYYHCpxaaBqB1hOxF0uvciL+9P8L57z1CwExGRk0jg7PNbPP8l071n1qzL2fbvph7zVSNrc/70k/cve+6h71fY8bkRAG7/3DD33DFAt2KaiKwgBTpZtGyJpVlcYrnQHDxJyjCXdPvJJWU/uRBZfOLIB8secp1RQ2cNvbYDtpYTJQXGQJzkPGlwhqcN7uOC2m42RzPUbF7ufXMNANpFxFxWYa6oMFUMcLBokJDijGHKG6aKOjNFjZmsxsOdNax1DbIwTd3mzPsqu7MxHu6sYapT50m1aaomo25y6sZRMzEANZNTsxkDUcr5a/awNm5QsTktHzPRGeGBZC0PuxHmiwHSLMK1DFHbkjcdthXh4nKmMli7uKcQQ1CiExGRk8DG0ztElcBvXreX8549z5r1+TG/52lP6fDvXrsPgEt+ZYqd367y3t89DYD5Gceh/fEx/wwROXoKdFJaOiPXLXyyrOhJEmMqlbLoSbXsJ+erUVn0JDb4yJANlBUsOyOGdKxsOzA0Wu5jG0w6WBNIC8e6aoMnJVOcEU9xWm/WrA1McaAyyMOVEQ62B9jTGmFnsh6HZzaaxZnAoaLO9zsbmOiMMJtV+d78egAmk+Fyf1yI2ZuOcv/8Bg60BlhXadAKMc0Q0QxlD7n5kNMMFVo+ZjRucWZlP5uiaaompxkSdsVriU1B5i272glF01HUDHnV4BNDiLt7B+1igZjFSqAiIiIrZ82GjEt+ZYpfetX+4xLiHs3I2pxnPa/BX9/2HQC+8406X/7MCA/9oMK//OPoE/ZzReRwCnRy2PLKXuET57q95bphrlYh1BOKgYS8FpHXu0VPkjLQ+YhymeXwYtuBM0anOL0+zZp4nsh4GkUFj6FuUwZswaCJqJoYSBmwGXWbUnU5sS2Yag9wn9tII6+wNp4n6u61M8DGygwVmzHZGebe2U3sisdIuhUspzp1JuZG6OSOg7UB9qaj7I7mCExTNwXNkPBQNspUPsj6aJanJvt4kmtRs9Dw88QmZ66osr82yL7qEPPVhCKxZXPyyBBc+egVillYaikiIrJCosQzNFLwex94kPO3Nk74zz/nx5uc8+NN5qYdcRL42j8P0ZjRf2aKnAj6J221O2yvnOsGuXKP3MKfoZrgByoUgwnZUFz2kxu0ZdGTqsHHECwUldBtO9Dm9NFpnjGyh7Ork2yMZomMZ6aosTsbIw0RLe9o2fK3h63gaYWEto+p2JwLxh4GYDar8b35DRxMmjylvo8nV/Yz5ubLHnPFED+IN/DN2Sdx3/QGstyRF5Z2t1qmiQIPV0aodKtZ7ouHe73qJrJRmkXCGZUDrHNt1ruyqErNpMz5FmNRg6G4QxLnzEeeEAWCowxzS2flFto5QFnlUkRE5AT78Z+a47nbZnnJ1QewZmWX/Q+NFrzlLx9kzwMV/uBVZ7Lz27UVvR6R1UCBbjV7ZJjrNQmPII4xcblXjqRsFF4MJGSDMZ0RRzpkSIcN+UAgr3tCEgjdfuPUCoZqbTbVZjizcoCnJfvYFLWJgGk3DwT25GvYkw8Bs9StZ95H7MlHmPcVzq7tY000D8DBfJAH22upuYwnV/bztGQ/a21OAEaLFgHDgWyQ/a1BDkwNUTTixX521cBUPAgBOkXEQ5U1ZR+6ImImq7GpNkPAEAIEAgGWPMyRd8Jpe5yIiJwEXBQYXpPzH//LQ5zz403GxrPj8r6+MGTpsf+Cct2mjGc9r6FAJ3ICKNCtVkeamYsiTBxjkhiqFUIlIVTjcq9cpVximQ67sujJqCFd0y16MpBTqWZYF/CFKZdUxikjUYv10RwbXIdxFxNhqZiU6ajBw9kavtk6nYl4tlflcqoYYF3U4OxkH+ttC4D9UY1B22a2qLHezTFuc9a6SjeApUy5OUajJgNxWrYdaDiSQxbXgXwgkFJlf+qYa9aoVlIi68m9xdrAQJRyIB9kX1QjNk1qpk0jGPYXAxzMB5nLqnSyGDKLyQ0mDxhfPsoUGCCUjcUDqAediIicENV6wX94+x5e8MuHqFT8MS37n9iVLAtdD95X5SN/Pn4crhKKXCtXRE4EBbpVbbGSZVn8JFoMc/UKvpZQ1GPyekRRteRVSzZYzsylox4/llMbaTE21GSk2qJiczLvmEurWFPWezTduS7T/W7hOTB8v7WeXe2x8nXBMZ7Msqk6zZNckw2unO5LTJNGmGbeV8rxqtcZYOl7Lec6kMwEbGYgWPJ2Qqse0UqqYMufnQx1mKgP8WCylkHboRHKaphNX2FXNsau9hj7W4N0WjGmY3Ep2AxsHjBF+cD7JcHuBP1fJiIiq5IxgU1npLzsmn3Uhwp++kXTP/Jry6FqMVztfzjmo93Q9uB3q3z7zoHjfbkicgIp0K1GvYbh3WqWznb3yi2GuWKgSj4Ykw1FZIOWrG4oqmWT8Gwo4EcLBsfmOX3NNGcNHmBTZYaazWj7iAPZEA+1RpktqhwsBjngG8RFhwjDtDccKAY5lNeZaA5zoDlAZD3r6/OcVjnUbTHAkvYCbWomL5dWFgOsLVqE0CEA+4uYA8Ugs3mNZhZT5BaTgykgagWiVsClhrxhyWsWHwWw4GNIPeyJRzCUzcXXJuuomIy2T5joDPNgY4zJ6WGK2YS4YYiagagdcB2PyYqymbj3y0OdiIjIE2BwJOe3/vBhnvuCWYZGix/5dVOTMZMPJXxzxwD/+7+t7z1f5Ia5af0noMipQv80r1oLoa5bgr87OxeqCb5WIR+MSUeiZU3C83qgqHh8LRANpowPz3H20H5+bOBhtsQHqduUto/Zk4/ijGeiPcLOznoi45mNZojwTPsaP+hsYHd7jIOtAQ4eGsLFnqFKh5ZPaIaERpinHlIAGsEw7xNmixodvwGAtW6egGEyH2ZnZz0Pt0eYadXwbUfcMbg04DrdAJZaiirkFQgRBGvIBqHjIhquzq7CMZdWGEo6RLYgLSJmO1Wm5+p0Zqq4GUc8Z4jmA1HL4zoem5aBLhTdQNddghlQsBMRkePLRYHX3fAwz3/JoR/5NXd+cYi7/mWQ7/5rnbu+NPQEXp2InAwU6Fapsn+4AVu2JjBRRIjjsvhJPSIbKsNce40lHQ1kw54wlGOrBXFSUKumrK812FI9yNnJPs6K5hiwhlZoMmhTGkWVQ1md++Y20sirjMXzOFPQKKo81BplV2OMQ7MDFNMJfjBnplNlsjPMrmQtCQUNPw8Y9hd1dmVjPNQepZknHMoHGIla+GA4lNd5qLWGXTNrmJ2tYeYioqbBtQNRJ5DM5kRNg69YitgQorLFginK6pSpT2i1He35hH1JgbXlHsCiExHmHW7OUZk2JDOBpOGJ5wtsK8d0MkyWE7qhLmiWTkREjjPrAhu3pPzqGyf4mV987DAXAux9sMIn/8c6vvbPQ8xMRcwd0n/iiawW+qd9NVpScp9uvzmiCJIYXy33zGWDtrtXLpCu9djRlOGRJqO1FvU4xRgYijuMuiZjrsVa56ibmHbIabkOa6J5BlzK/TMbmGwOMph0cCbQymMOtWrMNOpkU1XcnKMwcGiuzgNJ2UuuUVQZi8oeOgfzQXa11/KD2XVMt2tMVIepxykhGOazhOlWnZnpOn46IZk1xI1A3Ay4tse1cqLc42NLiC3BWfK6g+AwBZjMkDcdRc1RxIHClss1bWaImoaoCclsIJkLJLMF0XyObaWYTkbIMsjz7pJLrzAnIiLH1c+/4iD/8b88xA/riPPAfVVu/9wI/7//d5w8LXeXi8jqokC3KnULlNiFfXQWIkeIHb7iKKrlnrmFJuF2NGXt2BxnjEzxpNoMI3ETA2TBETD4YPB4PAFPoAiUzwVDljsOzAzjbMCYQFFY8lZMmHdEM45o3gCOTlzlYTtK7i37a4MMxR0A5rIK+1uDTM4M05qvMBPXiaJy/0CWRhTtCDPniGcsyYwhngvE856oVWA7GaaZYiNLcOXnM0UMAWxucZkln+/20YsMwYDxZfGTqBOIWhB3Z+biuQw3n2LaKaQZZDmhKAhFoeWWIiJy3Jz59Bb/8b88xFnntR81zPnC8Lm/G+NzfzfG9IGIh3dWTuxFishJRYFutVraGNuWs1chdhRJWc0yr0FeD4ShnOGRJmeOTnH+8MOcVdnPBjcHJnAgH+JQUWeyGKRmZhi0HZrBsK8YZH8+zExWo5XG5DMV8pYrK1IWBtcxuJYhboDrBIw3pCamWRh2dWL2VYeoxGUz8E4W0W4nFLMxds7hDXSislKlySDqGOL5co9bZTaQzBTEszluPsO0M0y7AyGUn7GSYLzHFAGXRkRtS1GxFInBOxbKZ2JzcGkgantcs8C1clwzxTTLQBc6aTk71yuMEsqHiIjIMXjqBU3e8eGdrP0hPeU+89Ex3vuW05ZVrhSR1UuBbrVbaFtgLcGV+8x8BD4xFBWPrRWM1lo8qTbdbey9jw0uxQD7bYvvput5MF1HO8QMmA6tELM3G+WB9lomWkM0Wwm0LZUpi826M2ApuHa5NNLmYAKYYMiyiLzlmK8mzEe+vL7cYtq2DG1zBhMguO6l5+DSbkXLZnef21xONJ+VSyPbKSHtLo10DtPd6+YKj01jbCfCJ7ZckmnNYqArAjbz2E6B7eSYdo5pp5hOSuh0IMsIeU7wBfhACL58oWboRETkcXBx4IyntrnuAw8+Zph74DtVPvzuTXzj/w4qzIlIjwLdamOWPszio9vCIFhDcOBdWRUyjgsGkpTRqMmGaJZxl7LBJRgMlg7T0Ry70rU80FlLxeR0fMzBbIAH58bYOzNMNlMhalji2XI/WhmWujNgLd9b/mhTi2tRthdILCEqw5HJDS4F1wrE8wGbhzJ8QTnTloHreKKWJ2oWuGaGbaaYZhs6KaQpIcsxzhG8L2fospzQyTHtCCJLiNxioPOUzcPzApMXkOaYNO+9D1lGyHJCd/9cryCKiIjI4zC6PuNN/+9unvm8BpWqf9TzfvCtGr/7iidzaH98Aq9ORPqBAt2pamHh/ZI/zZGOPdb+abP4x/KHWfJ1oAiW7zfW08wTMm9pdCpMN+q0Z6vYbtn/eD5QmfFEHY/Jyhkw1ynAgC1ibBqI2pa8WvaJ683CdQNg1A5ETY/LAqE7k2Y82Nxj0/K97MJMWjuFTkpYCGF5Xoa50A1ghcfkOSaNCK5ccoq1vRm6hf5yJvfla/McFt4nLwhFN8wtzMyBQp2IiBylwIt/8wAXbZvlwufPPeaZP7i3xh+99gyFORE5IgW6U01vB/WS5uFQVrQ0jzgewuL+r+7D+FAGpaJc0lhklmYWM5PXOFAMMGabWMqCJft9xIFikJm8xnSnxkNTo+RpRJE6mHe4hiOZNlRmykqRcaMsLmKzogxLWVE2Ns88th0RNR0+MfjYLM7C+YDNQtlbrl1g04JyBx3l9RYek5WzbuVsWrcC5dIwVyxpAl54TFEQrCure1qzGOgAKO9DWJh9KwoofPkeeVE+t3BsYZmlwpyIiBwFFwV+Zfs+/p83TJJUHn1WDuDB+6r83pVPZmqfwpyIHJkC3anELIY3s7CMcknhk8XvF87tTkkthLki9GbEbAa2Y8jbEdOtGg+3R1iXbMAA0778TeKBYpAfdDawtzNCu4jxhSWfS7ANSzJrDyv7H893i4u0UigKTOHBWkxeYDsRrhX12guEbr4yC9eVlWHOpGWxFAJluwAfMN2wRV702gmEbtGSsFC4xBhCL7iWidVYWz6/MDu3cD+6QTeEMgD2Alx3eWW5zBK0b05ERB6Pl756P1f99t4f2pLgu/9a513bz1CYE5HHpEB3qliyH86YMqiYhR5zthvonO3O1HXPJdCb7vK+DFap7+5JK3uxFQ3HbK3OrngMZwKHsjrrkgaxKWfKrAlsrs7gg8UQmPCGPKuCpyxUMtsNc3MZbr6DaXYwrXa5dNF7jLWYPIdOhIvLWbPg7GI4DeUsHEUBWVGe65csc/SLyyjL2bSFELdkNq07i1Z+5G4gs2bJvYBlo2pYnHkLfuHrxffphTiFOREROQpR7Hnpq/fzq2+a/KFh7sHvVnnHb57Jgb3Jibk4EelbCnSngqVhrrt80LgyHJnIgYsgcmXAMwv7xZbMzjkLSVQuPyzKcv1R0xI3DL5iSaMK+xgmAEWwDEZtnlSZYkM0hyVwKKkzFs3jjKedxRxMI4qGpZg3BFcu47SdHNPKFsv+Z919aM6Ws2uRK695YQnkkkC30BogLIS14BePLcymLVlSuVB9ktCdZesGrxAMmKKcvfSGYPzizNzSgbU3+0bvZwUFOREROSaBX37tfn7jLXt/6Jn33VXnD1+tMCciPxr7w09Z7rbbbuNFL3oRmzdvxhjDJz7xiWXHQwhcf/31bNq0iVqtxrZt27j//vuXnTM1NcWVV17J8PAwo6OjXH311TQajWP6IKvWI2fmrMVEESaOMUmCqVQwtSrUq4SBOmGojh+qdR/l92Ggih+skg9XyQcj8lr5t0XUCkQNg20ZfGFJXMH6yhxnVQ7w1GQ/T49neXo8x9OSAzy5so/TaodYU2sSVTOKSqBIKPfDRaY7O0gZkApflv3PMkKaEdIU2h1Cq01odQjNdvfrdvfr8hjtTlnopPOIR5p2q09miwVLFoqWLJtVW1wyGbozeKG7P+7wh+/to+tVstR+ORE5jjSerh4uClzxH/Zz5Rsmf+i5vjB85fPD7HtIYU5EfjRHHejm5+d55jOfyfve974jHn/3u9/Ne97zHj74wQ9yxx13MDAwwKWXXkq73e6dc+WVV3Lvvfdy88038+lPf5rbbruNV7/61Y//U6xWSwqcLCypNHEZ5qgkmFqVUK8RBmuEoTrFSI18tE6+pk4+VidfUyu/HqqSDSd0RmNaayNa6xzttZbOGoNPIFhwcUE9ShmJWqxzc2zoti/Y4Cqsd551rsFo1GQgTonjghAFQtRtf9Bth7Cwn29hmWPwvmwB0AtnHUK7TWi3oVU+Fr4Pnc6SANcNggv94Bb2zBW+F8RYGuYWBJYHM18sPoolj6XPK8iJyBNE4+nqYEzgZddM8u9/fy/JY7QlALj/mzX+v/+2no/8+fgJujoRORUc9ZLLyy67jMsuu+yIx0II/Pmf/zlvfetbefGLXwzA3/zN3zA+Ps4nPvEJXv7yl/Ptb3+bz372s3z1q1/l2c9+NgDvfe97eeELX8if/MmfsHnz5sPet9Pp0Ol0et/Pzs4e7WWfusxi2X0TRZgogiTGVCqEakKoJvhajK9EFNWyibaPDWFh61gBJg8UFUM6bEmHDdmgIRsI+GogRAEfQdlFYHFd4qPFm0eNPUc6sNAigDLc9frhHellfmmw6i6nXHbiI8ObApiInNxWYjwFjaknkrGBX/r3B7jyDZNY+9jj0u7vVXnXb53BQz+onqCrE5FTxVHP0D2WnTt3MjExwbZt23rPjYyMcNFFF7Fjxw4AduzYwejoaG/wAdi2bRvWWu64444jvu8NN9zAyMhI73H66acfz8vuT90qlWZhuaVz3TBXLrMMtUq5jHKkSrqmQnttTGt9THNDRHODoznumB93NDc4WusdnRFHZ42lvQ7aGzz5pgy7uUXltHnqmxq4qGA+i5nJ6uzPh9hfJEwWKZNFh32FY38xxKGsznxWIcscJjOYvNv+wAdMb6bLL7ZLoNzjVi5/7M6OZWXPt7BQobL7PUXROy8srTrZm1XTskgROXU8UeMpaEw9UawL/D+vn+Tq39tDlDz2uBQCfP22QYU5EXlcjmtRlImJCQDGx5cvFRgfH+8dm5iYYMOGDcsvIooYGxvrnfNI1113Hddee23v+9nZWQ1AsDijZbvVLCOHSWJCJcHXKxQDCdlQTDpsyQYs2YChqNJbRkkAm4NNDTaHdDiQrvGY0ZTR0SZr6k0GkxRrPK08Zj6tsKc9ws5kPdYEpqPZsihKMcAPOut5qL2GQ60aeTvGdQwuBZsFTBZ65f97M21L+bI4SXjUDucLwmNMAYqInDqeqPEUNKaeGIGXXL2fX712Eut+yMAV4PMfG+O//8GRZ1RFRH6YvqhyWalUqFQqK30ZJxezdHbOYiKHiWNCkhBqSRnmhuNy5m3UkA0ZsqFAXg+EigcXIBjIDK5tcC1DPhCwa1LWjs1x1uhBttQPMRY3cATmigoPtdewpznKPbNP4lBeZ03UxJrAbF7l4dYou+bGmJ4ZIMxGRE1D1Aq4TsBlHpstVKD0y2fTFoTeX0RE5AmkMfWJ5eLAr/xW2TT8h4W5PQ9UuPPWIf7qnZtJO8d10ZSIrCLHNdBt3LgRgMnJSTZt2tR7fnJykmc961m9c/bt27fsdXmeMzU11Xu9/IgMZZGRbosC4giSCF+NKeqOdNCSjhg6o4Z01ONHC9xARqWWEjuPD4Y0jUhbMcVsTEg8I8MtThue5ryhvZxdnWQ8miXCM+3rjEYtnAncN72B/a0BBpIUS6CZx0y36szO1igOJcSzlniu7EMXtTy2XWCyHJN3K0j2ZurQ8kgRkSPQeNq/XvqqH71p+A2/dQZ7dipci8ixOa6/DjrrrLPYuHEjt9xyS++52dlZ7rjjDrZu3QrA1q1bmZ6e5s477+yd84UvfAHvPRdddNHxvJxT25K+c2WFywiiiFCJ8VVHXndkg5Z0yJCu8fi1OQPr5zltwxTnbpjk/A17eMaGPZw9vo/162eI1raxAznDtTabajOcVTnA05L9nBPP8fSkydOSgzylMsnp1SmGkg77Zof43sR6vju5gQcn1jE1OUyxv0p80JEcMiRzgaThiZoFtp1BurAXzi82Aw9aQikiciQaT/vTwHDBtn839UPDnC8MX79tSGFORI6Lo56hazQafO973+t9v3PnTu666y7GxsbYsmULb3jDG/jDP/xDnvrUp3LWWWfx+7//+2zevJmXvOQlAJx77rn8/M//PK961av44Ac/SJZlXHPNNbz85S9/1IpccriyH/biHjrjLCFyhNhRVBx5zZLXIRsK+JGC+poWZ45N8eTBA2Uos21yLAeyIXZW1nG/DUw16tSijOGozVjUYK1LWesSIiyODgddk5GoxUCUYm2gebCG7VhMDlFqiJqGeA6SRiCZ8cRzBa6ZYdsZppMRshy6feLKKpXdipUiIquQxtNTy/CanDe/ZxdnPq39mOd991/rfO2fh/jwH2sWVUSOj6MOdF/72tf42Z/92d73Cxurr7rqKm688UZ++7d/m/n5eV796lczPT3N8573PD772c9SrS5WbvrIRz7CNddcwwte8AKstVxxxRW85z3vOQ4fZ7UxS0Jd2bzbR2VrgqJiyKuGouZxAxlrBxucNXiA8+p7eEplH8O2TR4cE9EQiclpFjHtLC47CWAIYeER8CbgAQ+EYPAAAUxhSA5ZXAtcCq4diJuBeN6TzBZE8xm2mWLaZeNv8m71yuIIe+hERFYZjaenksCTntzhuS947BYQk7sT/ug1Z7D3Qc3MicjxY0Lov/+qnp2dZWRkhOfzYiITr/TlrAjjorKqZRxjqhVMvUYYLJuFd8Yq3dYEhvbGgvrmBk/bsI+L1/yAZ9V28bRkhlFryUJgb2G5p7OR2+eewjennkTuLc8Y28tzh3ZybmUvG12HyAQOecd30/X8a/N0vjp1Bg/sW0e2p0510lLbXwY51wlErQLX6s7MtTJssw3tbtPwNIMsW7KPzivUifSxPGR8kU8yMzPD8PDwSl+OPE4aU4+HwIe+/B02n9l51DO+d0+Nu/7vEH+lapYi8gjHOp72RZVLeQRjFnt8d/vRLTwXjCFYeg9cwDlPxeUMuA5DtsOwsQyaCrkpaPiUQduhbjNiW3Bovs7e1gg7k3VY45leUhTlB5317G6tYapZJ2tF2HbZmsB1AslMTtQqsO0C28m7yyzTbphLy/1zebFk75yCnIiI9D9jApe8bIqxDdmRTwiw8zs1bnjtGTz0ffWZE5HjT4GuX4VHfLOwHW3Jw5TrJ/HBkHtL5iPS4OjgyUJOhqeDJQuOLDiKYGl2EnZPj2IIHMoGWBPP40ygkVd4uD3KQ3OjHJoZJMzFRPNla4KoE4janmg2xbbK8GbSDNKMkJUPspzQbQCuUCciIqeKZ1w0z+ve9RDxozQP3/mdGte9/Mkc2q/ZTxF5YijQ9a0lZf9DgFCGJBMCpgjYAkwOJrOkacRcWuVAPshEPsKQTWnanAzDRF5nIh/hUFZnPk3ImxEzrQF+4C1T7ToDcYo1gXYeMd2qMdcoWxNEM5a4AdF8tzVBp8CkOabV6Qa5vLtnrjsz1wtzQWFOREROEQEXhUcNcyHA379vvcKciDyhFOj6jTFl7zljF5ddQjlqeI/JPTYL2DTgOmXD8Gw+Zn99gO9X1+HwNEPCsG2RB8dkPsz3WxvY3Rhldr6GaUSYjqHRdszXarikwJiAzx1Fy2GajnjGkswYKrNLWhO0ykqWpBmh01mckVuyX64Mc9o3JyIipwYXwX9810NHPPbgd6u8/dfPYmqf/lNLRJ5Y+rdMHyq3zRmMc5jIQRR1H45gDQawRbm3LWoairmImXiAnW4dnSJmfzpEPUopvOVQVmNPc5S9MyN0ZipEc5aoYSjmDb4aUUSh3KJXQNQxRK0jtCaY77YmSLPFGbksK6tZeg8ELbMUEZFTzk9eNsP6zYfvnfvuXd2m4Q+omqWIPPEU6PqNMcv6z+EiTBwRkhhfjSkGYtJBRzpgyOuGohrKAim55VCjTjuP2F8dJLYFhbc005hGs0pnpoqddsSzhspMwDvwicE70wt0NgtE7UC00JpgriBqLGlNkHb3yuV5L8yFbqBTmBMRkVPNT75wmqTqlz03vT/inf/+TPbvSVboqkRktVGg6ztloDPWYpyD7gxdqMQU1ZhswJENWdIRQ2cskI8VxKNthgdbjNZaJK6gCIZGWmF6vkazWSkLnEy7chnldKAyU+7D87HBu+5P9WDzgEvLPXO91gTNDNvqQCclpGk5Q1d4CJ4Qyj8BhTkREVkVvvxPI+zfoz1zInLiKND1mYXllguzdMY5QhQREoevOvKaIatDNhTIh8swt2ntDKcNTrOpOkPdpmTBcSgb4MHKGh62o8x1HOCwObg2RE1P3CzwzhBsuVHPhIDJAzbzuE6BWWhN0E7LMNdrTZATfLF8Rk5hTkRETjEXbG1wwdb5Zc/d8v+t4b+9czPLN7mLiDyxFOj6kekut1x4RJYQO4rEUlQted2QD3jsSMa60TmeNrKPcwYmODM5wKBtk4aIyXyYwagNwAO5o9105C2HT8BHBpN6klbe/XlgfAAfMHmByQpIu60JMrUmEBGR1WfNhmxZ77n5Wcftnxuh1XAreFUishop0PWzJXvpvLP4yFDEUCTgq4FqNWNdfZ7Ta1M8pTLJ2fEUw9bTCYYR16IdYqbSAQ7UBmlXq2UgTMDHEJzB5EXZV26hPYL3GO8hL7qFT9SaQEREhAAfuP5J3Pap0ZW+EhFZhRTo+k255rIMct32BcEasBBc9xEBkSdJcobjDuuiBuOuwUYXGLIV0lDgabEhmmUkblGLU0ziCd0gF6wB1/0ZeYFpd8CHxZk376HwvbYEy1sTaGZORERWl4cfqPC1fx5a6csQkVVKge5UYR6xXr8sTokhYAlYE7DGYFl4UD5PWP7Sbl5cFscKX+6R64a1ZaHOqzWBiIisXg//oMJ//g9nqnm4iKwYBbp+E7p/6TXp9pjQ3d/my2qUpgByQ5o75vOE6aLOVFHnoJ0mtR3SEDjoK0wVA8zlVdpZRMgtpgBThPLP7p45fCCEUM7CZVkZ6LrLLxfCW/ABtSYQEZHV5I6bh/n036wljgPfv7e20pcjIquYAl3fCcu/9AGKgCk8Ng/YDGwKtmPptGIOtAbZVRtjwHYoMAzZDmlwTOQjPNBex97WMI1WFdoW2+m+Ni8rWhofMEuXUfpAKPLFIAeqZikiIqtSu+l471tOX+nLEBFRoOtLCyGqt/SxwGYem3pcOxC1wM0bskbMgeog34/Wk3vHVD5A3aVk3nEwG2Tn/Fr2zI3Qmqtg5y1RyxB1yl5zNvOYvFg2SxdCKCfiFgLe0usREREREZETToGuzwToLrHsFiEpirKVQFrg2gVxy1HMO/I5g08iWrbGgwFmOxUeqo1ScTm5tzSyCgcbAzRmanAoIZm1xI1A1Cybhts0h6xb9MQXy5ZYammliIiIiMjJQYGu3/T2rZWBzhQF5GVPONtxRE1HnBiKiiU4Q0pEp6gz2Uo4VB3AOY8PhiyNKOYjzFxEMmOIZyFpBOKmx7XLxuEm67YkKLozgcETUJATERERETlZKND1m7DwKAuVkBeENMdEGTZyRLEj2LL1gPFgM0PWchQ1R1pJCK5bPCU3xC1DNG+I5wKVWU8y64nnclwzw3QySLOyz1xRqLeciIiIiMhJSIGu75R72UwIhKLcP2fyDFKHcRYX2V7rAeMdNrO4NhRVg48NwYEJYHJwbYhagXg+kDQ8cSPHzWfYVorpZGVVy7y77DKoJYGIiIiIyMlGga7vdNsVeICy8TfWENIUYwwYg/OAD9gsJmpZ4pqlSLqBzi4EuoDLwLU9UcsTNcuZOTvfwbRTQqcD3SWXvabhqmYpIiIiInJSUaDrN4Gy8Xcoi6MEX0BuMGQLhyAEnPdl5ct2RNRy+NjgnQFbvtgUYHOP7XhcJ8e2c0w7w7Q70EkhzQh51i2KomIoIiIiIiInIwW6fhU8wZcBLpADC1+D8WXLgZDmmCQiNB2hu7euF+h8wOQek3lMlkMnw2QZIS33zpXLLcv9c3jfbR4uIiIiIiInEwW6fhQCmDK+heAxRTfULcza9fbW5Zg0IjgHzpZhzpjyPXzZ+sDkZWEV8pyQ5ZBnhIXvi6VLLTU7JyIiIiJyslGg61dLwlVgaajrtjPwRdlywDmMc2WQs7YXBBcCXeg2JqcoygCX573+dr0wp6WWIiIiIiInJQW6frY01AWPYbE/Hd6DLTDWEhaC3MJjYbbNL+lp11ta6cGXM3/aNyciIiIicnJToOt3vbAVCN6UlS4D5Z43u2RWrvdgsY9doNyLF0K3cXg34C18v+z9RURERETkZKNAdypY2FO3EMZMKIOdNwTjF4McsPjFkhYE3XB32F45hTkRERERkZOaAt2p4hHhq/y2O0vXPWSW/DUQlp+8cP4R3ktERERERE5OCnSnooWZNoBiydMrcjEiIiIiIvJEsSt9ASIiIiIiIvL4KNCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPrUUQW6G264gec85zkMDQ2xYcMGXvKSl3DfffctO6fdbrN9+3bWrl3L4OAgV1xxBZOTk8vO2bVrF5dffjn1ep0NGzbw5je/mTzPj/3TiIiI9AmNqSIicjwcVaC79dZb2b59O7fffjs333wzWZZxySWXMD8/3zvnjW98I5/61Kf42Mc+xq233sqePXt46Utf2jteFAWXX345aZry5S9/mQ9/+MPceOONXH/99cfvU4mIiJzkNKaKiMjxYEII4fG+eP/+/WzYsIFbb72Vn/7pn2ZmZob169fz0Y9+lF/+5V8G4Dvf+Q7nnnsuO3bs4OKLL+Yzn/kMv/ALv8CePXsYHx8H4IMf/CC/8zu/w/79+0mS5If+3NnZWUZGRng+LyYy8eO9fBEROQZ5yPgin2RmZobh4eGVvpy+pzFVRGR1Otbx9Jj20M3MzAAwNjYGwJ133kmWZWzbtq13zjnnnMOWLVvYsWMHADt27OD888/vDTwAl156KbOzs9x7771H/DmdTofZ2dllDxERkVOJxlQREXk8Hneg897zhje8gZ/8yZ/kGc94BgATExMkScLo6Oiyc8fHx5mYmOids3TgWTi+cOxIbrjhBkZGRnqP008//fFetoiIyElHY6qIiDxejzvQbd++nXvuuYebbrrpeF7PEV133XXMzMz0Hrt3737Cf6aIiMiJojFVREQer+jxvOiaa67h05/+NLfddhunnXZa7/mNGzeSpinT09PLfqM4OTnJxo0be+d85StfWfZ+CxW7Fs55pEqlQqVSeTyXKiIiclLTmCoiIsfiqGboQghcc801fPzjH+cLX/gCZ5111rLjF154IXEcc8stt/Seu++++9i1axdbt24FYOvWrdx9993s27evd87NN9/M8PAw55133rF8FhERkb6hMVVERI6Ho5qh2759Ox/96Ef55Cc/ydDQUG99/sjICLVajZGREa6++mquvfZaxsbGGB4e5nWvex1bt27l4osvBuCSSy7hvPPO45WvfCXvfve7mZiY4K1vfSvbt2/XbwxFRGTV0JgqIiLHw1G1LTDGHPH5D33oQ/z6r/86UDZBfdOb3sTf/u3f0ul0uPTSS3n/+9+/bOnHgw8+yGtf+1q++MUvMjAwwFVXXcW73vUuouhHy5cqsSwisvLUtuDYaEwVERE49vH0mPrQrRQNPiIiK0+B7tSgMVVEZGWtaB86ERERERERWTkKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifeqoAt0HPvABLrjgAoaHhxkeHmbr1q185jOf6R1vt9ts376dtWvXMjg4yBVXXMHk5OSy99i1axeXX3459XqdDRs28OY3v5k8z4/PpxEREekTGlNFROR4OKpAd9ppp/Gud72LO++8k6997Wv83M/9HC9+8Yu59957AXjjG9/Ipz71KT72sY9x6623smfPHl760pf2Xl8UBZdffjlpmvLlL3+ZD3/4w9x4441cf/31x/dTiYiInOQ0poqIyPFgQgjhWN5gbGyMP/7jP+aXf/mXWb9+PR/96Ef55V/+ZQC+853vcO6557Jjxw4uvvhiPvOZz/ALv/AL7Nmzh/HxcQA++MEP8ju/8zvs37+fJEl+pJ85OzvLyMgIz+fFRCY+lssXEZHHKQ8ZX+STzMzMMDw8vNKXc0rQmCoisvoc63j6uPfQFUXBTTfdxPz8PFu3buXOO+8kyzK2bdvWO+ecc85hy5Yt7NixA4AdO3Zw/vnn9wYegEsvvZTZ2dnebySPpNPpMDs7u+whIiJyqtCYKiIij9dRB7q7776bwcFBKpUKr3nNa/j4xz/Oeeedx8TEBEmSMDo6uuz88fFxJiYmAJiYmFg28CwcXzj2aG644QZGRkZ6j9NPP/1oL1tEROSkozFVRESO1VEHuqc//encdddd3HHHHbz2ta/lqquu4lvf+tYTcW091113HTMzM73H7t27n9CfJyIiciJoTBURkWMVHe0LkiTh7LPPBuDCCy/kq1/9Kn/xF3/By172MtI0ZXp6etlvFCcnJ9m4cSMAGzdu5Ctf+cqy91uo2LVwzpFUKhUqlcrRXqqIiMhJTWOqiIgcq2PuQ+e9p9PpcOGFFxLHMbfcckvv2H333ceuXbvYunUrAFu3buXuu+9m3759vXNuvvlmhoeHOe+88471UkRERPqaxlQRETlaRzVDd91113HZZZexZcsW5ubm+OhHP8oXv/hF/umf/omRkRGuvvpqrr32WsbGxhgeHuZ1r3sdW7du5eKLLwbgkksu4bzzzuOVr3wl7373u5mYmOCtb30r27dv128LRURkVdGYKiIix8NRBbp9+/bxa7/2a+zdu5eRkREuuOAC/umf/ol/+2//LQB/9md/hrWWK664gk6nw6WXXsr73//+3uudc3z605/mta99LVu3bmVgYICrrrqKd77zncf3U4mIiJzkNKaKiMjxcMx96FaCeuaIiKw89aE7NWhMFRFZWSvWh05ERERERERWlgKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifOqZA9653vQtjDG94wxt6z7XbbbZv387atWsZHBzkiiuuYHJyctnrdu3axeWXX069XmfDhg28+c1vJs/zY7kUERGRvqXxVEREHq/HHei++tWv8l//63/lggsuWPb8G9/4Rj71qU/xsY99jFtvvZU9e/bw0pe+tHe8KAouv/xy0jTly1/+Mh/+8Ie58cYbuf766x//pxAREelTGk9FRORYPK5A12g0uPLKK/mrv/or1qxZ03t+ZmaGv/7rv+ZP//RP+bmf+zkuvPBCPvShD/HlL3+Z22+/HYDPfe5zfOtb3+J//s//ybOe9Swuu+wy/uAP/oD3ve99pGl6fD6ViIhIH9B4KiIix+pxBbrt27dz+eWXs23btmXP33nnnWRZtuz5c845hy1btrBjxw4AduzYwfnnn8/4+HjvnEsvvZTZ2VnuvffeI/68TqfD7OzssoeIiEi/O9HjKWhMFRE51URH+4KbbrqJr3/963z1q1897NjExARJkjA6Orrs+fHxcSYmJnrnLB18Fo4vHDuSG264gXe84x1He6kiIiInrZUYT0FjqojIqeaoZuh2797N61//ej7ykY9QrVafqGs6zHXXXcfMzEzvsXv37hP2s0VERI63lRpPQWOqiMip5qgC3Z133sm+ffv4iZ/4CaIoIooibr31Vt7znvcQRRHj4+Okacr09PSy101OTrJx40YANm7ceFiVroXvF855pEqlwvDw8LKHiIhIv1qp8RQ0poqInGqOKtC94AUv4O677+auu+7qPZ797Gdz5ZVX9r6O45hbbrml95r77ruPXbt2sXXrVgC2bt3K3Xffzb59+3rn3HzzzQwPD3Peeecdp48lIiJy8tJ4KiIix8tR7aEbGhriGc94xrLnBgYGWLt2be/5q6++mmuvvZaxsTGGh4d53etex9atW7n44osBuOSSSzjvvPN45Stfybvf/W4mJiZ461vfyvbt26lUKsfpY4mIiJy8NJ6KiMjxctRFUX6YP/uzP8NayxVXXEGn0+HSSy/l/e9/f++4c45Pf/rTvPa1r2Xr1q0MDAxw1VVX8c53vvN4X4qIiEjf0ngqIiI/ChNCCCt9EUdrdnaWkZERns+LiUy80pcjIrIq5SHji3ySmZkZ7cPqYxpTRURW1rGOp4+rD52IiIiIiIisPAU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwpS+ADYAACjC0lEQVR0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSp44q0L397W/HGLPscc455/SOt9tttm/fztq1axkcHOSKK65gcnJy2Xvs2rWLyy+/nHq9zoYNG3jzm99MnufH59OIiIj0CY2pIiJyPERH+4If+7Ef4/Of//ziG0SLb/HGN76Rf/iHf+BjH/sYIyMjXHPNNbz0pS/lX/7lXwAoioLLL7+cjRs38uUvf5m9e/fya7/2a8RxzB/90R8dh48jIiLSPzSmiojIsTrqQBdFERs3bjzs+ZmZGf76r/+aj370o/zcz/0cAB/60Ic499xzuf3227n44ov53Oc+x7e+9S0+//nPMz4+zrOe9Sz+4A/+gN/5nd/h7W9/O0mSHPFndjodOp1O7/vZ2dmjvWwREZGTjsZUERE5Vke9h+7+++9n8+bNPPnJT+bKK69k165dANx5551kWca2bdt6555zzjls2bKFHTt2ALBjxw7OP/98xsfHe+dceumlzM7Ocu+99z7qz7zhhhsYGRnpPU4//fSjvWwREZGTjsZUERE5VkcV6C666CJuvPFGPvvZz/KBD3yAnTt38lM/9VPMzc0xMTFBkiSMjo4ue834+DgTExMATExMLBt4Fo4vHHs01113HTMzM73H7t27j+ayRURETjoaU0VE5Hg4qiWXl112We/rCy64gIsuuogzzjiDv//7v6dWqx33i1tQqVSoVCpP2PuLiIicaBpTRUTkeDimtgWjo6M87WlP43vf+x4bN24kTVOmp6eXnTM5OdnbH7Bx48bDKnQtfH+kPQQiIiKrhcZUERF5PI4p0DUaDb7//e+zadMmLrzwQuI45pZbbukdv++++9i1axdbt24FYOvWrdx9993s27evd87NN9/M8PAw55133rFcioiISF/TmCoiIo/HUS25/E//6T/xohe9iDPOOIM9e/bwtre9Deccr3jFKxgZGeHqq6/m2muvZWxsjOHhYV73utexdetWLr74YgAuueQSzjvvPF75ylfy7ne/m4mJCd761reyfft2Lf8QEZFVRWOqiIgcD0cV6B566CFe8YpXcPDgQdavX8/znvc8br/9dtavXw/An/3Zn2Gt5YorrqDT6XDppZfy/ve/v/d65xyf/vSnee1rX8vWrVsZGBjgqquu4p3vfOfx/VQiIiInOY2pIiJyPJgQQljpizhaMzMzjI6O8jxeSES80pcjIrIq5WR8iX9kenqakZGRlb4ceZw0poqIrKxjHU+PurH4yeDgwYMAfIl/XOErERGRubk5Bbo+pjFVROTk8HjH074MdGNjYwDs2rVL/xGxxOzsLKeffjq7d+9meHh4pS/npKB7cjjdk8PpnhzZD7svIQTm5ubYvHnzClydHC8aUw+nfyccTvfkyHRfDqd7crgnejzty0BnbVmcc2RkRH+jHMHw8LDuyyPonhxO9+RwuidH9lj3RQGg/2lMfXT6d8LhdE+OTPflcLonh3uixtNjalsgIiIiIiIiK0eBTkREREREpE/1ZaCrVCq87W1vU5+dR9B9OZzuyeF0Tw6ne3Jkui+rg/5/PpzuyeF0T45M9+VwuieHe6LvSV+2LRAREREREZE+naETERERERERBToREREREZG+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ/qy0D3vve9jzPPPJNqtcpFF13EV77ylZW+pCfMbbfdxote9CI2b96MMYZPfOITy46HELj++uvZtGkTtVqNbdu2cf/99y87Z2pqiiuvvJLh4WFGR0e5+uqraTQaJ/BTHF833HADz3nOcxgaGmLDhg285CUv4b777lt2TrvdZvv27axdu5bBwUGuuOIKJicnl52za9cuLr/8cur1Ohs2bODNb34zeZ6fyI9y3HzgAx/gggsuYHh4mOHhYbZu3cpnPvOZ3vHVdj+O5F3vehfGGN7whjf0nluN9+Xtb387xphlj3POOad3fDXek9VsNY2noDH1kTSeHpnG1B9OY+pJNp6GPnPTTTeFJEnC//gf/yPce++94VWvelUYHR0Nk5OTK31pT4h//Md/DL/3e78X/vf//t8BCB//+MeXHX/Xu94VRkZGwic+8Ynwr//6r+EXf/EXw1lnnRVarVbvnJ//+Z8Pz3zmM8Ptt98e/u///b/h7LPPDq94xStO8Cc5fi699NLwoQ99KNxzzz3hrrvuCi984QvDli1bQqPR6J3zmte8Jpx++unhlltuCV/72tfCxRdfHP7Nv/k3veN5nodnPOMZYdu2beEb3/hG+Md//Mewbt26cN11163ERzpm/+f//J/wD//wD+G73/1uuO+++8Lv/u7vhjiOwz333BNCWH3345G+8pWvhDPPPDNccMEF4fWvf33v+dV4X972treFH/uxHwt79+7tPfbv3987vhrvyWq12sbTEDSmPpLG0yPTmPrYNKaWTqbxtO8C3XOf+9ywffv23vdFUYTNmzeHG264YQWv6sR45ODjvQ8bN24Mf/zHf9x7bnp6OlQqlfC3f/u3IYQQvvWtbwUgfPWrX+2d85nPfCYYY8LDDz98wq79ibRv374AhFtvvTWEUN6DOI7Dxz72sd453/72twMQduzYEUIoB3VrbZiYmOid84EPfCAMDw+HTqdzYj/AE2TNmjXhv//3/77q78fc3Fx46lOfGm6++ebwMz/zM73BZ7Xel7e97W3hmc985hGPrdZ7slqt5vE0BI2pR6Lx9NFpTC1pTF10Mo2nfbXkMk1T7rzzTrZt29Z7zlrLtm3b2LFjxwpe2crYuXMnExMTy+7HyMgIF110Ue9+7Nixg9HRUZ797Gf3ztm2bRvWWu64444Tfs1PhJmZGQDGxsYAuPPOO8mybNl9Oeecc9iyZcuy+3L++eczPj7eO+fSSy9ldnaWe++99wRe/fFXFAU33XQT8/PzbN26ddXfj+3bt3P55Zcv+/ywuv8+uf/++9m8eTNPfvKTufLKK9m1axewuu/JaqPx9HAaUzWeHonG1OU0pi53soyn0XH4LCfMgQMHKIpi2QcHGB8f5zvf+c4KXdXKmZiYADji/Vg4NjExwYYNG5Ydj6KIsbGx3jn9zHvPG97wBn7yJ3+SZzzjGUD5mZMkYXR0dNm5j7wvR7pvC8f60d13383WrVtpt9sMDg7y8Y9/nPPOO4+77rprVd4PgJtuuomvf/3rfPWrXz3s2Gr9++Siiy7ixhtv5OlPfzp79+7lHe94Bz/1Uz/FPffcs2rvyWqk8fRwq31M1Xi6nMbUw2lMXe5kGk/7KtCJPNL27du55557+NKXvrTSl7Linv70p3PXXXcxMzPD//pf/4urrrqKW2+9daUva8Xs3r2b17/+9dx8881Uq9WVvpyTxmWXXdb7+oILLuCiiy7ijDPO4O///u+p1WoreGUispI0ni6nMXU5jamHO5nG075acrlu3Tqcc4dViJmcnGTjxo0rdFUrZ+EzP9b92LhxI/v27Vt2PM9zpqam+v6eXXPNNXz605/mn//5nznttNN6z2/cuJE0TZmenl52/iPvy5Hu28KxfpQkCWeffTYXXnghN9xwA8985jP5i7/4i1V7P+6880727dvHT/zETxBFEVEUceutt/Ke97yHKIoYHx9flfflkUZHR3na057G9773vVX798pqpPH0cKt5TNV4ejiNqctpTP3hVnI87atAlyQJF154IbfcckvvOe89t9xyC1u3bl3BK1sZZ511Fhs3blx2P2ZnZ7njjjt692Pr1q1MT09z55139s75whe+gPeeiy666IRf8/EQQuCaa67h4x//OF/4whc466yzlh2/8MILieN42X2577772LVr17L7cvfddy8bmG+++WaGh4c577zzTswHeYJ57+l0Oqv2frzgBS/g7rvv5q677uo9nv3sZ3PllVf2vl6N9+WRGo0G3//+99m0adOq/XtlNdJ4erjVOKZqPP3RaUzVmPrDrOh4erQVXVbaTTfdFCqVSrjxxhvDt771rfDqV786jI6OLqsQcyqZm5sL3/jGN8I3vvGNAIQ//dM/Dd/4xjfCgw8+GEIoSyyPjo6GT37yk+Gb3/xmePGLX3zEEss//uM/Hu64447wpS99KTz1qU/t2xLLIYTw2te+NoyMjIQvfvGLy0rFNpvN3jmvec1rwpYtW8IXvvCF8LWvfS1s3bo1bN26tXd8oVTsJZdcEu66667w2c9+Nqxfv75vS+e+5S1vCbfeemvYuXNn+OY3vxne8pa3BGNM+NznPhdCWH3349EsrcgVwuq8L29605vCF7/4xbBz587wL//yL2Hbtm1h3bp1Yd++fSGE1XlPVqvVNp6GoDH1kTSeHpnG1B/Nah9TT6bxtO8CXQghvPe97w1btmwJSZKE5z73ueH2229f6Ut6wvzzP/9zAA57XHXVVSGEsszy7//+74fx8fFQqVTCC17wgnDfffcte4+DBw+GV7ziFWFwcDAMDw+H3/iN3whzc3Mr8GmOjyPdDyB86EMf6p3TarXCb/3Wb4U1a9aEer0efumXfins3bt32fs88MAD4bLLLgu1Wi2sW7cuvOlNbwpZlp3gT3N8/OZv/mY444wzQpIkYf369eEFL3hBb+AJYfXdj0fzyMFnNd6Xl73sZWHTpk0hSZLwpCc9KbzsZS8L3/ve93rHV+M9Wc1W03gagsbUR9J4emQaU380q31MPZnGUxNCCEc3pyciIiIiIiIng77aQyciIiIiIiKLFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPqVAJyIiIiIi0qcU6ERERERERPqUAp2IiIiIiEifUqATERERERHpUwp0IiIiIiIifUqBTkREREREpE8p0ImIiIiIiPQpBToREREREZE+pUAnIiIiIiLSpxToRERERERE+tSKBbr3ve99nHnmmVSrVS666CK+8pWvrNSliIiI9DWNqSIiq9eKBLq/+7u/49prr+Vtb3sbX//613nmM5/JpZdeyr59+1bickRERPqWxlQRkdXNhBDCif6hF110Ec95znP4y7/8SwC895x++um87nWv4y1vecsPfb33nj179jA0NIQx5om+XBEROYIQAnNzc2zevBlrtYJ/pWhMFRHpb8c6nkZPwDU9pjRNufPOO7nuuut6z1lr2bZtGzt27DjiazqdDp1Op/f9ww8/zHnnnfeEX6uIiPxwu3fv5rTTTlvpy1iVNKaKiJw6Hu94esID3YEDByiKgvHx8WXPj4+P853vfOeIr7nhhht4xzvecdjzz+OFRMRPyHWKiMhjy8n4Ev/I0NDQSl/KqqUxVUSk/x3reHrCA93jcd1113Httdf2vp+dneX0008nIiYyGnxERFZEd8G+lun1F42pIiInmWMcT094oFu3bh3OOSYnJ5c9Pzk5ycaNG4/4mkqlQqVSORGXJyIi0jc0poqIyAnfxZ4kCRdeeCG33HJL7znvPbfccgtbt2490ZcjIiLStzSmiojIiiy5vPbaa7nqqqt49rOfzXOf+1z+/M//nPn5eX7jN35jJS5HRESkb2lMFRFZ3VYk0L3sZS9j//79XH/99UxMTPCsZz2Lz372s4dt6hYREZHHpjFVRGR1W5E+dMdqdnaWkZERns+LtYFbRGSF5CHji3ySmZkZhoeHV/py5HHSmCoisrKOdTxVJ1gREREREZE+pUAnIiIiIiLSpxToRERERERE+pQCnYiIiIiISJ9SoBMREREREelTCnQiIiIiIiJ9SoFORERERESkTynQiYiIiIiI9CkFOhERERERkT6lQCciIiIiItKnFOhERERERET6lAKdiIiIiIhIn1KgExERERER6VMKdCIiIiIiIn1KgU5ERERERKRPKdCJiIiIiIj0KQU6ERERERGRPhWt9AWInPKMeezjIZyY6xARERGRU44Cncjx1AtvBkz5p1ka6LrPLQ1xgbD4/SP/FBERERF5DAp0IsfDstBmyxBnus8bA8YuO62X14LHhPJPwpJwt/B2CnYiIiIi8hgU6ESO1UJKM93ZOGPBlkHOWAvWLp5jbZnVugGOEMB7grfdcLd0tq73l+5TYfE5BT0RERERQYFO5NgszMBhMHYhzFmMs+DcYqCziyEPWAxu3pePovvwxZKstrj8snd+gBAC4Bd//uLFLPl6SeALj/K1iIiIiPQ9BTqRx6sb5HphzrrFIBdFELnya+cWA53tFpb1oZyl855QeExeQJ4TCtvbZodfsp/Oe4L3i+HOL1yDXdyXt+QPls7ohQCEbhA0aIZPRERE5NShQCfyeCyEObMkzEXdIBdHEEWYOIY4IkQOIkdYCHVQBrOFWbk8x2QFIcvKYLd0/1wIZbDrzeQVhMKzUHTFLCznXLLsc9myzBAI3fC4MMu3LMsp2ImIiIj0NQU6kcfLsDzMdQOcqSSQJIQkJlRiQuLwsSU4S7DdIOYDJg+YvMCmBXRyTOog98sDXTfMhaLAFAXkBRTdhyln/JaFOrNkBs4vWdZZdGf4fBnsFmb7ygk7hToRERGRfqVAJ3K0zNKCJ0tn5mJMJSFUK4RqQqjFFNWIourwicXHhmABTC/QudTj2gW2HWHbDlP4MvRRhr6FMGbyArK8O4uXQ97dl+fsYqiztreikoXQ5n0ZBAvfC4LB+26O84tb7RTqRERERPqSAp3I42EWl1uaKIKkG+ZqFUK9SjGQkA9E5AOOvGbJqwYfg3eUM3QFuAxcOxC1HHHT45qunD1bWJbpwRQem3tMmpePTgRpRsjzcm9ed69eWNiftyTQUXiM92UQzPNuEMwhLwjkGE8Z+o5EAU9ERESkLyjQiRyNhSDXXe6IK/fHmTgmdANdMZCQD8WkQ450yJINQF4z+AR8VAYlWxhsClEL4nmHTwxxbAh2YRYPCGCzgM08rh3h2mWIM85iMkeII0jKPXohcmANobvkspwB9IS8wGQFJs3KIGgtxmTl2+d5t4XC0jYJ3S+7hVSWNMxbdlxERERETg4KdCJHa8mSSxM5iGJIYqgl+HpCNhSTjjo6I5Z0xJANBvJBj696iLr71nKDaVuieUM+ZygqlrxqjzyL1wlETUfUckSxwzUt5AU+ifDVCL+wRy8qA50JZaCzWcCmBbZdYDpR+Wjb8pyFz1IUwNKWd+ERbRK6RVTCwt4+BTsRERGRk4kCnchRKrsEdGforMPE5WyZr8QUtYhssJyZ64wYOmOBYqTADmfUqilJUs6KpXlEpxWTzcX4OCI4QzYARQJhaaBLwbUgrjriedNdWgkmDxS1iLzmKGqWIi6XdAYDJiy8NuA6jqhVLud0ke0W5jTdeiimO2PXXae50CahWxWz3IO3EO66s3aB8gco1ImIiIicFBToRI6GKZuH94qQLOxjS2J8JSKvO7JBQzpkSEcDxVhOZU2b9aNzrK81GIo7GALzeYX9rQH2V4douhqpjQkm4CsB4m5ayg22Y4jmDUXVUCSWYCA4gykCed2SDVqymqGo0Cu6YgKYvDuz17bEDU+cGOLI4DDYblGWMvxF5WwjLOmNt9AmoSymEooCvMEshLxgWGyEJyIiIiIrSYFO5KiYbi/xbpVLZwnOEWKHrzjyqiWvGbJByIc9yWiHTWMzPG1kH1uqU6yN57DAobzOrupavhfl7PKGdjCYak6llvVm8bIsotOOSediiorDRwYTLD4pe80V1TI4ZgNQ1AI+8QQHxoPJDK4N8XwZBH1syh54gXLGrfDdfYBLeth5v7xNQl5A0a2oWRSEbou84ANgAa+ZOhEREZEVpkAnctS6IciWoS44S4jK0OQTQ1ExFLUAAzkjQ022DB7i3IG9nF2ZZINrYIGDRY1B1yEPltlOlWkDawabrK3Nl7N4JjCfJRxoDXCwMkjb1khDhPFliDMF+BjSkUA+7KFe4Ko51gWCN/jUUTQdxZxb0i7Blb3vCo/LfVlQxdnF3nV+sdm5yfNumwSHsVkZ6ozpFlLxBE93pk6JTkRETi7GBOpDnvlZt9KXInJCKNCJPG6LwS5YQ3AGH1FWs0wCrlIwUm2zsTrDGckBnhxPs9GVc1sjdpYcx4HKILura6hGOU8ZPtCdxWtgCEwXdXa3xvh+vI5dGDq+RjsuS2CavJwpLEZy4jUdRgZbjFRbJK4g95ZGWmG6UadVrdKJIsBiPLjUYbMIUwRCZAnOLBZJ6VbGtFmBSQtMJyurYzpHSNPFfud5gaEgeLN4K9TmQEREVthP/cI0w2tykmrgZ35xmpv/fs0Rz3vwu1XuuWPwBF+dyBNHgU7kaBh6Sy57j26wW2g5EAwEC855EpdTsxmDtsOQ8QyaCgZD23YYMB1qNqUepYxVmpwzsJenVPYx7uYwBKb8AIN2cRbvQOpgqLwMnzl8bqkMt9k4Nsvpg4fYVJ2lZlPSEDGVDvBgsoY9bpSGr5OlMa5jyJuGqOUIUVlIJUTd2btQLtW0Wdns3LYLXNth22U7hLIR+eItCHnotTwIvlu5U6FOREROsEtffpBn/+wcAD/23HmG1+TESTkenXvh/BFfs++hhAfuq/Kdr9f5//7retqt7uAt0qcU6EQet7D46DbzNkuf8obcW1Lv6ISIdjC0Q4EF2iHQCRFpiIisZ1N1hrOSAzw1PshGF7AYDvhD+GCYqg6wpzZCvL6gGpU95FpZwmyrykitxdNH9nHOwF7OSA4waDt0QsREPspA1AEDD2aOTtuRNR1x1ZANWnzUXRoal+HT0C2kkoFre6KmI563uNjhuvvsejN03bYGAVN+Zjwh+IWDJ/j/AxERWc0+/7/G+MLHF2finv0zc/zbX5li3aaMp/9484iv2XBayobTUp79/Dl+Zfs+3vuW02jNW+68dYh2U8s0pf8o0IkcjV5g6/Zp86FX2t8UZbsAm4PNDEXqaKQVprIB9majDNkOOc3uHroqe/MRDmaD5MFSdx2GXJth6xmyFSyGlA5Dts2A67C2Os/pA4cYiVsAzGY19raGiaxnS+0gT61M8uT4EEPW0w6GYdum5WMOpXUO1AbpVKv4isUn0BkuC7cU1YU2CaEb6AyuA1HTElcCIY6JncEEsIGyWbn35Q2wBvKiLJZCObsXUKgTEZETq8gNRb44u7bjcyPs+NwI46d3eNZPNnjNO/dQqXmsDb0aYAusC1TrgTe/ZxcAX/rHEb74iTX8y2dGgLJWmGbupB8o0Ikcte6MnA/dXm0ekxXYzHd7vwVcC4pmxKFGnQeTtdRdSssnrI9mMcBUMcCD7XXsnF9LO4/JvCMNjjQYslBgMKQhkOEoguXM+kHOrBxgnZvDAAeKQXZW1jPZGWZd1GBD1GCjCwzaCp2QU9BifTTHSNyilmSY2OMjyKsGPwjZUKCoB0LVg+t+nsxi24aoYchrFh8HvI0gQBzKgikmBIxzhCzD2LxbJCVXqBMRkZPK5O4K/3RTwpf/aQRj4A1/vJunnt9iw2npo77meS+c4Tk/O8frbij3q//PPx3nUx9et3zPuMhJSIFO5GgFyn5tYbEyZMg9NvXlcsWWJWoaijlHq1rlYTdCAKayAUaiFsYE5vIqE61hJuaGqcUZh7IBJrMRRmwbT6ucxfMVJvIR0hBxdmUfT00m2eBSIHDAN4iMJw8OawKWgDNlj7ny4bHGY03ALEwrGihqkA57/GiBG8io1lLiqMAHQ5qWzc7TWoJPLGDAW1y2UEglwViLSTNMp9uHr3s7DKEb6kKZ5bSnTkREVpxh7lD5n7rvvPoszr1wnue+YJZXvH7ysNm6BZWap1Irfzn5H96+h01npBSFYXJ3wqduXNt7X5GTiQKdyNEIZWPtEMp+baYoIM8xWY7r5EQtRzzvKSplG4PgYub8AA+kEftrg9SSDAh08phGq0JnPqE91GZXZQ1DUZtOiJiMZsuiKMUgD3bWUrU549EMm6IOG1yMwRAVHWaiGR5ya5jO60wVNQ7YGTq2QzsEpooqh/IB5vIq7Twi5GWVy3TE48dyBsearBtqsL7WoO5SimCZzarsbw5yIBkkc1VM4bCFwaUWU0SEyOBaEbYdYV3ZXN0AmIVQl3VjXbefnYiIyEnk23cOcN9ddW7++zF+7c0TnH1+i7HxjIGh4ojnR3Hgpa/eD0DatvzSq/ZzcG/MX7zlNHxh2LMzQeFOTgYKdCJHLfQacFMUZRn/NMO0I1ziiBtl0ZFgwQRLlsZ0Wo5OtYqJyz1oIbfQdpiOoekND9k1BAwH00FG4ibGQCOv0MgrnDM4gTOeCIgoZ87Krz0hGB5ORxhwbQosAwtFUbIRHuysY6I1xHyrSkgtwYAfLqiPttgyNsVTBg+wpXqQYdcmD5YD+RAPVNbyXeOZDIa8UyXrOFzbEJwjalnieUfUdETWYLvVLxerXZZBzphAWPjVp2bpRETkJOILw54HKrxr+xkA/PSLpjn7/CbPel6Dpz/ryEVUAJKq50lndXjSWR3++rbv0Jq33PSecW779Ch7dlZO1OWLHJECnchRKqs8ekLhwRaYLAdnMZ0I13TEbkkj7wJsx+CarixK0v0nznafB0hNzGyokxWWA7UB6nGKMdDJIwaTDqfVKswUNQ65Jokp1/5Pe8u0r9Moquxpj5L6iKnqIHWb0vERB7NBfjC/lsnGMLm32HpOYQN2IGNsaJ4nDxzkvPoezq7sY8S2KYJhohiiajJaRUwzTTg0l5APWNrG4FqGuBkoEkMSl9cdAXahUEpRlH96X85emqAwJyIiJ73bPjXKbZ8aZcNpKU9/VpM3/dkuagP+h76uNuD5jev28vyXTPP7v3YWMwcj0rY9AVcscjgFOpGjErqN5hZn6MgzQmow1oIxOANJAFsEXOqIm6YsRpKAd2UYMj7g0kARgyksWZrQajpa1Vo5i2cAExhb0+Dh2ig/iDcAcChqdIuiDPCDznoeao+ye3aUh80Iu6prqLi8LLDiHbm3rBtoMFZv0kgTZpo1QjCMVZs8qXqIM5P9PCWeZY215CEwYA/RCTF7qqPsrQ4zM1AnN4G847BNQz5X9q7zUXeNJYGo8NiiXHoaCg/OQ+ExpmxYrlAnIiL9YN9DCfseium0z+BNf7ab0bX5j/S6s85p8Td3fJvPf2wN935lgO/+a50ffKv2BF+tyHIKdCJHIwCmLPxhFpYZ5gXG5ARjMcaUiyK7VSFtGhG1HEXFlHvqbFmixPqyzUFRMVgPLjXkTUdRcYQIggn4WmA2rrMrWUNiCxq1KmuisknqdF5nd2sNu+bWMDUzQJE5pqoDxHHO2ECTjfVZNtdmGHAdimA5lNV5qDrKgeYgFZdTtymDNmXIGAZMQmECg6HDgC2bnVejnLVrGuTDjmYroTOfkCYRoVsIxWUWm0fYToFJI0wagcvLUGuNKoKJiEgfMnzl8yP8wdWO510+wwt/9SCVqn/sbXIGrAlc8rIpLnnZFLvur/K2Xz+LfQ/F5Jlm7OTEUKATOVrdWafgfVnMkXIzdVnYMWB8gMITpQW2HRElET6xBGfLpZjGlOcEKGoWlzqieUNeK2fxgjN4Z0hHA5mrsDeM0slj9taGGYhTDNDIE6aadQ7NDpBNVSG1pGsMQ+tanDk0xTmDEzy5so8R2yLHMpmNsCbewD1mM0WwdELUbXYeqIWCHE8nWNIQETCcMTjFk4cO0C5i9rcHmWgMMxUPkpFgvMOlYFNbFknpxIROholcuTfQWrAeEyxBSy9FRKTP3POVQb515wD/80/HecMfP8TTf7zJhic9eruDpbY8tc1/veU+br95mPe85bRelU2RJ5L+LhN53AIh+LL/Wk4Z1Mpne/vKbBZB5LCxK2e37JJiIcZg0wibBlzbUjS7xVRcIK+ZcqbLOnJfZX/qmK7VSOIyPGaZI23HhLkIN+fwVU9czVlbb7KlNsXZlUmemhxg1ObkwTBqWxTdoisT7WEOZINMxCMM2Q7NkJEHw0RRZ18+zGjU5Kzqfiomp+kTdlfGqLqMwhsOpZa8bckbhqJm8BVLiC04VwY5Uy47XawHXd4RERGRfuILQ2Mm4g9ffSbnb23wjg/tpD5UPGq7g6WSquenXzRN8PCua87AF1q1Ik8sBTqRx2PJrFPwvqwBAmUrA+8JC+0MogicW1yK2At0gDWYToxtx2XRlNgRIoOPLdmgg2AxuSFrO/KGJavGpFH5YpMbbMdSrsA0dAYhTnIG4w5r4wYbolk2uYJRWyEPnkCbg9Eso3GTB+bH+MH8OhyeeZ8w4loU3SqXBZYfqz7MpmiWqvE0QsQaN48B5vMK880qaT2iqDqKpLxWHzlctDAz1w10C+tTFr7WLJ2IiPSpu3cM8Bv/5lwuefkUv/afJkiqP7xoCsBPv2iGmYMP8763nvYEX6Gsdgp0Io/X0lBHd6YuLLY0MEVB6FbAXAg6pvurvQBlH7e8IGQFtu0IkSuXW1YjjI8hRNjc4NqGvGm6ga/8eaYAm4JLA52R8h0NYbHJOAELZZNxY7rfl8dDgAdnxugUEQeyQQZcig+G2Bb8WP1hTo9neJIrqBrHXOiQhWn2J0OsqYxRqWSkSQUfO3wE3gGuDKrGdmfmul8Ha8twiznsfomIiPQPw8xUxMfev4HGjOMnL5vhOT83+8NfZQMX/JsGZzy9xYP3qVCKPHEU6ESOxUJICWVLbWNCGeqCh9yCK8pllsZiDARjF8+PXFnuP8vKWTxnCdZh8grGB0wecB1H1LQU1bKoinfly20BNgsUFUM2CKYw5LmjmSfMFDWmijoHXRtPhzwEpnzMoaLbaDyLmZoZpNGqMFkbJolyKlHOBaN7qNmUuimom4iKifAE6iajZjMqNsc5DxaCDeV+QGsIhm6Qs5jIQRGXK0qBUJThM+CX3y8REZE+9JmPrOVL/zDC5rM6vP1/PMDYePaY5595Tps/+Jud/M6vPIW9D6pfnTwxFOhEjlV3Pxzel6X6TcAEU4YYb7ozc7Zckrl0GX3hyhk6t7hc0UQRhIArPCbzuE5E1HT4xPaqZELZ9gCgvcZhU4NtG9JWzMFWnd2tMQZdG4AR1yIPlsl8hJ2ddextDTPTqpHPxhR5UrZJqBSMr52h7SNaPqEZHM2Q4wk0Q0EzJLR9TMdHFIUFD8YvFHYJZahLIkK9stho3PQKgnZnLbXsUkRETg1z0xH3fSPibb9+Ftd94EE2n9l5zPPHT0/Z/p8f5q2/+uQTdIWy2ijQiRwPS8NKCGWww2DKabvFGaqF3dSGcmlmUSyGOWsJRVk5k6LA5jkmjcuCKrHrBr/F5YtFLSKqW1w74FqGtBFzqDrAD+K1eAwz1TpDrk0RLAezQR5sjfHQ3Cjzc1VcwxE1DEXiyNcY5gcrHOwMsLcyyno3RxHmqJiC+VDhoWwNe7MRDnVqdDoxpBbTbc+TVy1mKCIAkTU4ui0bAmXA9R68LWcujZZeiojIqeO7/1rn+qvO4tk/M8dv/u7ex9xbF8WB4bGcuWmn1j5y3CnQiRxPvbDSbW0QlvxLe0lpLGMMGF/+S32hMqSzZbPy4CGPMHmB6WSEKCqPOdt7j+AsGIhalni+XJJZVBwdW2U3a2ikFR6ujVBzGT5Y5rIKU/N1Zmfq+EMJlRlDMm3I6+ATR7NR4aHaKFWX4zHsiWepmJx5X+Ghzhjfm1/P5NwwaTPG5IaiGuisMfiYbu880wubzgdMKMOq6e4nDGXjPoU5ERE5pey+v8ru71VozVt+6z8/XPatO4JnPW+Om+66l199znlMTcYn+CrlVKdAJ/JECId9sRhmjOkGnO5yTELvORPKPXim6FbKdA6z0BLALoQ/oJqUPe6anrjiyyWZkSEjIvU19rVipmt1XOQJAbI0Im9FmNmIZMYSzxpsEcpiJoUhb8YcmBkEoFXEjMQtEluUfeg6g+ydG2KuXcEmBWEskNVd2Qg9MfjIABbjHaaIMFmMzQtMlpefwVowHmNMOUunUCciIqeSYPjs346RVD2vecceXHT4OGcMOBd4xX+c5H2/p6qXcnwp0ImcaL2KIXSLqRjK/5V97ej2sKMo2x30+teZbqBzFmMMNnK4eUviTPf9LC4zpG1HUXOklYTgyn4KNjdEbUM8b4gaAZsH0mFDOubxozm1kTbDAy0qUc50WmOqUyfzjmYakxWOapRz2ppprAl0iojZVpX5RpU0qRAiiwkGm9uyr17HY7ICk2aQ55C7MqD6H63Ms4iISP8xfOrD68hSy394+8PUBo4w5hk49yeaJ/7S5JSnQCeyEkLvL71wF7wvZ+wCBB+g8IvLLBdm86yFKIIog7bDOdcNe+WKRptZXAfyblXM4Mr3tgXYDkStgM2hM2rIhgN+JGdgrMmm0RlOH5hmTdwksgWtImFve5iH81HW1po8qT7NaNIiMgXzeYW97WH2JKPsD5AVFVzH4dqGqGWJmq7XhmFhdjHYheIwRm3GRUTklBS84TMfWUsUB675o4eOeM6G01Ke+4JZvnLL8Am+OjmVKdCJrLTDCqqE7lJM0wt55YOyeAoQOhbTndlzlL3vbB7h2o68abtNv03ZWgCwecBmZehLh8q9c/mgpzLSYfPoDOeNTPC0+gTj0SyxyZnzVR5I1lN3GeuSBmfXJhmPZ4komPU1dlbWU3MZWWGZyh1Z0xLNG/KaoahYXOxg2VJRs2wPoYiIyKlqxz8N87JrEtZvTg87NrI256J/O8Nd/zJI2rYrcHVyKlKgEzlZHKlSZjCLOciY8hST92a6DEAAV3hsluDarmxzEJd76rDlnjXjy/PSYUeRQFEJUCsYGmizeWCGp9T2cW5lD5uiJokJzHlHxeSkwbExnuG86l42uiYxgRkfkZiCjo840B5kbr5GVosoKq7slRcZQtQt4qIwJyIiq8yBvQl/+Ooz+N0PPMj46YeHul/4tYP8nw+tU7NxOW4U6ERONkualQOL5f4XZu26LQMM3WbmIWCKgpAVmE602ObALgS68vx8ICK4siJliAMm8dTjlNG4yYZ4lk1Rk03OUjGOWZMxF80yEc8xHs2y0TXZ7ByRsdR9xmyYZV3cYCjukCQ5aRQIEXgHwXWLnyzs+Vs6w6hgJyIiq8B3vj7Ad/+1zobT0iMOfW//0AN89qNj/N1fjp/4i5NTzlHP9d5222286EUvYvPmzRhj+MQnPrHseAiB66+/nk2bNlGr1di2bRv333//snOmpqa48sorGR4eZnR0lKuvvppGo3FMH0TklNULeN19dr4g5AUhyyFNCe0OodXGzLewcy3sbAs33SSabhIdahLNtLBp3mtqXjY4LwuzWBOIjCeiIAJiY3FYImOIjMfhiYwnJhAZS4QlAiIKHB5nPKb7XqHXVbz759Iu4yJyGI2nIqe2P379Fr76hSPvldt8Zofn/Nwc646wLFPkaB11oJufn+eZz3wm73vf+454/N3vfjfvec97+OAHP8gdd9zBwMAAl156Ke12u3fOlVdeyb333svNN9/Mpz/9aW677TZe/epXP/5PIXKqC4FuWcyyYIr33VCXEdIU2h1Cu01otTDNFqbRxDRamPkWdDIIYPySR2EIuaFTRMwXFWZ9jRkfMe0zZn3KjPfMFFUavsqMrzHtI2Z8xozvMOMDM75Gw1dpFTF57qAwmKL73qGcNeSRD0AVUUQWaTwVObV1WpbP/6815OmRf7F5/sUNNp+pQCfH7qiXXF522WVcdtllRzwWQuDP//zPeetb38qLX/xiAP7mb/6G8fFxPvGJT/Dyl7+cb3/723z2s5/lq1/9Ks9+9rMBeO9738sLX/hC/uRP/oTNmzcfw8cROYUt2WMXfPGINgdlq4PD2hxEEcaVbQNM7rF5wGUB2wHajrlWlYnWMA8k66mZjFk/Q2IK5nyVH6Tr2dVeS8vHJCZnzs8SmYIZX+P7nQ3sao9xsDVApx1jOwaXgs0CJveYIkARuo3Sl4Y5JTqRBRpPRU59t/2fUX7mF6f5yctmjnj8gosb3L1jgBC0mkUev+NaXmfnzp1MTEywbdu23nMjIyNcdNFF7NixA4AdO3YwOjraG3wAtm3bhrWWO+6444jv2+l0mJ2dXfYQWZUWZupCIPhub7fCE/K8nK3rztiFTgpZXgaq7jk299g04Drg2gbbtDQbFfbMjfDdxga+2TqNb7TO4OutM7irtYVvzW9mZ2Mt98+Pc0/zSdzVPp272qdzd+s0vtPcyIONMaYadfx8hGsZXCcsC3Xlzw4Q/JIZRhH5UTxR4yloTBU5kUIwfPyv1tNquCMef8m/34898iGRH9lxLYoyMTEBwPj48g2e4+PjvWMTExNs2LBh+UVEEWNjY71zHumGG27gHe94x/G8VJH+Fcq2BgtLGYMJGGPAG4LptjlY6Pu2MHOX5dhOQdQqiJqGuGHxiaWTJBxgiKywHGwPMJS0iYynXcTMdGoMxB02V2bYUpliPJohMp7ZoobH0sirHKgO0K5W8EnUrXAZyqIoS6tbmqUb60TkR/FEjaegMVXkRLv79gH++PWnc/1fP7DSlyKnqL5ogHHdddcxMzPTe+zevXulL0lkZT1if1rwS2bsfLE4M+cLyAtMVmA6Oa5dEM97kgYks5AcsoSphEP7h3hg/1ru2z/Ot/dv5Hv719PJIzbVZzmrup9zKhOcm0xxXnKIcyr7OLsyyZbaFGP1JnE1w1d92Q4h7va/U9sCkZOWxlSRE81w/zfr/OXvnsb8rKbj5Pg7rjN0GzduBGBycpJNmzb1np+cnORZz3pW75x9+/Yte12e50xNTfVe/0iVSoVKpXI8L1Xk1LFsOaMhYDEBQtHdW5fnmDTDRA7XjIhdt0cdFrzBpo583pLXYrLYgwU7lLFxdJbRuMl4PMO4a7HJOSLjqJmU2WiWdfEcQ0m7bFsQB3wEwUGwS2fo7JLWBSjYifyInqjxFDSmiqyEfQ8nfOrDa3n+iw/xjIvme89P7Kosa0Mr8ngc1xm6s846i40bN3LLLbf0npudneWOO+5g69atAGzdupXp6WnuvPPO3jlf+MIX8N5z0UUXHc/LEVmdejN3HvICuvvrTCfFtlLcfEoym1OZ9lSnAtUDgep+Q3XSUpmIsPPlvxbKaFg+HAFnLA6DAxy+d8w8slUBj/K9iPzINJ6KnIKC4T+/5kz+5k82Mn2gnFP5b+/cjC80WMqxOeoZukajwfe+973e9zt37uSuu+5ibGyMLVu28IY3vIE//MM/5KlPfSpnnXUWv//7v8/mzZt5yUteAsC5557Lz//8z/OqV72KD37wg2RZxjXXXMPLX/5yVeQSOVah2xMueIw3BFNAbjE2K/fUWYvrzuaZImDTiKhtyecNRWJIhw35oMHnlnYe0SgqTBd1DvmYapESG8O0h0O+zmxRo5knZIe1LQgYH8qCKP6RbQv0a0iRBRpPRVafqcmYj/zpRv71S4P89Ium+e5dtZW+JDkFHHWg+9rXvsbP/uzP9r6/9tprAbjqqqu48cYb+e3f/m3m5+d59atfzfT0NM973vP47Gc/S7Va7b3mIx/5CNdccw0veMELsNZyxRVX8J73vOc4fBwRAbot67qBKi8I3Wk0YwwmBJwP2Mx3C6VEFBVLOuwoqhbbgaLtmG3V2NsaYWeyntgUzPaKolT5frqB3e0xplp10laMbS+2LbBZKNsW+CVtC0JQkUuRR9B4KrJ63fOVAe75ygBayiLHgwmh/35lPjs7y8jICM/nxUQmXunLETn5dAuRGGPBWkzkyp50cYxJYkgSQhJBJcYnEcVAQmdtQmvM0dpg6KzzMN5h7do5njJ6gDPqU6yNG0QUNHyV3a01PNBYy+6Da2gfqJPsc1T3Q+1AoHYgI55uY2eamGbZ7Dx0UkKWgy8IRbHSd0eOkzxkfJFPMjMzw/Dw8EpfjjxOGlNFRFbWsY6nx7UoioicJLq/pwl4jIeQUxZKgW5fugKTx5Dl2GqFEFmiVkTctOQN8ImhkyQcZIi8cOxvDTKUdHDG08pjplp1DjUG6ExVcTOOeM4Qzweipse2C0xaYPJuePOLfej679dHIiIiIic3BTqRU9UjQx1loZPgPSZ4QlFgQgWcw3ZyXCsnrliKhsNHBu8suU84lFkatSpxkmNMIC8caSsizMe4aUcyY4jnAvG8J2oVuE6OSfOyIEtREIpuOwU1FxcRERE57hToRE5lh4W6sNijLgrlckznoO1wcbelgQOCxXhD1um2NKjGZHFZcMUUYDsW14J4zpDMBZIZTzJbEM3nmFaGSTNClpWhrrePDuU5ERERkeNMgU7kVLcQ6oIHDMYYAgZjyqbjIcswqcO2HM4aEgsmRJjC4jqQNw2+YvARi4EuBdcOxM1yZi6ZLYgbGa6ZYtoppBlkOaFYWHYZuj9fiU5ERETkeFKgE1kNuu0M8IFgDAZDKCibjtuFAiqm29IgYPKATR1xy5FXDUVsCI4y0PmymqVLA1HLEzU9rpnh5jNMs4PpdAj///buPc6uur73//u7bnuue08mlxkiCRe5hAhBDZrsqq1HUiJGiyWcH+WXH6QtP31IJ/yEWI7GIgieR8MPH5UjPYJ9tJb4e1TkiKdIRUFjkFBluEVSQygpWHSCycyEJDN7bnvvdfn+/th7djKZoE4yyWRlXs/HYzcza609+7u+pPn4nrXW91MuS1FUeSXVnngHty8AAADApCDQAdOFtZXVLw9uaRDHsmGlA/i4lgZlT8mwKz9TeabOuqbyHJ61cqJKewK3GMspRTLFUGakXAlzpcoVOhtFtWfnUriYLgAAQCoQ6IDpZEzj8erqlzroRkhrZZJEimJ5ZV82cGU9V4nnSI6pXeUzsZWJEpmwsgCKKYWVEBeGB8Jc9fm5AwuiAAAAYLIR6IDp5je0NDBJdfXLKKo8B+d5Mq4jx3Wqve1UOTCuLKxioliKokqPubByi6WNoupzc3H1ypwd87kAAACYPAQ6YDr6TS0NqqFObiS5roxTaU4uxxx4b1JZLdPGcSXcxdUrcnFcuSIXJ7JJNczx7BwAAMAxQ6ADpqs3a2kQVxqPy3FkHEfWGb06N3qFzo4NddU2CAc3EbdJcuAzCHMAAADHDIEOmM4OCnVKqi0NrK18fXCYkypX6Ubfc9CrEuhGv08q77fcZgkAAHA8EOiA6e6g8GXNgRUvbZIcuDInqXJ5rvamA6tlHtzn7uAAR5gDAAA45gh0AA4JX1ZW1fYG5kCIM7VAZw9aFbP6f2p/EuIAAACOJwIdgAN+w62SRDUAAIATjzPVAwAAAAAAHBkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKTWhQLd+/Xq9613vUnNzs+bMmaOPfvSj2rFjx5hjisWiOjo6NHPmTDU1NWnlypXq6ekZc0xXV5dWrFihhoYGzZkzRzfddJOiKDr6swEAICWoqQCAyTChQLd582Z1dHTo6aef1saNGxWGoS655BINDQ3Vjrnxxhv13e9+Vw8++KA2b96sXbt26fLLL6/tj+NYK1asULlc1lNPPaWvf/3r2rBhg2655ZbJOysAAE5w1FQAwGQw1lp7pG/es2eP5syZo82bN+v3f//31d/fr9mzZ+v+++/XFVdcIUl6+eWXdd5556mzs1NLly7Vo48+qg9/+MPatWuX2traJElf/epX9elPf1p79uxREAS/9XMLhYJyuZzer8vkGf9Ihw8AOAqRDfWEHlZ/f7+y2exUDyf1qKkAMD0dbT09qmfo+vv7JUmtra2SpC1btigMQy1btqx2zIIFCzR//nx1dnZKkjo7O3XBBRfUCo8kLV++XIVCQdu3bz/s55RKJRUKhTEvAABOJtRUAMCROOJAlySJbrjhBr3nPe/R+eefL0nq7u5WEARqaWkZc2xbW5u6u7trxxxceEb3j+47nPXr1yuXy9Ve8+bNO9JhAwBwwqGmAgCO1BEHuo6ODr344ot64IEHJnM8h7Vu3Tr19/fXXjt37jzmnwkAwPFCTQUAHCnvSN60Zs0aPfLII3ryySd16qmn1ra3t7erXC6rr69vzG8Ue3p61N7eXjvm2WefHfPzRlfsGj3mUJlMRplM5kiGCgDACY2aCgA4GhO6Qmet1Zo1a/TQQw/p8ccf1xlnnDFm/+LFi+X7vjZt2lTbtmPHDnV1dSmfz0uS8vm8tm3bpt7e3toxGzduVDab1cKFC4/mXAAASA1qKgBgMkzoCl1HR4fuv/9+Pfzww2pubq7dn5/L5VRfX69cLqdrr71Wa9euVWtrq7LZrK6//nrl83ktXbpUknTJJZdo4cKFuvrqq3XnnXequ7tbN998szo6OviNIQBg2qCmAgAmw4TaFhhjDrv9vvvu05/+6Z9KqjRB/dSnPqVvfvObKpVKWr58ue65554xt3786le/0nXXXacnnnhCjY2NWr16te644w553u+WL1liGQCmHm0Ljg41FQAgHX09Pao+dFOF4gMAU49Ad3KgpgLA1JrSPnQAAAAAgKlDoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKTSjQ3XvvvVq0aJGy2ayy2azy+bweffTR2v5isaiOjg7NnDlTTU1NWrlypXp6esb8jK6uLq1YsUINDQ2aM2eObrrpJkVRNDlnAwBASlBTAQCTYUKB7tRTT9Udd9yhLVu26Pnnn9cHPvABXXbZZdq+fbsk6cYbb9R3v/tdPfjgg9q8ebN27dqlyy+/vPb+OI61YsUKlctlPfXUU/r617+uDRs26JZbbpncswIA4ARHTQUATAZjrbVH8wNaW1v1xS9+UVdccYVmz56t+++/X1dccYUk6eWXX9Z5552nzs5OLV26VI8++qg+/OEPa9euXWpra5MkffWrX9WnP/1p7dmzR0EQHPYzSqWSSqVS7ftCoaB58+bp/bpMnvGPZvgAgCMU2VBP6GH19/crm81O9XBOCtRUAJh+jraeHvEzdHEc64EHHtDQ0JDy+by2bNmiMAy1bNmy2jELFizQ/Pnz1dnZKUnq7OzUBRdcUCs8krR8+XIVCoXabyQPZ/369crlcrXXvHnzjnTYAACccKipAIAjNeFAt23bNjU1NSmTyegTn/iEHnroIS1cuFDd3d0KgkAtLS1jjm9ra1N3d7ckqbu7e0zhGd0/uu/NrFu3Tv39/bXXzp07JzpsAABOONRUAMDR8ib6hnPPPVdbt25Vf3+/vv3tb2v16tXavHnzsRhbTSaTUSaTOaafAQDA8UZNBQAcrQkHuiAIdNZZZ0mSFi9erOeee05f/vKXdeWVV6pcLquvr2/MbxR7enrU3t4uSWpvb9ezzz475ueNrtg1egwAANMFNRUAcLSOug9dkiQqlUpavHixfN/Xpk2bavt27Nihrq4u5fN5SVI+n9e2bdvU29tbO2bjxo3KZrNauHDh0Q4FAIBUo6YCACZqQlfo1q1bp0svvVTz58/XwMCA7r//fj3xxBP6wQ9+oFwup2uvvVZr165Va2urstmsrr/+euXzeS1dulSSdMkll2jhwoW6+uqrdeedd6q7u1s333yzOjo6uP0DADCtUFMBAJNhQoGut7dX11xzjXbv3q1cLqdFixbpBz/4gf7wD/9QknTXXXfJcRytXLlSpVJJy5cv1z333FN7v+u6euSRR3Tdddcpn8+rsbFRq1ev1u233z65ZwUAwAmOmgoAmAxH3YduKhQKBeVyOXrmAMAUog/dyYGaCgBTa8r60AEAAAAAphaBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABS6qgC3R133CFjjG644YbatmKxqI6ODs2cOVNNTU1auXKlenp6xryvq6tLK1asUENDg+bMmaObbrpJURQdzVAAAEgt6ikA4EgdcaB77rnn9Hd/93datGjRmO033nijvvvd7+rBBx/U5s2btWvXLl1++eW1/XEca8WKFSqXy3rqqaf09a9/XRs2bNAtt9xy5GcBAEBKUU8BAEfjiALd4OCgVq1apb//+7/XjBkzatv7+/v1ta99TV/60pf0gQ98QIsXL9Z9992np556Sk8//bQk6Yc//KFeeukl/dM//ZPe/va369JLL9UXvvAFfeUrX1G5XJ6cswIAIAWopwCAo3VEga6jo0MrVqzQsmXLxmzfsmWLwjAcs33BggWaP3++Ojs7JUmdnZ264IIL1NbWVjtm+fLlKhQK2r59+2E/r1QqqVAojHkBAJB2x7ueStRUADjZeBN9wwMPPKCf/exneu6558bt6+7uVhAEamlpGbO9ra1N3d3dtWMOLj6j+0f3Hc769et12223TXSoAACcsKainkrUVAA42UzoCt3OnTv1yU9+Ut/4xjdUV1d3rMY0zrp169Tf31977dy587h9NgAAk22q6qlETQWAk82EAt2WLVvU29urd77znfI8T57nafPmzbr77rvleZ7a2tpULpfV19c35n09PT1qb2+XJLW3t49bpWv0+9FjDpXJZJTNZse8AABIq6mqpxI1FQBONhMKdBdffLG2bdumrVu31l4XXXSRVq1aVfva931t2rSp9p4dO3aoq6tL+XxekpTP57Vt2zb19vbWjtm4caOy2awWLlw4SacFAMCJi3oKAJgsE3qGrrm5Weeff/6YbY2NjZo5c2Zt+7XXXqu1a9eqtbVV2WxW119/vfL5vJYuXSpJuuSSS7Rw4UJdffXVuvPOO9Xd3a2bb75ZHR0dymQyk3RaAACcuKinAIDJMuFFUX6bu+66S47jaOXKlSqVSlq+fLnuueee2n7XdfXII4/ouuuuUz6fV2Njo1avXq3bb799socCAEBqUU8BAL8LY621Uz2IiSoUCsrlcnq/LpNn/KkeDgBMS5EN9YQeVn9/P89hpRg1FQCm1tHW0yPqQwcAAAAAmHoEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIqQkFus9//vMyxox5LViwoLa/WCyqo6NDM2fOVFNTk1auXKmenp4xP6Orq0srVqxQQ0OD5syZo5tuuklRFE3O2QAAkBLUVADAZPAm+oa3ve1t+tGPfnTgB3gHfsSNN96o733ve3rwwQeVy+W0Zs0aXX755frpT38qSYrjWCtWrFB7e7ueeuop7d69W9dcc41839df//VfT8LpAACQHtRUAMDRmnCg8zxP7e3t47b39/fra1/7mu6//3594AMfkCTdd999Ou+88/T0009r6dKl+uEPf6iXXnpJP/rRj9TW1qa3v/3t+sIXvqBPf/rT+vznP68gCI7+jAAASAlqKgDgaE34GbpXXnlFc+fO1ZlnnqlVq1apq6tLkrRlyxaFYahly5bVjl2wYIHmz5+vzs5OSVJnZ6cuuOACtbW11Y5Zvny5CoWCtm/f/qafWSqVVCgUxrwAAEg7aioA4GhNKNAtWbJEGzZs0GOPPaZ7771Xr732mt73vvdpYGBA3d3dCoJALS0tY97T1tam7u5uSVJ3d/eYwjO6f3Tfm1m/fr1yuVztNW/evIkMGwCAEw41FQAwGSZ0y+Wll15a+3rRokVasmSJTjvtNH3rW99SfX39pA9u1Lp167R27dra94VCgQIEAEg1aioAYDIcVduClpYWnXPOOXr11VfV3t6ucrmsvr6+Mcf09PTUng9ob28ft0LX6PeHe4ZgVCaTUTabHfMCAOBkQk0FAByJowp0g4OD+sUvfqFTTjlFixcvlu/72rRpU23/jh071NXVpXw+L0nK5/Patm2bent7a8ds3LhR2WxWCxcuPJqhAACQatRUAMCRmNAtl3/5l3+pj3zkIzrttNO0a9cu3XrrrXJdV1dddZVyuZyuvfZarV27Vq2trcpms7r++uuVz+e1dOlSSdIll1yihQsX6uqrr9add96p7u5u3Xzzzero6FAmkzkmJwgAwImImgoAmAwTCnSvv/66rrrqKu3du1ezZ8/We9/7Xj399NOaPXu2JOmuu+6S4zhauXKlSqWSli9frnvuuaf2ftd19cgjj+i6665TPp9XY2OjVq9erdtvv31yzwoAgBMcNRUAMBmMtdZO9SAmqlAoKJfL6f26TJ7xp3o4ADAtRTbUE3pY/f39PIeVYtRUAJhaR1tPJ9xY/EQwmkEjhVLq4igAnBwihZIO/JuMdKKmAsDUOtp6mspAt3fvXknST/T9KR4JAGBgYEC5XG6qh4EjRE0FgBPDkdbTVAa61tZWSVJXVxf/I+Igo72Edu7cye1PVczJeMzJeMzJ4f22ebHWamBgQHPnzp2C0WGyUFPH49+E8ZiTw2NexmNOxjvW9TSVgc5xKt0Wcrkcf1EOg75C4zEn4zEn4zEnh/eb5oUAkH7U1DfHvwnjMSeHx7yMx5yMd6zq6VH1oQMAAAAATB0CHQAAAACkVCoDXSaT0a233krj1EMwL+MxJ+MxJ+MxJ4fHvEwP/HcejzkZjzk5POZlPOZkvGM9J6nsQwcAAAAASOkVOgAAAAAAgQ4AAAAAUotABwAAAAApRaADAAAAgJRKZaD7yle+otNPP111dXVasmSJnn322ake0jHz5JNP6iMf+Yjmzp0rY4y+853vjNlvrdUtt9yiU045RfX19Vq2bJleeeWVMcfs27dPq1atUjabVUtLi6699loNDg4ex7OYXOvXr9e73vUuNTc3a86cOfroRz+qHTt2jDmmWCyqo6NDM2fOVFNTk1auXKmenp4xx3R1dWnFihVqaGjQnDlzdNNNNymKouN5KpPm3nvv1aJFi2oNK/P5vB599NHa/uk2H4dzxx13yBijG264obZtOs7L5z//eRljxrwWLFhQ2z8d52Q6m071VKKmHop6enjU1N+OmnqC1VObMg888IANgsD+4z/+o92+fbv92Mc+ZltaWmxPT89UD+2Y+P73v2//6q/+yv7zP/+zlWQfeuihMfvvuOMOm8vl7He+8x37b//2b/aP/uiP7BlnnGFHRkZqx3zwgx+0F154oX366aftv/7rv9qzzjrLXnXVVcf5TCbP8uXL7X333WdffPFFu3XrVvuhD33Izp8/3w4ODtaO+cQnPmHnzZtnN23aZJ9//nm7dOlS+3u/93u1/VEU2fPPP98uW7bMvvDCC/b73/++nTVrll23bt1UnNJR+5d/+Rf7ve99z/7Hf/yH3bFjh/3sZz9rfd+3L774orV2+s3HoZ599ll7+umn20WLFtlPfvKTte3TcV5uvfVW+7a3vc3u3r279tqzZ09t/3Sck+lqutVTa6mph6KeHh419TejplacSPU0dYHu3e9+t+3o6Kh9H8exnTt3rl2/fv0Ujur4OLT4JEli29vb7Re/+MXatr6+PpvJZOw3v/lNa621L730kpVkn3vuudoxjz76qDXG2F//+tfHbezHUm9vr5VkN2/ebK2tzIHv+/bBBx+sHfPv//7vVpLt7Oy01laKuuM4tru7u3bMvffea7PZrC2VSsf3BI6RGTNm2H/4h3+Y9vMxMDBgzz77bLtx40b7B3/wB7XiM13n5dZbb7UXXnjhYfdN1zmZrqZzPbWWmno41NM3R02toKYecCLV01Tdclkul7VlyxYtW7asts1xHC1btkydnZ1TOLKp8dprr6m7u3vMfORyOS1ZsqQ2H52dnWppadFFF11UO2bZsmVyHEfPPPPMcR/zsdDf3y9Jam1tlSRt2bJFYRiOmZcFCxZo/vz5Y+blggsuUFtbW+2Y5cuXq1AoaPv27cdx9JMvjmM98MADGhoaUj6fn/bz0dHRoRUrVow5f2l6/z155ZVXNHfuXJ155platWqVurq6JE3vOZluqKfjUVOpp4dDTR2LmjrWiVJPvUk4l+PmjTfeUBzHY05cktra2vTyyy9P0aimTnd3tyQddj5G93V3d2vOnDlj9nuep9bW1toxaZYkiW644Qa95z3v0fnnny+pcs5BEKilpWXMsYfOy+HmbXRfGm3btk35fF7FYlFNTU166KGHtHDhQm3dunVazockPfDAA/rZz36m5557bty+6fr3ZMmSJdqwYYPOPfdc7d69W7fddpve97736cUXX5y2czIdUU/Hm+41lXo6FjV1PGrqWCdSPU1VoAMO1dHRoRdffFE/+clPpnooU+7cc8/V1q1b1d/fr29/+9tavXq1Nm/ePNXDmjI7d+7UJz/5SW3cuFF1dXVTPZwTxqWXXlr7etGiRVqyZIlOO+00fetb31J9ff0UjgzAVKKejkVNHYuaOt6JVE9TdcvlrFmz5LruuBVienp61N7ePkWjmjqj5/yb5qO9vV29vb1j9kdRpH379qV+ztasWaNHHnlEP/7xj3XqqafWtre3t6tcLquvr2/M8YfOy+HmbXRfGgVBoLPOOkuLFy/W+vXrdeGFF+rLX/7ytJ2PLVu2qLe3V+985zvleZ48z9PmzZt19913y/M8tbW1Tct5OVRLS4vOOeccvfrqq9P278p0RD0dbzrXVOrpeNTUsaipv91U1tNUBbogCLR48WJt2rSpti1JEm3atEn5fH4KRzY1zjjjDLW3t4+Zj0KhoGeeeaY2H/l8Xn19fdqyZUvtmMcff1xJkmjJkiXHfcyTwVqrNWvW6KGHHtLjjz+uM844Y8z+xYsXy/f9MfOyY8cOdXV1jZmXbdu2jSnMGzduVDab1cKFC4/PiRxjSZKoVCpN2/m4+OKLtW3bNm3durX2uuiii7Rq1ara19NxXg41ODioX/ziFzrllFOm7d+V6Yh6Ot50rKnU098dNZWa+ttMaT2d6IouU+2BBx6wmUzGbtiwwb700kv24x//uG1paRmzQszJZGBgwL7wwgv2hRdesJLsl770JfvCCy/YX/3qV9bayhLLLS0t9uGHH7Y///nP7WWXXXbYJZbf8Y532Geeecb+5Cc/sWeffXZql1i21trrrrvO5nI5+8QTT4xZKnZ4eLh2zCc+8Qk7f/58+/jjj9vnn3/e5vN5m8/na/tHl4q95JJL7NatW+1jjz1mZ8+endqlcz/zmc/YzZs329dee83+/Oc/t5/5zGesMcb+8Ic/tNZOv/l4MwevyGXt9JyXT33qU/aJJ56wr732mv3pT39qly1bZmfNmmV7e3uttdNzTqar6VZPraWmHop6enjU1N/NdK+pJ1I9TV2gs9bav/3bv7Xz58+3QRDYd7/73fbpp5+e6iEdMz/+8Y+tpHGv1atXW2sryyx/7nOfs21tbTaTydiLL77Y7tixY8zP2Lt3r73qqqtsU1OTzWaz9s/+7M/swMDAFJzN5DjcfEiy9913X+2YkZER+xd/8Rd2xowZtqGhwf7xH/+x3b1795if88tf/tJeeumltr6+3s6aNct+6lOfsmEYHuezmRx//ud/bk877TQbBIGdPXu2vfjii2uFx9rpNx9v5tDiMx3n5corr7SnnHKKDYLAvuUtb7FXXnmlffXVV2v7p+OcTGfTqZ5aS009FPX08Kipv5vpXlNPpHpqrLV2Ytf0AAAAAAAnglQ9QwcAAAAAOIBABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJSaskD3la98Raeffrrq6uq0ZMkSPfvss1M1FAAAUo2aCgDT15QEuv/1v/6X1q5dq1tvvVU/+9nPdOGFF2r58uXq7e2diuEAAJBa1FQAmN6MtdYe7w9dsmSJ3vWud+l//s//KUlKkkTz5s3T9ddfr8985jPjji+VSiqVSrXvkyTRvn37NHPmTBljjtu4AQAHWGs1MDCguXPnynG4g3+qUFMBIN2Otp56x2BMv1G5XNaWLVu0bt262jbHcbRs2TJ1dnYe9j3r16/XbbfddryGCACYgJ07d+rUU0+d6mFMS9RUADh5HGk9Pe6B7o033lAcx2praxuzva2tTS+//PJh37Nu3TqtXbu29n1/f7/mz5+v9+pD8uQf0/ECAA4vUqif6Ptqbm6e6qFMW9RUAEi/o62nxz3QHYlMJqNMJjNuuydfnqH4AMCUqN6wz2166UJNBYATzFHW0+P+0MOsWbPkuq56enrGbO/p6VF7e/vxHg4AAKlFTQUAHPdAFwSBFi9erE2bNtW2JUmiTZs2KZ/PH+/hAACQWtRUAMCU3HK5du1arV69WhdddJHe/e5363/8j/+hoaEh/dmf/dlUDAcAgNSipgLA9DYlge7KK6/Unj17dMstt6i7u1tvf/vb9dhjj417qBsAAPxm1FQAmN6mpA/d0SoUCsrlcnq/LuMBbgCYIpEN9YQeVn9/v7LZ7FQPB0eImgoAU+to6ymdYAEAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSEw50Tz75pD7ykY9o7ty5MsboO9/5zpj91lrdcsstOuWUU1RfX69ly5bplVdeGXPMvn37tGrVKmWzWbW0tOjaa6/V4ODgUZ0IAABpQj0FAEyGCQe6oaEhXXjhhfrKV75y2P133nmn7r77bn31q1/VM888o8bGRi1fvlzFYrF2zKpVq7R9+3Zt3LhRjzzyiJ588kl9/OMfP/KzAAAgZainAIDJYKy19ojfbIweeughffSjH5VU+W3i3Llz9alPfUp/+Zd/KUnq7+9XW1ubNmzYoD/5kz/Rv//7v2vhwoV67rnndNFFF0mSHnvsMX3oQx/S66+/rrlz5477nFKppFKpVPu+UCho3rx5er8uk2f8Ix0+AOAoRDbUE3pY/f39ymazUz2cVDte9VSipgLAieZo6+mkPkP32muvqbu7W8uWLatty+VyWrJkiTo7OyVJnZ2damlpqRUfSVq2bJkcx9Ezzzxz2J+7fv165XK52mvevHmTOWwAAE4ox6qeStRUADjZTGqg6+7uliS1tbWN2d7W1lbb193drTlz5ozZ73meWltba8ccat26derv76+9du7cOZnDBgDghHKs6qlETQWAk4031QP4XWQyGWUymakeBgAAqUdNBYCTy6ReoWtvb5ck9fT0jNne09NT29fe3q7e3t4x+6Mo0r59+2rHAAAwnVFPAQC/q0kNdGeccYba29u1adOm2rZCoaBnnnlG+XxekpTP59XX16ctW7bUjnn88ceVJImWLFkymcMBACCVqKcAgN/VhG+5HBwc1Kuvvlr7/rXXXtPWrVvV2tqq+fPn64YbbtB//+//XWeffbbOOOMMfe5zn9PcuXNrK3edd955+uAHP6iPfexj+upXv6owDLVmzRr9yZ/8yZuuyAUAwMmGegoAmAwTDnTPP/+8/st/+S+179euXStJWr16tTZs2KD/9t/+m4aGhvTxj39cfX19eu9736vHHntMdXV1tfd84xvf0Jo1a3TxxRfLcRytXLlSd9999yScDgAA6UA9BQBMhqPqQzdVCoWCcrkcPXMAYArRh+7kQE0FgKl1QvWhAwAAAAAcPwQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpb6oHgJQy5tAN47+0B+8/6Bs7ZgcAAACAI0Sgw8QcHOSMIxnJGKNaijM68HUtuFnZ0a8twQ4AAACYLAQ6/O5Gg9toiKsGOjnOgVBXC3S2elGuEuZMYqsBzsoaS7ADAAAAJgGBDr8bYyRjZIxT+dpxZJzKn3Iq24xjDoQ+SbLVMGcTKU6kJKmGu6Syr/qnjCHUAQAAAEeAQIff7uAw5ziSY2RcV3Ld6p9OLdiZ6rG1MJdYKUmkJK6EujiW4lg2SSrX8exBV+sIdQAAAMCEEOjwm1VvrTTGSK5zIMh5nuR5Mp4reZVtchzZ0at0VpJNZGJbCXNRLBvFMlEkG0UycfX7JJG1yUELqRDqAAAAgN8VgQ5vrnZl7qAw53kygV/70/q+5Huyvit5jqzj1B6hk7UyUSITxVIYyZQjKQyl0JHCSJJk4+rhltsvAQAAgIki0OHwDr7NcjTM+Z6M58sEgZQJZDO+bMZXkvFkA1eJ78i6jqyRjJVMYmXCRE4YyynFUimUSq6MY2SNkam2MrDVY+1omCPUAQAAAL8TAh3GG+1AMLr4yeiVOd+XyWRk6zJSfaC4IVBS5yuqdxXXO4p9I+sZWUeSlZzYyilbuSUrbySWO+LJGXErz+A5TiW7VT/MRrZypY6FUgAAAIDfGYEOh2FqV+hqK1p63oErc/WBksaMoiZfUaOnsNFRVG8UZ6TYN9JooIus3JLkFq38ISPfN/JcI3f0U5JEVpVFU8zoCpiOUwl1owh1AAAAwJsi0GEsYw78aRwZtxLm5HtSEMjWBUqaMoqaApVynsrNjsJmKWw0iuutksAeuEIXSm7RyBs2iuuMksDIupWf70pSUl0FM66GOWNk40RGprpQymj7g4PGV+1lN/Z7AAAAYHoi0OGAg67K1frNuZVVLI3vywaekvpAcYOvcrOrcs5RKWdUzlmFzYlsQyJlYhnXStYoLjuKhh1Fg44S31QWTJFkYisTJ3LLldUvlSSV2zujSDKRbHTgVkxJB/JbrcWBrbY70OiKKsd5ogAAAIATA4EOFQevaOk4kuNWrs5V2xTI9yoLoNR5Chtdhc2VMFdqtQpnxHJaympqKqm5rijfTRQnRsPlQANDdQr7M7KeJ8nIJI6csisn9CsLpdik0pDcDWXDg/rYjY7pkD51NkkqV/aq2621kpLafgAAAGA6IdBh3PNyclwZ3ztoZUtP1vNkA09xnauowVG50ShstgpzibzWkma1DugtTf1qqxtQvRuqnLjaHzbo9foWdXtZFVWvcuTJKRt5I47ckisnDOR41efz3Orql5LMaOuDWj87K9lKkKs0Ka+8bJzIWFu9aEdzcgAAAEw/BLrp7qCrYcZxak3Dje9Jvl/pORf4ku/K+q7ijKOozihqMIqaEplsqBktQ3pr7g2d29Sj+cFeNTolla2nnjCnRrckSfp16CoacRQNu4rqjZzIkXV9eSOuXM+R61ZCnJEkL6kEy4P62dlqiDNxXHnmLo5lTCSbJDKJWEgFAAAA0xKBDpVVLEevzHmVK3IKAplMIFuXka3zlWR8xXWVXnNxUF3Rst4q0xiqrXFAb23co4V1v9Zbg31qMrGK1qjbG1Aio6Eoo77hevU1BIrrK7dqRhlH/rAjfzBR4BnJMXJHr8pVx1R7jK66cIpJkkpD8qj6chwpjmWj6EDLg1GEOgDASaJtXkmZequu/6ib6qEAOAER6KYjY8Z8bQ5d0TKo9purD5Q0ZJQ0BIoa3Mqr3pH1JOtJ8hNlglC5oKjZ/oDavYJOcWM1O55KNpY0qG6/Xy3BTDUEZfUHiaJsoiRw5A5L8aBR4juVNgeSZK1cYyrNyV0z5hk6EyUyYVx5lUOZcijrODJhWHmrRB87AMBJ5V3/paCVn9ijXGsk17Nad9Vbtbfbn+phATjBEOimm4NvsawGORlzUHuC0TCXqfaaCxQ2ewqbXIVNRlG9FNUZWddKRnKMlWdiBSZSxsTKGEeBPFlJGRPJN7F8E8tzEzXkRhQ1uiqP+IqHPMV9rhLfSHIkK5mksuhK4jtK3AP97Exi5YRWTjmWU4zlFD2ZkidTdGTNmPUwJVUXxTz4ah0AACnjZxLlP9ivd7xvoLbts/f+Up/647OncFQATkQEuunkoBUkKwuPVJuGu27l9kWvshiKDXzZ+kBxo68w66mcdVXKGoVZo6jBKqpPZH3JGimKHRVjX0NJnQaSjAaSQckpqWgTDSS+BpOMRpJAs+qHNKt+UMXI176RRu2va1DJqVNZnpzQyAkduWVXiWcUB0aJJ8mpXGUzseSWrdySK284lhc4coYdOUaV3nXWylhVVrxMrIyxsrUedlylAwCkzzU3detD/9feMdvmn13S0kv69fQPc1M0KgAnIgLddFELc9XFT5zKLZaVRVCqrQmqt1sq4yuu9xU1VcJccYZRucWo3JIoaY7lNEYKgkiOk8jKaG+pUTuLM5R1hmUlNTlllayn7iirX5dbNcMb1pkz9shTooG4TjuLM/TLTKt2mlaVknqFJVeVtVNcRXVSnDFKAsk6krFGJpLckpU3IvlDjoJBR57nyDNGjjEyia3ccmmrq1/aaqiz9sDCKgAApMSct5S1ZFlhzBMSkpRtjbT0Dwt64V+bVRpxDv9mANMOgW46GBPmqlflvMoCKPK8SmsCv/K1DXwlGU9xvauwwVW5yaicNSrPSJS0hmrIjWhm07Cag6J8J1Y58TQS+frPwdmSpP64QY1uSaXE0xths3wn1gUNO9XmFeSZRP1xvbLeiBxjNVTOqKfoKR5wFNc5SgIpbKwstpJkrGz1lksnNHJHJG/YKA4k67qypnIrpqyVE8UycSwbxZJbbWtgR5/Bk0h0AIA0ef9H9+u0c4qH3Xfpqr363383WztfZYEUABUEupNd7dd7B12Zq/aWO7gtgQ182aDSay7JjPabMwqbjMKsVdISKTdzUPNyfTqjaa9mBwPKmEgjia/uUk6/GmrV9v5T9HowQ3VuqNg6mhkM6aKm13ROsEftbijfGPW5I5KsBuOMdtXnKrdeZgJFjVKcsYqysUxjLLcukusmShKjuOyqPOwpGnCVBI6sK1njysSSia1MOZKJYimOq20N4sriKCyMAgBIGT9I1Don+o3HrP2bnbrxsrOkcU+RA5iOCHTTgalemXMrz8sdWMkykM1kZOsC2XpfScZVXOcp8Y2iOkdRxiiul+LGRJnmkuZmCzo326OFDbs01+tTnQk1ZAN1+TPlOYle6mvXjr1zZGQ1u2lQp9bv1wx3WDOcUK1uIE+OjEqa4Y4o646o3gvl+bGKnlXYUAmNwYyick0jaqkbUcaNFFlHg+WM9g82aChTr5LrS4kjJ5K8kiO37Mkp+rJhJFN2ZV2n2vLAkZHl2hwAIEWsrlzTqz/+2J7feNSpZ5X0zt8f1M+ebJYkOa7VFdf16oUnm/XKzxuOx0ABnEAIdNOAqd5yaZyDVrIMqj3mGjKKGyoLoET1jqJ6p/IMm1/tNRdYqS5WQ31JbfUFzc/s1dlBj071RlRvjAaTYQUm1mBSpz11TeotNGuk5Gtm45AS6yiWo1hGsU1kjFEsKZZRIkeJNbLWyBopaY6VmVHU3NY+zW/ar7l1/WpwyyonrvaFjfplplWvuzPUbxsVlgO5ZSNv2MgdceRmXDlFT/Kqi7uM9rAzEg/RAQBOfFatcyJ98Kp9uvL63t96dHZGpP/2t7/SG7sDSZJxrM48r6iPrN6r/r2evvv1mfrBN2ce60EDOEFM6Ina9evX613vepeam5s1Z84cffSjH9WOHTvGHFMsFtXR0aGZM2eqqalJK1euVE9Pz5hjurq6tGLFCjU0NGjOnDm66aabFEW/+fYCHIHRZ+dMNeRUFz6pNQxvrFPclFGYC1Sc4Wlklqfh2Y6G5zgabjMq54wSXzKeVZ0fqdkrqdUb0iy3pFmOp5lORrNco5nOsGa4Q2ryS/K9SEnsaLgcqC+sV0+UVXdcr91xrO64pO7YVU+U1RthkwbDjMKyJ1kjJxtqVm5A5+T26O3ZnVrS9AvlG19VvulVLW7+pRZmu/WWXJ/qsyXFTUl1tU2jOOPI+q7sQWHOGCNjHHErCoATGTUVoxxXunfTDl3z33YryPxubXdmzI509qJhnb1oWGedPyLHtZrzlrLOXjSs/PKCPnD5PvELTWB6mNAVus2bN6ujo0Pvete7FEWRPvvZz+qSSy7RSy+9pMbGRknSjTfeqO9973t68MEHlcvltGbNGl1++eX66U9/KkmK41grVqxQe3u7nnrqKe3evVvXXHONfN/XX//1X0/+GU5r1WBjTPVWS1fyPSnwZOsCxQ2+wmZf5ZyrUs5RuckobLaVRUnqbKXXnKrXuGylLFgZJVay1dsZR7dZmerjaka27KgwUq9dwzm9FsyWI6v9Xn9tUZTXSrPVNdKqvcONCkc8yVhl6kLNqh/SvLp9Oivo0VuD/Wo2ViVr1OyUNJIE2ltuVG99k0bq6hRnHCW+lPhGiWdkXSM72orh0GXBAOAERE2FJLmu1X/9i141ZeNJK1/5S/r1zvcN6OIr9kuSXny6Sd/5x1lKIqNSkdUxgZONsfbIV43Ys2eP5syZo82bN+v3f//31d/fr9mzZ+v+++/XFVdcIUl6+eWXdd5556mzs1NLly7Vo48+qg9/+MPatWuX2traJElf/epX9elPf1p79uxREAS/9XMLhYJyuZzer8vkGf9Ih3/yc5zKQiiuK+P7MnUZmbo62cZ6Jc11KrdkVJrhqdTiqNhqVM5ZxS2xTGOkoC6U68Wy1iiKXDU1lHT+7F16R/NOvb2+S2/xhlRvrAat0S/DnLaOnKaf9c3TSz2naLi3UcrEam4d1ryW/Tq1sU8t/rA8k2gwymh3MafXB1rUuzereG9GyiTKtQ/ogjm79Hstr+qd9Tt1theqyQlUtpF2xbG2ltrUOXCWtrwxT6/vnimnO6OGXUb1exI17Anl7y/K6R+WGRqRHSnKlsqyUSQbRZKlyThwLEQ21BN6WP39/cpms1M9nNSjpk4/jmt1zU3durKjV4577K6mJbFRHEkv/GuzPnfNmcfscwAcmaOtp0f1a5r+/n5JUmtrqyRpy5YtCsNQy5Ytqx2zYMECzZ8/X52dnZKkzs5OXXDBBbXCI0nLly9XoVDQ9u3bD/s5pVJJhUJhzAu/RbVNQe3Zudotl+6BlSzrXYWNjsrN1TDXGikzc0RzZvfrzDlv6NzZvTpndq/mzdov143VM9KsXxVn6pVym3aUW/VymNWO8ky9WmpT10ir9ow0qVT0ZYqOTL+vgf0N+tW+Vm3be4pe2DdPW/bN17/te4te2TtbvfuaFfcFcoedMXeEmIO+OPQXlVx3A3Ayo6ZOL8ZY/dfreo95mJMqwdHPWL31ghG9430Dx/SzABx/R7woSpIkuuGGG/Se97xH559/viSpu7tbQRCopaVlzLFtbW3q7u6uHXNw4RndP7rvcNavX6/bbrvtSIc6/VQXAzGji4KY6gqXjiPrubKBq7jOVdhgFDaqcptlS6xMa1HzZu7T6U37NK9uv5rcoiLram/UqF8Nz9SuoZxeLrRpJPE105+ljBNqJAnUU2rWrwZa1dOfVVwI5A8auSWjsBxoaMTVcH29nCCWjGQjo6ToyQy5CgpGJjaKm4zKoavBKKN9UaPeiBuVc/araEoqSdoTZ7Q3alYhqlMx9GVDRyaqtixIJCW29rJJUm1VYGlZACA1qKnTz7Ir9uuam7qPeZg72My2UEuWFfTiM40Ky9x6CZwsjjjQdXR06MUXX9RPfvKTyRzPYa1bt05r166tfV8oFDRv3rxj/rmpZCTpoGfJnPELo1jPraxiGRjFdUZRQyKnKVRr85DObN6r8xp3661Br3LuiELrqCfKqd4JVYo97RxoUaGUUXOmLM+JFcau+ot16htsULmvTm6/K3/AyB+0ckpG0UglPFrPVnp9x0Z+SXJHjPwhKQ4kp+ioVAz0xkijuupa1eiWFFujJqeksvXUHeX0y9JMdY9kNTiSkYqO3JLkhJITWjmRrYa7RNbaAw/8AUBKUFOnlz/+2B4tubggzz/+xeqj//ceffurs2srZAJIvyMKdGvWrNEjjzyiJ598Uqeeempte3t7u8rlsvr6+sb8RrGnp0ft7e21Y5599tkxP290xa7RYw6VyWSUyWSOZKjTy0Fhzjim8gydW1390ZjqKpCVBUQSv9qaIJBsxipTH2pmdVGStwY9OjfYr5wjRdYq55QUWle99c3aM9yo7n0t2mOtjGNlE6Oo6EnDnryCo6DPKOi3CgasvBEpGpKSYHThElWClqn8EQeSsZI7bBQO+Hoj06RX3dkqJ5721DWrwSkrtK72hk365VCrft2f00ihTu6gK2/YyCsmcsuJTBhXGosniVQNddYmItUBSANq6vThB4lOOa2sD161V6cvKE7JGPb3+ooiHmIATiYTut5urdWaNWv00EMP6fHHH9cZZ5wxZv/ixYvl+742bdpU27Zjxw51dXUpn89LkvL5vLZt26be3gN9VjZu3KhsNquFCxcezblMb2OemauGOc+rvIJAxvcktxroHCNrKgHLupL1rHwvVoNXVs4dUas7olZHanUyanUDtTqhZrjDanZLqvMi2dgo2lOnaFeDkl318roDZXpc1b1hlNlvlelPlOmPVbc/VlCw8oasTCQlvlTOWRVnJSrOSVRsS1ScZSuhrt9VcV+9du6doe172/XcvtP09P4z9My+M7R171v0n3tnqW9fk0yfX7kCOGTlDVt5I4mcUixF1Vc11NWW4CTUAThBUVOnn1NOL+vvN788ZWGuuyvQbdeerr49LH4DnEwmdIWuo6ND999/vx5++GE1NzfX7s/P5XKqr69XLpfTtddeq7Vr16q1tVXZbFbXX3+98vm8li5dKkm65JJLtHDhQl199dW688471d3drZtvvlkdHR38xvBoHSbMyfdlMoGUCWQzvqzvHVhd5EDfAVkrJdZUmoCr0gA8kVVsk9q2pNqeQFZyykaZfZVn2dxQcotW3oiVP2jlD8cysRTVOYrqK/3syi1WYTaRGmK5dZEct3J1Lym7ioddOUOunD5P5ahee4Z97a9rrB4jRWVPybAnZ8CV3+8o6LfyB6z8oURuMZIpRTLlUDaOpXg00CXVxgoAcGKipk4vy6/aq8v+/I3j/rk2Mdr/hqc4NLr92jP0i+31x30MAI6tCQW6e++9V5L0/ve/f8z2++67T3/6p38qSbrrrrvkOI5WrlypUqmk5cuX65577qkd67quHnnkEV133XXK5/NqbGzU6tWrdfvttx/dmUxn1atzpvqcXKXnnCcFvkwmU2kiXh8oaQgU11dWt0w8I5NITiSZyKhc9jQQ1mlv2KQeP6ucU9KILSm0Rt1xnXqjrPrCeg2VAyWhIy808oakTL+VW7ZyylZeMZE3EkuJVTnnq9zsqJwzKrVaRa2R/JaSsk0jytWPKOPGihJHg+WM+obqNdJfJ7Pfl7/XVVJwFQWB5EpKKuMLRiRvqPJsXlCwyhRi+YOhnOFQplSWwlCKItk4PrAwCouiADiBUVOnl52v1GnWKeFx/9zN383p/11zmmxCWQROVkfVh26q0DPnENVFTyqtCZxKz7kgkKkLZOvqZBszShoyCpt9RY2VVgVRnVFcJ4WNlcCVnFLSrFkFnTezWwuaunVGZo9yzogi66onyurVYpu29c3VL/fN1PDuRgW9rhp6pLq9iYLBWLKV5+FMbGUdo2Krp+JMo5HZUnlWrGB2Ue0z+jWvuU/tdf2qd0KF1tW+coO6hlr1676cBvc2yuv15ReMjJWso8rVwEhyS5Vn8vwhK38glj8YyRsoyxkuyQwXZYslqVSWLZerV+qqwU4skAIcK/ShOzlQU4+90xeM6LYNr6l9fvm4faZNpH/9Xovu/sypGth/xGvgATgOjrae8v/hJwlTXdGydnXO9yq3WdZnFDdmFDX7KrV4CpsclbNGYYMU11slvpX1rJJBT/v8Jr3qzVYx9tVbn1WjW1ZkHe0PG/T6UIte72vRcF+d3IHKoiRusfL8W9hUueJnzYFQF9UZRfVGUVMiJxdqVsuAzmnp1YLGbp0evKEmp6hSdQXLJq8kSfpl5Kk04sodcVX/hpVbkkwimcjKDW31ts5Y3nAsZySUM1SSKZYqYS4MK43E4wMLo0gizAEAplx2Rnxcw5wkbf6XFt35/5ymmAVQgJMegS7tRtsTjL5cV3JdGd+XDXzZel9xo69ys6dy1lEpV2kiHjVb2YZYJhPLOFZOYhSVXPXuy2q4HKi3vlkZN1JijYbKgfqH6zXUXy/T79faEpjEqpx1FGekxJOsY2QSKxNXnrOLAymps6qrDzWrfkjz6/fp7EyPzvT3qdlJVLJGObeoYuJrX9ioN+obVarLKMk4ShwpM1K5GufEttKeoBzLKcVyiqFMMayEuVJYCXNhJMVx5dm5WusC0hwAYGoZx+qPjuOzc0ls9NNHc7p73amEOWCaINCl2ZgwJxnHkXEdyXNlfU824yuu9xQ2uio3Oyq1GJVmWEWtsbxcSU1NRTXVleQ7saLE1WAp0OBQnfr2NargNMhxE1lbWbjEjrhyB1z5hUpbAieSyjmjsNEorrNKAsk6tnpFTXKLRolvJS9R4EfK+kXN8gY1xxvQKa5Vk5NRycZKNKw53oBa/BHVB6GMn1TCoWdkTfW5vMFQphzJRIlMGMmMhrjyQWHu4OfnkmSq/8sAACBJOvXMkhb//sAx+/l9b3j69WsZNedieYHV5/6vM7Rnd6DSCI3DgemCQJdWZrRFgSNptMfcgUVRrO/JBp7iOldRg6OwSQqbraJcrKC1qNktA5rXvF+zMoOqc0KVEl/7yo3qyrSotz+r4t56JUVHTiQ5kZFbrC5KMlQJc2FTdeXKpkS2IZGqV/qsNVLZUTTkyimZ0U4KcoyVYxI5snKMkSMjV0aOVNtuZA+swHnwqUZx5fbKanBTGMmO/hnHtTCn5KAnvrk6BwCYYmecN6J19/5KDc3xMfn5xWFHf7N2vp79UVbt80tqaEr0+n/WHZPPAnDiItClUW0RlGqLAsep3GbpupLjVvrNea4S31EcOOOeZ5vdMqCzq8+znRrsU4NT1kgSaHfYonq3LGOkX5ddJSN18vsdeSOSW5K8ESslUrl6pS9sjeXkQjU1FtVYV5LnJooTR8OlQIODdYoLgWxiFIauhqJAfVGD9sf12usUVHZKKlmrfUlG++NGDUQZlSJfNnJk4spzeCbRaD+FSo+5YqlyVS6Oq0Fu9IpcfOC5OW61BACcAGadUtaFvzeo0845Nj3nBvpcffH/ma9nf9QsSeruok0FMF0R6NLm0DDnepJXXQjF86oNxF1Z15H1HCW+URxIcZ2U1CdqaCirvbGgtzbs0dvqfq35fr8aTawR66jVHVJoXQ1GGe1raNBAg68wlJLAyBsevXRmVM5ahS2J/NaSZs0Y0Fua+zS7dqXP0/5yo3bWt2iP36xiX51KRV97RprUVTdTTW5JkRw1OSWVq4ui/LI4S90jWQ2MZKSiI7ckOaHkRFZOZKvhLqmEuDCUjWIpiSsLoFgraw9qU0CYAwCcAG78m5266P2Te6vl3m5fvb8O9MuX6/TUYzk9u4nVZQEQ6NKldpulqd1aKb8S4kwQSL4nG/hS4Mt6rqxjZF0j60nWs5KfKBOEyvkjmu0PqN0b1Fw3UaMTaDiJFGlQc/yCWvwRNWRCFbNlJfWuwqKraNBVHBi5ZSlqtDLZUK0tg3pr7g2d09RTu9JXTHx1hznVuaGMpF2hq2jE0xuFJv3Cm6XYGu2ra1SDU1bZutobNuk/B2dp10BOxYGMnCFH7oiRV7JyS4lMmMiM3k6ZWFlrq7dXxrXvZavPzBHmAABTbO4ZJd305S7NP3tyrsxZKxX2eXr4vln66fdzGh5w1bfXU7nIM3IAKgh0aXHwM3PVK3PG9yTfl8kEUl0gmwmU1PlK6jwlGU9xxpF1JGsqL1WfZfOcRL6J5ZtYgXHky1VgEgWqbPecWDMbhjSjflgjka/+kToNFupV9jPyCo6ShkR1jWWd0lTQWY29uqD+dZ3u769d6fu1V5CV0Ujsq2+4XoUhX0P76vUra1Qo1Wln3Qxl3EiRdTVQzmjvYKMG++ul/YGCgiN/0MobTuQWEznlSAorfeVGb60cvQ2zdmWOXnMAgCnWlIv0nkv7terGHrXNm7wWBc89ntUX/u/TVS6PFnMAGItAlyYHhzqvenWuGuaShjol9YHiRk9xvauo3lUUGCVBtTdcIik2imJXI7GvwbhOA0mgQjKi2ClpOElUsBkNxnVqcEO9vWWnHCMVojrtGsnpda9Fe6xRlASSb1UXhGoJRjTHL+gUr6C5bqxG42nERko0qN1+QS1BZeXKAS+R2e+rGDWoZ9jXvvpGuU6ixBpFZU/RkCcz4CnoN/ILUjBo5Q8lckdimVIkE0aV2yyrPeZkE1lxiyUA4MQxe26otV/aOWk/r+8NT//jpnl6+WcNKpe4GgfgzRHo0mA0yFWfn1O1ebgJDgpzTRlFTb7Kza7CRqfaTqDy/Jx1VbmCVXI0PBJoz0izujKtyrrDKtt9anBCjSS+dkU5DSeBFtTv0hyvIEdW++ImvRbMVuDEKseu9keOFBs5jq1e4YuUMbHqjKOM8WRlVWcSZUykwERynKSyymXZyB1wFde7KmdspcWBlUxo5I+YygqaA1aZQqKgkMgfjOSOhJUWBeVwbFsCghwA4ARy2rkjumDp0KT8rH/7aZOKw442/L+n6D9fqtNhl38GgIMQ6NJiNNS51WfnvMrtljYTKKkPFDb5Kmc9lXOOys1GYZMUNVglGSvrqRLoEqNwKFDPYLPqvNkykvYFTap3yiraylW7ecE+nRP0qN0tyjHS3nhIjhIVojr1NDRroK5e0UCgKHZUTDwNJxkNJr4GkhFZp6xhG2sw8TWUZDSS+IpiVzY2ciIp6DeyA5VFVqxTGZMTqdISYcTKH7IKBhP5A5HcoVDOSFmmVJYNw8oql3F8yOInhDoAwFSzWnH1Xl12hM3Dra00A//7L8zVyJCjJ7/bouEBd5LHCOBkRqBLBSOj6tU5x6mtZmkDv3qbpa+wuRLmiq1G5ZxVlEtkmyJ5dZFcP5GsFIWu4pKrvr4GRbGjgXJGv8zMVOBGMpJOb3hDc7yC2r2i2l1fjox8ldXvFTTTH1STX5LvRwptoJFioD3FJu3MtKrFG1asvWo0oYo20K6oRV2lVvUWmzU0EkglR04oecNW3oitLNTiVG8Fja3csuQWE3kjibzhSO5wWOk7VyzLlsq1vnOjTcNtrdfclP5HAQBAb3v3kD541b433W+t9MrPG5TE0lvfVpSfSWr7ktjouxtm6v4vt6l/r1fp5QoAE0SgS4Pqgiajq1tW+sx5UlBZ/CSqdyuNvpsrYS5sjeXNKCmbHdGM+mE1+KGslQbDTGWRkkKDCn0NGhkJ1F0XynNjzc0WdEaDlatEriRXjoyMXGMqzcBl5Zhq4+/YKBz01dPQrIbRK32ZRtU7ZZUSXz1hVq8MztHugZyKQxk5w5WVK92SVaY/kUls5YqjrfSac8JETimRW4rkFCOZYihTLFXCXDmsXKE7uHE4t1wCAE4AjmO1/E/2KVOfvOkxmx+eob+5cZ7KJaMV1+xVUzZWfVOid7x3QE9+t0Xf+YfZimOCHIAjR6BLg+rtlpX+c5Vn6KznygaukoyrqN5R2GAUNkthLpE7o6y2mf06Pbtfb6nfr6w7Iiuj/WGjXq9v0S+9mXpjX7OifXWKTEZONtRIw4gG4zrtjxu1Lx5SYMpyJO2NjfYnDSrE9RqOfMWRK6fkSEVH/X6j/tMaDYWBdmYqK1eWE1f9pXp1D2bV198g9fnyB4z8ISt/JJE3HMsbiirBsBroTBTLRIlMOZJKoUwYVhqIj4a56vNzShLZhCAHAJhaxrFqn1fW/9HRqz/8r/sPe0ySGD3+v2foKze/pbaoyff+v1mSJNe1evgfZ2l/r3/cxgzg5EWgSwtjpNH+c45TbRzuKg4cxXVGUb1R1GBlmiO1ZId0Zm6f3tb0a52Z2aOZ7qASGfVGWc3w5yixjkqRq/5hT06/p8RP1DdSr1+PtOg//dkyxqovKcgx0r64Qb8ozdHO4gztH25QOOLJKRq5JaNQGfWFroaGM9pVF8p1EsWJo1LZU3kokAqegv1OZfXKwURedeVKd7AkE8WV80qslCSV76O4Et7CSIqqDcQPDnO1FgWEOgDA1Ln48v361F075bhvXo+e+E6L/mbtPCWHufoWx4YwB2DSEOjSxqga7kZDnVHiSUkgxRkrry7SjIYRvaVuv87M7NE5wR7NcmIlklqcoqyM9tQ3aU99kwbqG6R+V2bI1UChXq/7LQqcSANxnVr9ITmy6o/q9Xpxhn5VaFXfQIPsoCdv2MgflJzQUVTyFTW4GgjqJKfaD67syB125A0ZBQUpKFgFA4n8oVhuMZQpliurV9qkFuhsklRuq4yTSoCLosr2g8Mct1oCAKZYkEn0wf9zXy3MRaFREhsFdYlKI45KI46ee7xZ93zuLYcNcwAw2Qh0KWBqD9GNLoxSuVpnHVVerlHiStaz8vxIDV5ZLd6wZrmDmu3GmuVklEhKVNJed0A5b0QNflmulyhyJW/QUehl1GuzKkWeuuuzag5KMrIajgLtG2lQX6FB4b46ef2u/EEp02flD0vhkFFc5yrxVW1FYOSEB61cOVhdubIQyRssyxmuhDlbLElxdCCkJbYa6hIpiWXjyvNytebhhDkAwAngg//nXp2/ZFBS5bbKb9zVpp6dgd7xvkF1/jCrzh/kVCldhDkAxweB7qRzSAGxo4tBWlVuWBxfYNxhI1lHUZzRvtDVQH2dfD+WTGVlzLDoVa7M9bkK+o2CgcoVNxnJqzOKM5WrhNaRTGJlIsktW3nFSoNwbziutCEYLssUy1K5XLmlshxWg5oOhLeDFj6xtnL1rjJ8whwAYOrZxGiw39Xdn56nKDR65kdZxZHRpv/dOtVDAzBNEehSwMrKjD47VrtNsbqgSFJZ+t+JjJzIKAxdDYWB9keN2hM3a4ZbVKySEkm9caA9cbP6ogYNhYHi0JETGrklyR8yCouuoiFHUcZX6FcClImNnKKp3WYZDFRWqgwKkZzIKg4cJb5R4pnaypVOfNDKlcXKypXOSGXlSpXKsuVy9Tm5WDapPktXuwqn8c/KEeYAACeI739jpjY+OEPFYUc0/QZwIiDQpU3tFsVEJk7kRFZOqMqrZBQVPe0fadDrIy3KecOy0phFUV4rzdaukZz6R+qVFD355crVtGBAcktSNGyUBJUrbpJkYlX7xFUaf/tDVkEhkjcYySlFcj1H1ndkHSPrGJlEUmLlRLFMmMiUIplyKFMOq2EurIa5gxY70UHBzUoSQQ4AcGKKI6M4ovE3gBMHgS4tqs+ZHfysmQljOeVEbqnSsNsbMooLnvqDBr3mzVRsHe2tb1LWLcpK2h816tfDLfpVf6sG+uvlDLjyhoy8EaugkMgfkOI6U7niVq1VlT5xVm6p0nbAHYnlDYVyhiuLm8gxlTYKzoErdMZaKaoscmJGw1u5+mcUVRqF1xY7OegZOQAAAAATQqBLA3vgdkubJDJxXFnmP4zllCJ5I678ocqzbHGdo9DNqMfkNBL66qlvrjQWlzRUDtQ3Uq+BvgYlfYGCgpE/aOUNW/lDsZwwUexXVs60bvU2ksRWrwImcouVz3NGQqlYlimVK8c4TqXpeTXQKaneGlpbsTKW4rgS5uKEMAcAAABMEgJdGow+UpZYmdHl/aNIKodyip68YVd+XeU5tsQ7sMDJ/mFPhfoGuV4sySgqu0qKrsyAp6BglOk31XYCidyRSO5wKNcxklu5hVJS5Vm92Faaf5djmTCstBwII9lyuRLeRsOcMbUFTiqLm1RDXXXMoytXEuYAAACAyUGgSwVbWRhldBXIKJYNK8+mOUVPrucq8EYfzq4sdBIWXUUNjpKMp9CTZCUTSX7JyBuqXJkLBpLKAicDlTDnDJUqP99xKuFMOnDFLU5koupCJmF44PbJJNFoSwVjzNh+caPhLTloQRdrK9/TIBwAAAA4agS6tBhdyj9OJCeuhKvQlSmW5TiOvNErataVEzrySkbR0IHn4YwqC5w45crzdv6wlT+YyB+I5A4e3FIgrF5xcw58bpKMbf4dxZXbJuO4Gs6qzMEZ7UB/OcmObwxOmAMAAACOGoEuDarhx9oDt1zaKJJKpnpNTpKsvCSRiXx5RVfRsFNtKSBZV5UrdLHkRJX+cG4xkTccyR2O5AyXZEZKUrFUufpmNfYKXe35vWq4i+NKuKv1jFMlzMnooMZ31bcf0keOIAcAAABMGgJdmlT7s9mkcvujNarc6qhKqKs09U7kljy5I66SoLrAiVN5tq2y38otJ3JKsZxi5Xk4UyxXwlw5rAS6JKlcpZMZ29h7dIXNWuPvgwKd3iSoEeAAAACAY4ZAlxajV+mUyMS1i2LVLFVpFWCiWE45kgJPju/Jeo6s64xewjuwwEkYy4SxVA5lwlC2HEphtT9cGFVC24EPPvDHaJDTIbdPHnJVDgAAAMDxQaBLk1qoq9x6WQt1o2ErrrQ0UOjKeF41zJkDt08mBxqSK4rH9oWLoupKlPGBq3LVzzrom9pVwoPHAwAAAGBqEOjSxlpJiWziyNhqqLP2oAVLIsl1JNeVGV2t0hkb6GrPv8Wx7GiPuDg5sPgJLQUAAACAVCDQpdFoqJORSVRdrMTKxImsG1cbfTuyo73hHDPmlsnaAiejDb6TpNoM3BLmAAAAgBQh0KXV6O2X1T5wRtUwlpixYU6q9JWTxixwUukNd9ACJ6O94ugPBwAAAKQGgS7NDlqUxCamtuKlTZJqmKsGOlM77KD3jV6Rk8aEOMIcAAAAkBoEurQ7OIDZ6hImB4c5aXygG/3mkPcCAAAASBcC3cmCcAYAAABMO85vPwQAAAAAcCIi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUmpCge7ee+/VokWLlM1mlc1mlc/n9eijj9b2F4tFdXR0aObMmWpqatLKlSvV09Mz5md0dXVpxYoVamho0Jw5c3TTTTcpiqLJORsAAFKCmgoAmAwTCnSnnnqq7rjjDm3ZskXPP/+8PvCBD+iyyy7T9u3bJUk33nijvvvd7+rBBx/U5s2btWvXLl1++eW198dxrBUrVqhcLuupp57S17/+dW3YsEG33HLL5J4VAAAnOGoqAGAyGGutPZof0Nraqi9+8Yu64oorNHv2bN1///264oorJEkvv/yyzjvvPHV2dmrp0qV69NFH9eEPf1i7du1SW1ubJOmrX/2qPv3pT2vPnj0KguB3+sxCoaBcLqf36zJ5xj+a4QMAjlBkQz2hh9Xf369sNjvVwzkpUFMBYPo52np6xM/QxXGsBx54QENDQ8rn89qyZYvCMNSyZctqxyxYsEDz589XZ2enJKmzs1MXXHBBrfBI0vLly1UoFGq/kTycUqmkQqEw5gUAwMmCmgoAOFITDnTbtm1TU1OTMpmMPvGJT+ihhx7SwoUL1d3drSAI1NLSMub4trY2dXd3S5K6u7vHFJ7R/aP73sz69euVy+Vqr3nz5k102AAAnHCoqQCAozXhQHfuuedq69ateuaZZ3Tddddp9erVeumll47F2GrWrVun/v7+2mvnzp3H9PMAADgeqKkAgKPlTfQNQRDorLPOkiQtXrxYzz33nL785S/ryiuvVLlcVl9f35jfKPb09Ki9vV2S1N7ermeffXbMzxtdsWv0mMPJZDLKZDITHSoAACc0aioA4GgddR+6JElUKpW0ePFi+b6vTZs21fbt2LFDXV1dyufzkqR8Pq9t27apt7e3dszGjRuVzWa1cOHCox0KAACpRk0FAEzUhK7QrVu3Tpdeeqnmz5+vgYEB3X///XriiSf0gx/8QLlcTtdee63Wrl2r1tZWZbNZXX/99crn81q6dKkk6ZJLLtHChQt19dVX684771R3d7duvvlmdXR08NtCAMC0Qk0FAEyGCQW63t5eXXPNNdq9e7dyuZwWLVqkH/zgB/rDP/xDSdJdd90lx3G0cuVKlUolLV++XPfcc0/t/a7r6pFHHtF1112nfD6vxsZGrV69WrfffvvknhUAACc4aioAYDIcdR+6qUDPHACYevShOzlQUwFgak1ZHzoAAAAAwNQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABAShHoAAAAACClCHQAAAAAkFIEOgAAAABIKQIdAAAAAKQUgQ4AAAAAUopABwAAAAApRaADAAAAgJQi0AEAAABASh1VoLvjjjtkjNENN9xQ21YsFtXR0aGZM2eqqalJK1euVE9Pz5j3dXV1acWKFWpoaNCcOXN00003KYqioxkKAACpRT0FABypIw50zz33nP7u7/5OixYtGrP9xhtv1He/+109+OCD2rx5s3bt2qXLL7+8tj+OY61YsULlcllPPfWUvv71r2vDhg265ZZbjvwsAABIKeopAOBoHFGgGxwc1KpVq/T3f//3mjFjRm17f3+/vva1r+lLX/qSPvCBD2jx4sW677779NRTT+npp5+WJP3whz/USy+9pH/6p3/S29/+dl166aX6whe+oK985Ssql8uTc1YAAKQA9RQAcLSOKNB1dHRoxYoVWrZs2ZjtW7ZsURiGY7YvWLBA8+fPV2dnpySps7NTF1xwgdra2mrHLF++XIVCQdu3bz/s55VKJRUKhTEvAADS7njXU4maCgAnG2+ib3jggQf0s5/9TM8999y4fd3d3QqCQC0tLWO2t7W1qbu7u3bMwcVndP/ovsNZv369brvttokOFQCAE9ZU1FOJmgoAJ5sJXaHbuXOnPvnJT+ob3/iG6urqjtWYxlm3bp36+/trr507dx63zwYAYLJNVT2VqKkAcLKZUKDbsmWLent79c53vlOe58nzPG3evFl33323PM9TW1ubyuWy+vr6xryvp6dH7e3tkqT29vZxq3SNfj96zKEymYyy2eyYFwAAaTVV9VSipgLAyWZCge7iiy/Wtm3btHXr1trroosu0qpVq2pf+76vTZs21d6zY8cOdXV1KZ/PS5Ly+by2bdum3t7e2jEbN25UNpvVwoULJ+m0AAA4cVFPAQCTZULP0DU3N+v8888fs62xsVEzZ86sbb/22mu1du1atba2KpvN6vrrr1c+n9fSpUslSZdccokWLlyoq6++Wnfeeae6u7t18803q6OjQ5lMZpJOCwCAExf1FAAwWSa8KMpvc9ddd8lxHK1cuVKlUknLly/XPffcU9vvuq4eeeQRXXfddcrn82psbNTq1at1++23T/ZQAABILeopAOB3Yay1dqoHMVGFQkG5XE7v12XyjD/VwwGAaSmyoZ7Qw+rv7+c5rBSjpgLA1DraenpEfegAAAAAAFOPQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUItABAAAAQEoR6AAAAAAgpQh0AAAAAJBSBDoAAAAASCkCHQAAAACkFIEOAAAAAFKKQAcAAAAAKUWgAwAAAICUmlCg+/znPy9jzJjXggULavuLxaI6Ojo0c+ZMNTU1aeXKlerp6RnzM7q6urRixQo1NDRozpw5uummmxRF0eScDQAAKUFNBQBMBm+ib3jb296mH/3oRwd+gHfgR9x444363ve+pwcffFC5XE5r1qzR5Zdfrp/+9KeSpDiOtWLFCrW3t+upp57S7t27dc0118j3ff31X//1JJwOAADpQU0FABytCQc6z/PU3t4+bnt/f7++9rWv6f7779cHPvABSdJ9992n8847T08//bSWLl2qH/7wh3rppZf0ox/9SG1tbXr729+uL3zhC/r0pz+tz3/+8wqC4LCfWSqVVCqVat8XCoWJDhsAgBMONRUAcLQm/AzdK6+8orlz5+rMM8/UqlWr1NXVJUnasmWLwjDUsmXLascuWLBA8+fPV2dnpySps7NTF1xwgdra2mrHLF++XIVCQdu3b3/Tz1y/fr1yuVztNW/evIkOGwCAEw41FQBwtCYU6JYsWaINGzboscce07333qvXXntN73vf+zQwMKDu7m4FQaCWlpYx72lra1N3d7ckqbu7e0zhGd0/uu/NrFu3Tv39/bXXzp07JzJsAABOONRUAMBkmNAtl5deemnt60WLFmnJkiU67bTT9K1vfUv19fWTPrhRmUxGmUzmmP18AACON2oqAGAyHFXbgpaWFp1zzjl69dVX1d7ernK5rL6+vjHH9PT01J4PaG9vH7dC1+j3h3uGAACA6YKaCgA4EkcV6AYHB/WLX/xCp5xyihYvXizf97Vp06ba/h07dqirq0v5fF6SlM/ntW3bNvX29taO2bhxo7LZrBYuXHg0QwEAINWoqQCAIzGhWy7/8i//Uh/5yEd02mmnadeuXbr11lvluq6uuuoq5XI5XXvttVq7dq1aW1uVzWZ1/fXXK5/Pa+nSpZKkSy65RAsXLtTVV1+tO++8U93d3br55pvV0dHB7R8AgGmFmgoAmAwTCnSvv/66rrrqKu3du1ezZ8/We9/7Xj399NOaPXu2JOmuu+6S4zhauXKlSqWSli9frnvuuaf2ftd19cgjj+i6665TPp9XY2OjVq9erdtvv31yzwoAgBMcNRUAMBmMtdZO9SAmqr+/Xy0tLXqvPiRP/lQPBwCmpUihfqLvq6+vT7lcbqqHgyNETQWAqXW09XTCjcVPBHv37pUk/UTfn+KRAAAGBgYIdClGTQWAE8OR1tNUBrrW1lZJUldXF/8j4iCFQkHz5s3Tzp07lc1mp3o4JwTmZDzmZDzm5PB+27xYazUwMKC5c+dOwegwWaip4/FvwnjMyeExL+MxJ+Md63qaykDnOJXFOXO5HH9RDiObzTIvh2BOxmNOxmNODu83zQsBIP2oqW+OfxPGY04Oj3kZjzkZ71jV06NqWwAAAAAAmDoEOgAAAABIqVQGukwmo1tvvZU+O4dgXsZjTsZjTsZjTg6PeZke+O88HnMyHnNyeMzLeMzJeMd6TlLZtgAAAAAAkNIrdAAAAAAAAh0AAAAApBaBDgAAAABSikAHAAAAAClFoAMAAACAlEploPvKV76i008/XXV1dVqyZImeffbZqR7SMfPkk0/qIx/5iObOnStjjL7zne+M2W+t1S233KJTTjlF9fX1WrZsmV555ZUxx+zbt0+rVq1SNptVS0uLrr32Wg0ODh7Hs5hc69ev17ve9S41Nzdrzpw5+uhHP6odO3aMOaZYLKqjo0MzZ85UU1OTVq5cqZ6enjHHdHV1acWKFWpoaNCcOXN00003KYqi43kqk+bee+/VokWLlM1mlc1mlc/n9eijj9b2T7f5OJw77rhDxhjdcMMNtW3TcV4+//nPyxgz5rVgwYLa/uk4J9PZdKqnEjX1UNTTw6Om/nbU1BOsntqUeeCBB2wQBPYf//Ef7fbt2+3HPvYx29LSYnt6eqZ6aMfE97//fftXf/VX9p//+Z+tJPvQQw+N2X/HHXfYXC5nv/Od79h/+7d/s3/0R39kzzjjDDsyMlI75oMf/KC98MIL7dNPP23/9V//1Z511ln2qquuOs5nMnmWL19u77vvPvviiy/arVu32g996EN2/vz5dnBwsHbMJz7xCTtv3jy7adMm+/zzz9ulS5fa3/u936vtj6LInn/++XbZsmX2hRdesN///vftrFmz7Lp166bilI7av/zLv9jvfe979j/+4z/sjh077Gc/+1nr+7598cUXrbXTbz4O9eyzz9rTTz/dLlq0yH7yk5+sbZ+O83Lrrbfat73tbXb37t211549e2r7p+OcTFfTrZ5aS009FPX08Kipvxk1teJEqqepC3Tvfve7bUdHR+37OI7t3Llz7fr166dwVMfHocUnSRLb3t5uv/jFL9a29fX12UwmY7/5zW9aa6196aWXrCT73HPP1Y559NFHrTHG/vrXvz5uYz+Went7rSS7efNma21lDnzftw8++GDtmH//93+3kmxnZ6e1tlLUHcex3d3dtWPuvfdem81mbalUOr4ncIzMmDHD/sM//MO0n4+BgQF79tln240bN9o/+IM/qBWf6Tovt956q73wwgsPu2+6zsl0NZ3rqbXU1MOhnr45amoFNfWAE6mepuqWy3K5rC1btmjZsmW1bY7jaNmyZers7JzCkU2N1157Td3d3WPmI5fLacmSJbX56OzsVEtLiy666KLaMcuWLZPjOHrmmWeO+5iPhf7+fklSa2urJGnLli0Kw3DMvCxYsEDz588fMy8XXHCB2traascsX75chUJB27dvP46jn3xxHOuBBx7Q0NCQ8vn8tJ+Pjo4OrVixYsz5S9P778krr7yiuXPn6swzz9SqVavU1dUlaXrPyXRDPR2Pmko9PRxq6ljU1LFOlHrqTcK5HDdvvPGG4jgec+KS1NbWppdffnmKRjV1uru7Jemw8zG6r7u7W3PmzBmz3/M8tba21o5JsyRJdMMNN+g973mPzj//fEmVcw6CQC0tLWOOPXReDjdvo/vSaNu2bcrn8yoWi2pqatJDDz2khQsXauvWrdNyPiTpgQce0M9+9jM999xz4/ZN178nS5Ys0YYNG3Tuuedq9+7duu222/S+971PL7744rSdk+mIejredK+p1NOxqKnjUVPHOpHqaaoCHXCojo4Ovfjii/rJT34y1UOZcueee662bt2q/v5+ffvb39bq1au1efPmqR7WlNm5c6c++clPauPGjaqrq5vq4ZwwLr300trXixYt0pIlS3TaaafpW9/6lurr66dwZACmEvV0LGrqWNTU8U6kepqqWy5nzZol13XHrRDT09Oj9vb2KRrV1Bk95980H+3t7ert7R2zP4oi7du3L/VztmbNGj3yyCP68Y9/rFNPPbW2vb29XeVyWX19fWOOP3ReDjdvo/vSKAgCnXXWWVq8eLHWr1+vCy+8UF/+8pen7Xxs2bJFvb29euc73ynP8+R5njZv3qy7775bnuepra1tWs7LoVpaWnTOOefo1VdfnbZ/V6Yj6ul407mmUk/Ho6aORU397aaynqYq0AVBoMWLF2vTpk21bUmSaNOmTcrn81M4sqlxxhlnqL29fcx8FAoFPfPMM7X5yOfz6uvr05YtW2rHPP7440qSREuWLDnuY54M1lqtWbNGDz30kB5//HGdccYZY/YvXrxYvu+PmZcdO3aoq6trzLxs27ZtTGHeuHGjstmsFi5ceHxO5BhLkkSlUmnazsfFF1+sbdu2aevWrbXXRRddpFWrVtW+no7zcqjBwUH94he/0CmnnDJt/65MR9TT8aZjTaWe/u6oqdTU32ZK6+lEV3SZag888IDNZDJ2w4YN9qWXXrIf//jHbUtLy5gVYk4mAwMD9oUXXrAvvPCClWS/9KUv2RdeeMH+6le/stZWllhuaWmxDz/8sP35z39uL7vsssMusfyOd7zDPvPMM/YnP/mJPfvss1O7xLK11l533XU2l8vZJ554YsxSscPDw7VjPvGJT9j58+fbxx9/3D7//PM2n8/bfD5f2z+6VOwll1xit27dah977DE7e/bs1C6d+5nPfMZu3rzZvvbaa/bnP/+5/cxnPmONMfaHP/yhtXb6zcebOXhFLmun57x86lOfsk888YR97bXX7E9/+lO7bNkyO2vWLNvb22utnZ5zMl1Nt3pqLTX1UNTTw6Om/m6me009kepp6gKdtdb+7d/+rZ0/f74NgsC++93vtk8//fRUD+mY+fGPf2wljXutXr3aWltZZvlzn/ucbWtrs5lMxl588cV2x44dY37G3r177VVXXWWbmppsNpu1f/Znf2YHBgam4Gwmx+HmQ5K97777aseMjIzYv/iLv7AzZsywDQ0N9o//+I/t7t27x/ycX/7yl/bSSy+19fX1dtasWfZTn/qUDcPwOJ/N5PjzP/9ze9ppp9kgCOzs2bPtxRdfXCs81k6/+Xgzhxaf6TgvV155pT3llFNsEAT2LW95i73yyivtq6++Wts/HedkOptO9dRaauqhqKeHR0393Uz3mnoi1VNjrbUTu6YHAAAAADgRpOoZOgAAAADAAQQ6AAAAAEgpAh0AAAAApBSBDgAAAABSikAHAAAAAClFoAMAAACAlCLQAQAAAEBKEegAAAAAIKUIdAAAAACQUgQ6AAAAAEgpAh0AAAAApNT/D1Hr6rB+tD/AAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QPWAK3BK9UPJ"
      },
      "source": [
        "## NonBlockND"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJdpZrHW9UPJ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "class _NonLocalBlockND(nn.Module):\n",
        "    def __init__(self, in_channels, inter_channels=None, dimension=3, sub_sample=True, bn_layer=True):\n",
        "        \"\"\"\n",
        "        :param in_channels:\n",
        "        :param inter_channels:\n",
        "        :param dimension:\n",
        "        :param sub_sample:\n",
        "        :param bn_layer:\n",
        "        \"\"\"\n",
        "\n",
        "        super(_NonLocalBlockND, self).__init__()\n",
        "\n",
        "        assert dimension in [1, 2, 3]\n",
        "\n",
        "        self.dimension = dimension\n",
        "        self.sub_sample = sub_sample\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.inter_channels = inter_channels\n",
        "\n",
        "        if self.inter_channels is None:\n",
        "            self.inter_channels = in_channels // 2\n",
        "            if self.inter_channels == 0:\n",
        "                self.inter_channels = 1\n",
        "\n",
        "        if dimension == 3:\n",
        "            conv_nd = nn.Conv3d\n",
        "            max_pool_layer = nn.MaxPool3d(kernel_size=(1, 2, 2))\n",
        "            bn = nn.BatchNorm3d\n",
        "        elif dimension == 2:\n",
        "            conv_nd = nn.Conv2d\n",
        "            max_pool_layer = nn.MaxPool2d(kernel_size=(2, 2))\n",
        "            bn = nn.BatchNorm2d\n",
        "        else:\n",
        "            conv_nd = nn.Conv1d\n",
        "            max_pool_layer = nn.MaxPool1d(kernel_size=(2))\n",
        "            bn = nn.BatchNorm1d\n",
        "\n",
        "        self.g = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                         kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if bn_layer:\n",
        "            self.W = nn.Sequential(\n",
        "                conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                        kernel_size=1, stride=1, padding=0),\n",
        "                bn(self.in_channels)\n",
        "            )\n",
        "            nn.init.constant_(self.W[1].weight, 0)\n",
        "            nn.init.constant_(self.W[1].bias, 0)\n",
        "        else:\n",
        "            self.W = conv_nd(in_channels=self.inter_channels, out_channels=self.in_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "            nn.init.constant_(self.W.weight, 0)\n",
        "            nn.init.constant_(self.W.bias, 0)\n",
        "\n",
        "        self.theta = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                             kernel_size=1, stride=1, padding=0)\n",
        "        self.phi = conv_nd(in_channels=self.in_channels, out_channels=self.inter_channels,\n",
        "                           kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "        if sub_sample:\n",
        "            self.g = nn.Sequential(self.g, max_pool_layer)\n",
        "            self.phi = nn.Sequential(self.phi, max_pool_layer)\n",
        "\n",
        "    def forward(self, x, y, return_nl_map=False):\n",
        "        \"\"\"\n",
        "        :param x: (b, c, h, w)\n",
        "        :param y: (b, c, 1)\n",
        "        :param return_nl_map: if True return z, nl_map, else only return z.\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        h, w = x.shape[2:]\n",
        "\n",
        "        g_x = self.g(x).view(batch_size, self.inter_channels, -1)\n",
        "        #g_x = g_x.permute(0, 2, 1)\n",
        "\n",
        "        theta_x = self.theta(x).view(batch_size, self.inter_channels, -1)\n",
        "        theta_x = theta_x.permute(0, 2, 1)\n",
        "\n",
        "        #phi_x = self.phi(x).view(batch_size, self.inter_channels, -1)\n",
        "        phi_x = self.phi(y.unsqueeze(-1)).view(batch_size, self.inter_channels, -1)\n",
        "        f = torch.matmul(theta_x, phi_x)\n",
        "        #f_div_C = F.softmax(f, dim=-1)\n",
        "        f_div_C = torch.sigmoid(f)\n",
        "        f_div_C = f_div_C.permute(0,2,1).contiguous()\n",
        "\n",
        "        #y = torch.matmul(f_div_C, g_x)\n",
        "        #y = y.permute(0, 2, 1).contiguous()\n",
        "        y = g_x * f_div_C\n",
        "        y = y.view(batch_size, self.inter_channels, *x.size()[2:])\n",
        "        W_y = self.W(y)\n",
        "        z = W_y + x\n",
        "\n",
        "        if return_nl_map:\n",
        "            return z, f_div_C.view(batch_size, 1, h, w)\n",
        "        return z\n",
        "\n",
        "class NONLocalBlock2D(_NonLocalBlockND):\n",
        "    def __init__(self, in_channels, inter_channels=None, sub_sample=True, bn_layer=True):\n",
        "        super(NONLocalBlock2D, self).__init__(in_channels,\n",
        "                                              inter_channels=inter_channels,\n",
        "                                              dimension=2, sub_sample=sub_sample,\n",
        "                                              bn_layer=bn_layer,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ld_aLxHH9UPK"
      },
      "source": [
        "## BAG - Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAar3gnt9UPK"
      },
      "source": [
        "### process_point.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LKkD4dhS9UPK"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "import skimage.draw\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "def create_circular_mask(h, w, center, radius):\n",
        "    Y, X = np.ogrid[:h, :w]\n",
        "    dist_from_center = np.sqrt((X - center[0])**2 + (Y - center[1])**2)\n",
        "    mask = dist_from_center <= radius\n",
        "    return mask\n",
        "\n",
        "\n",
        "def NMS(heatmap, kernel=13):\n",
        "    hmax = F.max_pool2d(heatmap, kernel, stride=1, padding=(kernel - 1) // 2)\n",
        "    keep = (hmax == heatmap).float()\n",
        "    return heatmap * keep, hmax, keep\n",
        "\n",
        "\n",
        "def draw_msra_gaussian(heatmap, center, sigma):\n",
        "    tmp_size = sigma * 3\n",
        "    mu_x = int(center[0] + 0.5)\n",
        "    mu_y = int(center[1] + 0.5)\n",
        "    w, h = heatmap.shape[0], heatmap.shape[1]\n",
        "    ul = [int(mu_x - tmp_size), int(mu_y - tmp_size)]\n",
        "    br = [int(mu_x + tmp_size + 1), int(mu_y + tmp_size + 1)]\n",
        "    if ul[0] >= h or ul[1] >= w or br[0] < 0 or br[1] < 0:\n",
        "        return heatmap\n",
        "    size = 2 * tmp_size + 1\n",
        "    x = np.arange(0, size, 1, np.float32)\n",
        "    y = x[:, np.newaxis]\n",
        "    x0 = y0 = size // 2\n",
        "    g = np.exp(-((x - x0)**2 + (y - y0)**2) / (2 * sigma**2))\n",
        "    g_x = max(0, -ul[0]), min(br[0], h) - ul[0]\n",
        "    g_y = max(0, -ul[1]), min(br[1], w) - ul[1]\n",
        "    img_x = max(0, ul[0]), min(br[0], h)\n",
        "    img_y = max(0, ul[1]), min(br[1], w)\n",
        "    heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]] = np.maximum(\n",
        "        heatmap[img_y[0]:img_y[1], img_x[0]:img_x[1]], g[g_y[0]:g_y[1],\n",
        "                                                         g_x[0]:g_x[1]])\n",
        "    return heatmap\n",
        "\n",
        "\n",
        "def kpm_gen(label_path, R, N):\n",
        "    label = np.load(label_path)\n",
        "    #     label = label[0]\n",
        "    label_ori = label.copy()\n",
        "    label = label[::4, ::4]\n",
        "    label = np.uint8(label * 255)\n",
        "    contours, hierarchy = cv2.findContours(label, cv2.RETR_LIST,\n",
        "                                           cv2.CHAIN_APPROX_NONE)\n",
        "    contour_len = len(contours)\n",
        "\n",
        "    label = np.repeat(label[..., np.newaxis], 3, axis=-1)\n",
        "    draw_label = cv2.drawContours(label.copy(), contours, -1, (0, 0, 255), 1)\n",
        "\n",
        "    point_file = []\n",
        "    if contour_len == 0:\n",
        "        point_heatmap = np.zeros((512, 512))\n",
        "    else:\n",
        "        point_heatmap = np.zeros((512, 512))\n",
        "        for contour in contours:\n",
        "            stds = []\n",
        "            points = contour[:, 0]  # (N,2)\n",
        "            points = points * 4\n",
        "            points_number = contour.shape[0]\n",
        "            if points_number < 30:\n",
        "                continue\n",
        "\n",
        "            if points_number < 100:\n",
        "                radius = 6\n",
        "                neighbor_points_n_oneside = 3\n",
        "            elif points_number < 200:\n",
        "                radius = 10\n",
        "                neighbor_points_n_oneside = 15\n",
        "            elif points_number < 300:\n",
        "                radius = 10\n",
        "                neighbor_points_n_oneside = 20\n",
        "            elif points_number < 350:\n",
        "                radius = 15\n",
        "                neighbor_points_n_oneside = 30\n",
        "            else:\n",
        "                radius = 10\n",
        "                neighbor_points_n_oneside = 40\n",
        "\n",
        "            for i in range(points_number):\n",
        "                current_point = points[i]\n",
        "                mask = create_circular_mask(512, 512, points[i], radius)\n",
        "                overlap_area = np.sum(\n",
        "                    mask * label_ori) / (np.pi * radius * radius)\n",
        "                stds.append(overlap_area)\n",
        "            print(\"stds len: \", len(stds))\n",
        "\n",
        "            # show\n",
        "            selected_points = []\n",
        "            stds = np.array(stds)\n",
        "            neighbor_points = []\n",
        "            for i in range(len(points)):\n",
        "                current_point = points[i]\n",
        "                neighbor_points_index = np.concatenate([\n",
        "                    np.arange(-neighbor_points_n_oneside, 0),\n",
        "                    np.arange(1, neighbor_points_n_oneside + 1)\n",
        "                ]) + i\n",
        "                neighbor_points_index[np.where(\n",
        "                    neighbor_points_index < 0)[0]] += len(points)\n",
        "                neighbor_points_index[np.where(\n",
        "                    neighbor_points_index > len(points) - 1)[0]] -= len(points)\n",
        "                if stds[i] < np.min(\n",
        "                        stds[neighbor_points_index]) or stds[i] > np.max(\n",
        "                            stds[neighbor_points_index]):\n",
        "                    #                     print(points[i])\n",
        "                    point_heatmap = draw_msra_gaussian(\n",
        "                        point_heatmap, (points[i, 0], points[i, 1]), 5)\n",
        "                    selected_points.append(points[i])\n",
        "\n",
        "            print(\"selected_points num: \", len(selected_points))\n",
        "            #             print(selected_points)\n",
        "            maskk = np.zeros((512, 512))\n",
        "            rr, cc = skimage.draw.polygon(\n",
        "                np.array(selected_points)[:, 1],\n",
        "                np.array(selected_points)[:, 0])\n",
        "            maskk[rr, cc] = 1\n",
        "            intersection = np.logical_and(label_ori, maskk)\n",
        "            union = np.logical_or(label_ori, maskk)\n",
        "            iou_score = np.sum(intersection) / np.sum(union)\n",
        "            print(iou_score)\n",
        "    return label_ori, point_heatmap\n",
        "\n",
        "\n",
        "def point_gen_isic2018():\n",
        "    R = 10\n",
        "    N = 25\n",
        "    data_dir = '/raid/wjc/data/skin_lesion/isic2018/Label'\n",
        "\n",
        "    save_dir = data_dir.replace('Label', 'Point')\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    path_list = os.listdir(data_dir)\n",
        "    path_list.sort()\n",
        "    num = 0\n",
        "    for path in tqdm(path_list):\n",
        "        name = path[:-4]\n",
        "        label_path = os.path.join(data_dir, path)\n",
        "        print(label_path)\n",
        "        label_ori, point_heatmap = kpm_gen(label_path, R, N)\n",
        "\n",
        "        save_path = os.path.join(save_dir, name + '.npy')\n",
        "        np.save(save_path, point_heatmap)\n",
        "        num += 1\n",
        "\n",
        "\n",
        "def point_gen_isic2016():\n",
        "    R = 10\n",
        "    N = 25\n",
        "    for split in ['Train', 'Test', 'Validation']:\n",
        "        data_dir = '/raid/wjc/data/skin_lesion/isic2016/{}/Label'.format(split)\n",
        "\n",
        "        save_dir = data_dir.replace('Label', 'Point')\n",
        "        os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "        path_list = os.listdir(data_dir)\n",
        "        path_list.sort()\n",
        "        num = 0\n",
        "        for path in tqdm(path_list):\n",
        "            name = path[:-4]\n",
        "            label_path = os.path.join(data_dir, path)\n",
        "            print(label_path)\n",
        "            label_ori, point_heatmap = kpm_gen(label_path, R, N)\n",
        "            save_path = os.path.join(save_dir, name + '.npy')\n",
        "            np.save(save_path, point_heatmap)\n",
        "            num += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rpAsnr89UPL"
      },
      "source": [
        "## BAT utility modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_mqFXmim9UPL"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "class CrossAttention(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 dim_feedforward=512,\n",
        "                 dropout=0.0):\n",
        "        super().__init__()\n",
        "\n",
        "        self.cross_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = nn.LeakyReLU()\n",
        "\n",
        "\n",
        "    def forward(self, tgt, src):\n",
        "        \"tgt shape: Batch_size, C, H, W \"\n",
        "        \"src shape: Batch_size, 1, C    \"\n",
        "\n",
        "        B, C, h, w = tgt.shape\n",
        "        tgt = tgt.view(B, C, h*w).permute(2,0,1)  # shape: L, B, C\n",
        "\n",
        "        src = src.permute(1,0,2)  # shape: Q:1, B, C\n",
        "\n",
        "        fusion_feature = self.cross_attn(query=tgt,\n",
        "                                         key=src,\n",
        "                                         value=src)[0]\n",
        "        tgt = tgt + self.dropout1(fusion_feature)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt1 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout2(tgt1)\n",
        "        tgt = self.norm2(tgt)\n",
        "        return tgt.permute(1, 2, 0).view(B, C, h, w)\n",
        "\n",
        "class BoundaryCrossAttention(CrossAttention):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 BAG_type='2D',\n",
        "                 Atrous=True,\n",
        "                 dim_feedforward=512,\n",
        "                 dropout=0.0):\n",
        "        super().__init__(d_model, nhead, dim_feedforward, dropout)\n",
        "\n",
        "        #self.BAG = nn.Sequential(\n",
        "        #    nn.Conv2d(d_model, d_model, kernel_size=3, padding=1, bias=False),\n",
        "        #    nn.BatchNorm2d(d_model),\n",
        "        #    nn.ReLU(inplace=False),\n",
        "        #    nn.Conv2d(d_model, d_model, kernel_size=3, padding=1, bias=False),\n",
        "        #    nn.BatchNorm2d(d_model),\n",
        "        #    nn.ReLU(inplace=False),\n",
        "        #    nn.Conv2d(d_model, 1, kernel_size=1))\n",
        "        self.BAG_type = BAG_type\n",
        "        if self.BAG_type == '1D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous1D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate1D(d_model)\n",
        "        elif self.BAG_type == '2D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous2D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate2D(d_model)\n",
        "\n",
        "    def forward(self, tgt, src):\n",
        "        \"tgt shape: Batch_size, C, H, W \"\n",
        "        \"src shape: Batch_size, 1, C    \"\n",
        "\n",
        "        B, C, h, w = tgt.shape\n",
        "        tgt = tgt.view(B, C, h*w).permute(2,0,1)  # shape: L, B, C\n",
        "\n",
        "        src = src.permute(1,0,2)  # shape: Q:1, B, C\n",
        "\n",
        "        fusion_feature = self.cross_attn(query=tgt,\n",
        "                                         key=src,\n",
        "                                         value=src)[0]\n",
        "        tgt = tgt + self.dropout1(fusion_feature)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt1 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout2(tgt1)\n",
        "        tgt = self.norm2(tgt)\n",
        "\n",
        "        if self.BAG_type == '1D':\n",
        "            tgt = tgt.permute(1,2,0)\n",
        "            tgt, weights = self.BAG(tgt)\n",
        "            tgt = tgt.view(B, C, h, w).contiguous()\n",
        "            weights = weights.view(B, 1, h, w)\n",
        "        elif self.BAG_type == '2D':\n",
        "            tgt = tgt.permute(1,2,0).view(B, C, h, w)\n",
        "            tgt, weights = self.BAG(tgt)\n",
        "            tgt = tgt.contiguous()\n",
        "        return tgt, weights\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"\n",
        "    This class implements a multi head attention module like proposed in:\n",
        "    https://arxiv.org/abs/2005.12872\n",
        "    \"\"\"\n",
        "    def __init__(self, query_dimension: int = 64, hidden_features: int = 64, number_of_heads: int = 16,\n",
        "                 dropout: float = 0.0) -> None:\n",
        "        \"\"\"\n",
        "        Constructor method\n",
        "        :param query_dimension: (int) Dimension of query tensor\n",
        "        :param hidden_features: (int) Number of hidden features in detr\n",
        "        :param number_of_heads: (int) Number of prediction heads\n",
        "        :param dropout: (float) Dropout factor to be utilized\n",
        "        \"\"\"\n",
        "        # Call super constructor\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        # Save parameters\n",
        "        self.hidden_features = hidden_features\n",
        "        self.number_of_heads = number_of_heads\n",
        "        self.dropout = dropout\n",
        "        # Init layer\n",
        "        self.layer_box_embedding = nn.Linear(in_features=query_dimension, out_features=hidden_features, bias=True)\n",
        "        # Init convolution layer\n",
        "        self.layer_image_encoding = nn.Conv2d(in_channels=query_dimension, out_channels=hidden_features,\n",
        "                                              kernel_size=(1, 1), stride=(1, 1), padding=(0, 0), bias=True)\n",
        "        # Init normalization factor\n",
        "        self.normalization_factor = torch.tensor(self.hidden_features / self.number_of_heads, dtype=torch.float).sqrt()\n",
        "\n",
        "        # Linear\n",
        "        self.linear = nn.Linear(in_features=number_of_heads, out_features=1)\n",
        "\n",
        "    def forward(self, input_box_embeddings: torch.Tensor, input_image_encoding: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Forward pass\n",
        "        :param input_box_embeddings: (torch.Tensor) Bounding box embeddings\n",
        "        :param input_image_encoding: (torch.Tensor) Encoded image of the transformer encoder\n",
        "        :return: (torch.Tensor) Attention maps of shape (batch size, n, m, height, width)\n",
        "        \"\"\"\n",
        "        # Map box embeddings\n",
        "        output_box_embeddings = self.layer_box_embedding(input_box_embeddings)\n",
        "        # Map image features\n",
        "        output_image_encoding = self.layer_image_encoding(input_image_encoding)\n",
        "        # Reshape output box embeddings\n",
        "        output_box_embeddings = output_box_embeddings.view(output_box_embeddings.shape[0],\n",
        "                                                           output_box_embeddings.shape[1],\n",
        "                                                           self.number_of_heads,\n",
        "                                                           self.hidden_features // self.number_of_heads)\n",
        "        # Reshape output image encoding\n",
        "        output_image_encoding = output_image_encoding.view(output_image_encoding.shape[0],\n",
        "                                                           self.number_of_heads,\n",
        "                                                           self.hidden_features // self.number_of_heads,\n",
        "                                                           output_image_encoding.shape[-2],\n",
        "                                                           output_image_encoding.shape[-1])\n",
        "        # Combine tensors and normalize\n",
        "        output = torch.einsum(\"bqnc,bnchw->bqnhw\",\n",
        "                              output_box_embeddings * self.normalization_factor,\n",
        "                              output_image_encoding)\n",
        "        # Apply softmax\n",
        "        output = F.softmax(output.flatten(start_dim=2), dim=-1).view_as(output)\n",
        "\n",
        "        # Linear: to generate one map\n",
        "        b, _, _, h, w = output.shape\n",
        "        output = torch.sigmoid(self.linear(output.flatten(start_dim=3).permute(0,1,3,2))).view(b,1,h,w)\n",
        "\n",
        "        # Perform dropout if utilized\n",
        "        if self.dropout > 0.0:\n",
        "            output = F.dropout(input=output, p=self.dropout, training=self.training)\n",
        "#         print(\"MultiHead Attention\",output.shape)\n",
        "        return output.contiguous()\n",
        "\n",
        "\n",
        "class BoundaryWiseAttentionGateAtrous2D(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels = None):\n",
        "\n",
        "        super(BoundaryWiseAttentionGateAtrous2D,self).__init__()\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        if hidden_channels == None:\n",
        "            hidden_channels = in_channels // 2\n",
        "\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 3, padding=1, dilation=1, bias=False),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 3, padding=2, dilation=2, bias=False),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 3, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_channels, 3, padding=6, dilation=6, bias=False),\n",
        "            nn.BatchNorm2d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "\n",
        "        self.conv_out = nn.Conv2d(5 * hidden_channels, 1, 1, bias=False)\n",
        "    def forward(self, x):\n",
        "        \" x.shape: B, C, H, W \"\n",
        "        \" return: feature, weight (B,C,H,W) \"\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        weight = torch.sigmoid(self.conv_out(res))\n",
        "        x = x * weight + x\n",
        "        return x, weight\n",
        "\n",
        "class BoundaryWiseAttentionGateAtrous1D(nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels = None):\n",
        "\n",
        "        super(BoundaryWiseAttentionGateAtrous1D,self).__init__()\n",
        "\n",
        "        modules = []\n",
        "\n",
        "        if hidden_channels == None:\n",
        "            hidden_channels = in_channels // 2\n",
        "\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv1d(in_channels, hidden_channels, 1, bias=False),\n",
        "            nn.BatchNorm1d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv1d(in_channels, hidden_channels, 3, padding=1, dilation=1, bias=False),\n",
        "            nn.BatchNorm1d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv1d(in_channels, hidden_channels, 3, padding=2, dilation=2, bias=False),\n",
        "            nn.BatchNorm1d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv1d(in_channels, hidden_channels, 3, padding=4, dilation=4, bias=False),\n",
        "            nn.BatchNorm1d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "        modules.append(nn.Sequential(\n",
        "            nn.Conv1d(in_channels, hidden_channels, 3, padding=6, dilation=6, bias=False),\n",
        "            nn.BatchNorm1d(hidden_channels),\n",
        "            nn.ReLU(inplace=True)))\n",
        "\n",
        "        self.convs = nn.ModuleList(modules)\n",
        "\n",
        "        self.conv_out = nn.Conv1d(5 * hidden_channels, 1, 1, bias=False)\n",
        "    def forward(self, x):\n",
        "        \" x.shape: B, C, L \"\n",
        "        \" return: feature, weight (B,C,L) \"\n",
        "        res = []\n",
        "        for conv in self.convs:\n",
        "            res.append(conv(x))\n",
        "        res = torch.cat(res, dim=1)\n",
        "        weight = torch.sigmoid(self.conv_out(res))\n",
        "        x = x * weight + x\n",
        "        return x, weight\n",
        "\n",
        "class BoundaryWiseAttentionGate2D(nn.Sequential):\n",
        "    def __init__(self, in_channels, hidden_channels = None):\n",
        "        super(BoundaryWiseAttentionGate2D,self).__init__(\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(in_channels),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv2d(in_channels, 1, kernel_size=1))\n",
        "    def forward(self, x):\n",
        "        \" x.shape: B, C, H, W \"\n",
        "        \" return: feature, weight (B,C,H,W) \"\n",
        "        weight = torch.sigmoid(super(BoundaryWiseAttentionGate2D,self).forward(x))\n",
        "        x = x * weight + x\n",
        "        return x, weight\n",
        "\n",
        "class BoundaryWiseAttentionGate1D(nn.Sequential):\n",
        "    def __init__(self, in_channels, hidden_channels = None):\n",
        "        super(BoundaryWiseAttentionGate1D,self).__init__(\n",
        "            nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm1d(in_channels),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv1d(in_channels, in_channels, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm1d(in_channels),\n",
        "            nn.ReLU(inplace=False),\n",
        "            nn.Conv1d(in_channels, 1, kernel_size=1))\n",
        "    def forward(self, x):\n",
        "        \" x.shape: B, C, L \"\n",
        "        \" return: feature, weight (B,C,L) \"\n",
        "        weight = torch.sigmoid(super(BoundaryWiseAttentionGate1D,self).forward(x))\n",
        "        x = x * weight + x\n",
        "        return x, weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wyBin1-klDc"
      },
      "source": [
        "## transformer.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p7bRaHbhklDd"
      },
      "outputs": [],
      "source": [
        "# Based on: https://github.com/facebookresearch/detr/blob/master/models/transformer.py\n",
        "import copy\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, Tensor\n",
        "\n",
        "# from .BAT_Modules import BoundaryWiseAttentionGate2D, BoundaryWiseAttentionGate1D, BoundaryWiseAttentionGateAtrous2D, BoundaryWiseAttentionGateAtrous1D\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model=512,\n",
        "                 nhead=8,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=2,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False,\n",
        "                 return_intermediate_dec=False):\n",
        "        super().__init__()\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers,\n",
        "                                          encoder_norm)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        decoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            decoder_layer,\n",
        "            num_decoder_layers,\n",
        "            decoder_norm,\n",
        "            return_intermediate=return_intermediate_dec)\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, mask, query_embed, pos_embed):\n",
        "        bs, c, h, w = src.shape\n",
        "        src = src.flatten(2).permute(2, 0, 1)\n",
        "        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n",
        "        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
        "        if mask is not None:\n",
        "            mask = mask.flatten(1)\n",
        "\n",
        "        tgt = torch.zeros_like(query_embed)\n",
        "        memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n",
        "        #         print(\"Trans Encoder\",memory.shape)\n",
        "        hs = self.decoder(tgt,\n",
        "                          memory,\n",
        "                          memory_key_padding_mask=mask,\n",
        "                          pos=pos_embed,\n",
        "                          query_pos=query_embed)\n",
        "        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 point_pred_layers=6,\n",
        "                 d_model=512,\n",
        "                 nhead=8,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=2,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False,\n",
        "                 return_intermediate_dec=False,\n",
        "                 BAG_type='2D',\n",
        "                 Atrous=False):\n",
        "        super().__init__()\n",
        "\n",
        "        encoder_layer = BoundaryAwareTransformerEncoderLayer(\n",
        "            d_model, nhead, BAG_type, Atrous, dim_feedforward, dropout,\n",
        "            activation, normalize_before)\n",
        "        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n",
        "        self.encoder = BoundaryAwareTransformerEncoder(point_pred_layers,\n",
        "                                                       encoder_layer,\n",
        "                                                       num_encoder_layers,\n",
        "                                                       encoder_norm)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        decoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            decoder_layer,\n",
        "            num_decoder_layers,\n",
        "            decoder_norm,\n",
        "            return_intermediate=return_intermediate_dec)\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, mask, query_embed, pos_embed):\n",
        "        bs, c, h, w = src.shape\n",
        "        src = src.flatten(2).permute(2, 0, 1)\n",
        "        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n",
        "        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
        "        if mask is not None:\n",
        "            mask = mask.flatten(1)\n",
        "\n",
        "        tgt = torch.zeros_like(query_embed)\n",
        "        memory, weights = self.encoder(src,\n",
        "                                       src_key_padding_mask=mask,\n",
        "                                       pos=pos_embed,\n",
        "                                       height=h,\n",
        "                                       width=w)\n",
        "\n",
        "        hs = self.decoder(tgt,\n",
        "                          memory,\n",
        "                          memory_key_padding_mask=mask,\n",
        "                          pos=pos_embed,\n",
        "                          query_pos=query_embed)\n",
        "        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h,\n",
        "                                                                w), weights\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None):\n",
        "        output = src\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output,\n",
        "                           src_mask=mask,\n",
        "                           src_key_padding_mask=src_key_padding_mask,\n",
        "                           pos=pos)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformerEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 point_pred_layers,\n",
        "                 encoder_layer,\n",
        "                 num_layers,\n",
        "                 norm=None):\n",
        "        super().__init__()\n",
        "        self.point_pred_layers = point_pred_layers\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                height: int = 32,\n",
        "                width: int = 32):\n",
        "        output = src\n",
        "        weights = []\n",
        "\n",
        "        for layer_i, layer in enumerate(self.layers):\n",
        "            if layer_i > self.num_layers - self.point_pred_layers - 1:\n",
        "                output, weight = layer(\n",
        "                    True,\n",
        "                    output,\n",
        "                    src_mask=mask,\n",
        "                    src_key_padding_mask=src_key_padding_mask,\n",
        "                    pos=pos,\n",
        "                    height=height,\n",
        "                    width=width)\n",
        "                weights.append(weight)\n",
        "            else:\n",
        "                output = layer(False,\n",
        "                               output,\n",
        "                               src_mask=mask,\n",
        "                               src_key_padding_mask=src_key_padding_mask,\n",
        "                               pos=pos,\n",
        "                               height=height,\n",
        "                               width=width)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation()\n",
        "        self.normalize_before = normalize_before\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "\n",
        "    def forward_post(self,\n",
        "                     src,\n",
        "                     src_mask: Optional[Tensor] = None,\n",
        "                     src_key_padding_mask: Optional[Tensor] = None,\n",
        "                     pos: Optional[Tensor] = None):\n",
        "        q = k = self.with_pos_embed(src, pos)\n",
        "        src2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=src,\n",
        "                              attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "    def forward_pre(self,\n",
        "                    src,\n",
        "                    src_mask: Optional[Tensor] = None,\n",
        "                    src_key_padding_mask: Optional[Tensor] = None,\n",
        "                    pos: Optional[Tensor] = None):\n",
        "        src2 = self.norm1(src)\n",
        "        q = k = self.with_pos_embed(src2, pos)\n",
        "        src2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=src2,\n",
        "                              attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src2 = self.norm2(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        return src\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                src_mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None):\n",
        "        if self.normalize_before:\n",
        "            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)\n",
        "        return self.forward_post(src, src_mask, src_key_padding_mask, pos)\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformerEncoderLayer(TransformerEncoderLayer):\n",
        "    \"    Add Boundary-wise Attention Gate to Transformer's Encoder\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 BAG_type='2D',\n",
        "                 Atrous=True,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation,\n",
        "                         normalize_before)\n",
        "        if BAG_type == '1D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous1D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate1D(d_model)\n",
        "        elif BAG_type == '2D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous2D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate2D(d_model)\n",
        "        self.BAG_type = BAG_type\n",
        "\n",
        "    def forward(self,\n",
        "                use_bag,\n",
        "                src,\n",
        "                src_mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                height: int = 32,\n",
        "                width: int = 32):\n",
        "        if self.normalize_before:\n",
        "            features = self.forward_pre(src, src_mask, src_key_padding_mask,\n",
        "                                        pos)\n",
        "            if use_bag:\n",
        "                b, c = features.shape[1:]\n",
        "                if self.BAG_type == '1D':\n",
        "                    features = features.permute(1, 2, 0)\n",
        "                    features, weights = self.BAG(features)\n",
        "                    features = features.permute(2, 0, 1).contiguous()\n",
        "                    weights = weights.view(b, 1, height, width)\n",
        "                elif self.BAG_type == '2D':\n",
        "                    features = features.permute(1, 2,\n",
        "                                                0).view(b, c, height, width)\n",
        "                    features, weights = self.BAG(features)\n",
        "                    features = features.flatten(2).permute(2, 0,\n",
        "                                                           1).contiguous()\n",
        "                return features, weights\n",
        "            else:\n",
        "                return features\n",
        "        features = self.forward_post(src, src_mask, src_key_padding_mask, pos)\n",
        "        if use_bag:\n",
        "            b, c = features.shape[1:]\n",
        "            if self.BAG_type == '1D':\n",
        "                features = features.permute(1, 2, 0)\n",
        "                features, weights = self.BAG(features)\n",
        "                features = features.permute(2, 0, 1).contiguous()\n",
        "                weights = weights.view(b, 1, height, width)\n",
        "            elif self.BAG_type == '2D':\n",
        "                features = features.permute(1, 2, 0).view(b, c, height, width)\n",
        "                features, weights = self.BAG(features)\n",
        "                features = features.flatten(2).permute(2, 0, 1).contiguous()\n",
        "            return features, weights\n",
        "        else:\n",
        "            return features\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 decoder_layer,\n",
        "                 num_layers,\n",
        "                 norm=None,\n",
        "                 return_intermediate=False):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(decoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "        self.return_intermediate = return_intermediate\n",
        "\n",
        "    def forward(self,\n",
        "                tgt,\n",
        "                memory,\n",
        "                tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                query_pos: Optional[Tensor] = None):\n",
        "        output = tgt\n",
        "\n",
        "        intermediate = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output,\n",
        "                           memory,\n",
        "                           tgt_mask=tgt_mask,\n",
        "                           memory_mask=memory_mask,\n",
        "                           tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                           memory_key_padding_mask=memory_key_padding_mask,\n",
        "                           pos=pos,\n",
        "                           query_pos=query_pos)\n",
        "            if self.return_intermediate:\n",
        "                intermediate.append(self.norm(output))\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "            if self.return_intermediate:\n",
        "                intermediate.pop()\n",
        "                intermediate.append(output)\n",
        "\n",
        "        if self.return_intermediate:\n",
        "            return torch.stack(intermediate)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model,\n",
        "                                                    nhead,\n",
        "                                                    dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation()\n",
        "        self.normalize_before = normalize_before\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "\n",
        "    def forward_post(self,\n",
        "                     tgt,\n",
        "                     memory,\n",
        "                     tgt_mask: Optional[Tensor] = None,\n",
        "                     memory_mask: Optional[Tensor] = None,\n",
        "                     tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                     memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                     pos: Optional[Tensor] = None,\n",
        "                     query_pos: Optional[Tensor] = None):\n",
        "        q = k = self.with_pos_embed(tgt, query_pos)\n",
        "        tgt2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=tgt,\n",
        "                              attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),\n",
        "                                   key=self.with_pos_embed(memory, pos),\n",
        "                                   value=memory,\n",
        "                                   attn_mask=memory_mask,\n",
        "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt\n",
        "\n",
        "    def forward_pre(self,\n",
        "                    tgt,\n",
        "                    memory,\n",
        "                    tgt_mask: Optional[Tensor] = None,\n",
        "                    memory_mask: Optional[Tensor] = None,\n",
        "                    tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                    memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                    pos: Optional[Tensor] = None,\n",
        "                    query_pos: Optional[Tensor] = None):\n",
        "        tgt2 = self.norm1(tgt)\n",
        "        q = k = self.with_pos_embed(tgt2, query_pos)\n",
        "        tgt2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=tgt2,\n",
        "                              attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt2 = self.norm2(tgt)\n",
        "        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),\n",
        "                                   key=self.with_pos_embed(memory, pos),\n",
        "                                   value=memory,\n",
        "                                   attn_mask=memory_mask,\n",
        "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt2 = self.norm3(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        return tgt\n",
        "\n",
        "    def forward(self,\n",
        "                tgt,\n",
        "                memory,\n",
        "                tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                query_pos: Optional[Tensor] = None):\n",
        "        if self.normalize_before:\n",
        "            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,\n",
        "                                    tgt_key_padding_mask,\n",
        "                                    memory_key_padding_mask, pos, query_pos)\n",
        "        return self.forward_post(tgt, memory, tgt_mask, memory_mask,\n",
        "                                 tgt_key_padding_mask, memory_key_padding_mask,\n",
        "                                 pos, query_pos)\n",
        "\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "def build_transformer(args):\n",
        "    return Transformer(\n",
        "        d_model=args.hidden_dim,\n",
        "        dropout=args.dropout,\n",
        "        nhead=args.nheads,\n",
        "        dim_feedforward=args.dim_feedforward,\n",
        "        num_encoder_layers=args.enc_layers,\n",
        "        num_decoder_layers=args.dec_layers,\n",
        "        normalize_before=args.pre_norm,\n",
        "        return_intermediate_dec=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    \"\"\"Return an activation function given a string\"\"\"\n",
        "    if activation == \"leaky relu\":\n",
        "        return F.leaky_relu\n",
        "    if activation == \"selu\":\n",
        "        return F.selu\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    if activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    if activation == \"glu\":\n",
        "        return F.glu\n",
        "    raise RuntimeError(\n",
        "        F\"activation should be relu, gelu, glu, leaky relu or selu, not {activation}.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLaynkwn9UPM"
      },
      "source": [
        "## ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsyy9B33klD8"
      },
      "outputs": [],
      "source": [
        "from torchvision.models import resnet50, resnet34, resnet18, ResNet50_Weights, ResNet18_Weights, ResNet34_Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rlV1_wDH9UPM"
      },
      "outputs": [],
      "source": [
        "# For ResNet18, use layers up to layer3 so that the output has OS16.\n",
        "def ResNet18_OS16(multi_scale=False):\n",
        "    resnet = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
        "    # Original resnet18 children:\n",
        "    # [conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc]\n",
        "    # Removing layer4, avgpool and fc gives a feature map of size roughly (B, 256, H/16, W/16)\n",
        "    features = nn.Sequential(*list(resnet.children())[:-3])\n",
        "    return features\n",
        "\n",
        "# For ResNet50, adjust layer4 to preserve OS16.\n",
        "def ResNet50_OS16(multi_scale=False):\n",
        "    resnet = resnet50(weights=ResNet50_Weights.IMAGENET1K_V2)\n",
        "    # The children of resnet50 are:\n",
        "    # [conv1, bn1, relu, maxpool, layer1, layer2, layer3, layer4, avgpool, fc]\n",
        "    # To achieve OS16 instead of OS32, modify layer4 so that it does not downsample:\n",
        "    #  - Change the stride in the first Bottleneck of layer4 from 2 to 1.\n",
        "    resnet.layer4[0].conv2.stride = (1, 1)\n",
        "    if resnet.layer4[0].downsample:  # adjust the downsampling layer as well\n",
        "        resnet.layer4[0].downsample[0].stride = (1, 1)\n",
        "    # Additionally, increase dilation in layer4 so that its receptive field remains large.\n",
        "    for m in resnet.layer4.modules():\n",
        "        if isinstance(m, nn.Conv2d) and m.kernel_size == (3, 3):\n",
        "            m.dilation = (2, 2)\n",
        "            m.padding = (2, 2)\n",
        "    # Now remove the avgpool and fc layers.\n",
        "    features = nn.Sequential(*list(resnet.children())[:-2])\n",
        "    return features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFIKfzTH9UPN"
      },
      "source": [
        "## Atrous Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GMt0ON6a9UPO"
      },
      "outputs": [],
      "source": [
        "# # camera-ready\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# class ASPP(nn.Module):\n",
        "#     def __init__(self, num_classes, head = True):\n",
        "#         super(ASPP, self).__init__()\n",
        "\n",
        "#         self.conv_1x1_1 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "#         self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "#         self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "#         self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_3 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "#         self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "#         self.conv_1x1_2 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "#         self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1) # (1280 = 5*256)\n",
        "#         self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         if head:\n",
        "#             self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "#         self.head = head\n",
        "\n",
        "#     def forward(self, feature_map):\n",
        "#         # (feature_map has shape (batch_size, 512, h/16, w/16)) (assuming self.resnet is ResNet18_OS16 or ResNet34_OS16. If self.resnet instead is ResNet18_OS8 or ResNet34_OS8, it will be (batch_size, 512, h/8, w/8))\n",
        "\n",
        "#         feature_map_h = feature_map.size()[2] # (== h/16)\n",
        "#         feature_map_w = feature_map.size()[3] # (== w/16)\n",
        "\n",
        "#         out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "\n",
        "#         out_img = self.avg_pool(feature_map) # (shape: (batch_size, 512, 1, 1))\n",
        "#         out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img))) # (shape: (batch_size, 256, 1, 1))\n",
        "#         out_img = F.interpolate(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\") # (shape: (batch_size, 256, h/16, w/16))\n",
        "\n",
        "#         out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1) # (shape: (batch_size, 1280, h/16, w/16))\n",
        "#         out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         if self.head:\n",
        "#             out = self.conv_1x1_4(out) # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "\n",
        "#         return out\n",
        "\n",
        "# class ASPP_Bottleneck(nn.Module):\n",
        "#     def __init__(self, num_classes):\n",
        "#         super(ASPP_Bottleneck, self).__init__()\n",
        "\n",
        "#         self.conv_1x1_1 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "#         self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_1 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "#         self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_2 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "#         self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_3x3_3 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "#         self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "#         self.conv_1x1_2 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "#         self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1) # (1280 = 5*256)\n",
        "#         self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "#         self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "#     def forward(self, feature_map):\n",
        "#         # (feature_map has shape (batch_size, 4*512, h/16, w/16))\n",
        "\n",
        "#         feature_map_h = feature_map.size()[2] # (== h/16)\n",
        "#         feature_map_w = feature_map.size()[3] # (== w/16)\n",
        "\n",
        "#         out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "\n",
        "#         out_img = self.avg_pool(feature_map) # (shape: (batch_size, 512, 1, 1))\n",
        "#         out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img))) # (shape: (batch_size, 256, 1, 1))\n",
        "#         out_img = F.interpolate(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\") # (shape: (batch_size, 256, h/16, w/16))\n",
        "\n",
        "#         out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1) # (shape: (batch_size, 1280, h/16, w/16))\n",
        "#         out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "#         out = self.conv_1x1_4(out) # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "\n",
        "#         return out\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhAMspTBQ0N4"
      },
      "outputs": [],
      "source": [
        "# camera-ready\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ASPP(nn.Module):\n",
        "    def __init__(self, num_classes, head = True):\n",
        "        super(ASPP, self).__init__()\n",
        "\n",
        "        self.conv_1x1_1 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_1 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "        self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_2 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "        self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_3 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "        self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.conv_1x1_2 = nn.Conv2d(512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1) # (1280 = 5*256)\n",
        "        self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        if head:\n",
        "            self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "        self.head = head\n",
        "\n",
        "    def forward(self, feature_map):\n",
        "        # (feature_map has shape (batch_size, 512, h/16, w/16)) (assuming self.resnet is ResNet18_OS16 or ResNet34_OS16. If self.resnet instead is ResNet18_OS8 or ResNet34_OS8, it will be (batch_size, 512, h/8, w/8))\n",
        "        #print(f\"Shape of feature_map: {feature_map.shape}\")\n",
        "\n",
        "        feature_map_h = feature_map.size()[2] # (== h/16)\n",
        "        feature_map_w = feature_map.size()[3] # (== w/16)\n",
        "\n",
        "        out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_1x1: {out_1x1.shape}\")\n",
        "        out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_1: {out_3x3_1.shape}\")\n",
        "        out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_2: {out_3x3_2.shape}\")\n",
        "        out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_3: {out_3x3_3.shape}\")\n",
        "\n",
        "        out_img = self.avg_pool(feature_map) # (shape: (batch_size, 512, 1, 1))\n",
        "        #print(f\"Shape of out_img after avg_pool: {out_img.shape}\")\n",
        "        out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img))) # (shape: (batch_size, 256, 1, 1))\n",
        "        #print(f\"Shape of out_img after conv_1x1_2: {out_img.shape}\")\n",
        "        out_img = F.interpolate(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\") # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_img after interpolate: {out_img.shape}\")\n",
        "\n",
        "        out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1) # (shape: (batch_size, 1280, h/16, w/16))\n",
        "        #print(f\"Shape of out after concatenation: {out.shape}\")\n",
        "        out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out after conv_1x1_3: {out.shape}\")\n",
        "        if self.head:\n",
        "            out = self.conv_1x1_4(out) # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "            #print(f\"Shape of out after conv_1x1_4 (head): {out.shape}\")\n",
        "\n",
        "        return out\n",
        "\n",
        "class ASPP_Bottleneck(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(ASPP_Bottleneck, self).__init__()\n",
        "\n",
        "        self.conv_1x1_1 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_1 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=6, dilation=6)\n",
        "        self.bn_conv_3x3_1 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_2 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=12, dilation=12)\n",
        "        self.bn_conv_3x3_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_3x3_3 = nn.Conv2d(4*512, 256, kernel_size=3, stride=1, padding=18, dilation=18)\n",
        "        self.bn_conv_3x3_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.conv_1x1_2 = nn.Conv2d(4*512, 256, kernel_size=1)\n",
        "        self.bn_conv_1x1_2 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_3 = nn.Conv2d(1280, 256, kernel_size=1) # (1280 = 5*256)\n",
        "        self.bn_conv_1x1_3 = nn.BatchNorm2d(256)\n",
        "\n",
        "        self.conv_1x1_4 = nn.Conv2d(256, num_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, feature_map):\n",
        "        # (feature_map has shape (batch_size, 4*512, h/16, w/16))\n",
        "        #print(f\"Shape of feature_map: {feature_map.shape}\")\n",
        "\n",
        "        feature_map_h = feature_map.size()[2] # (== h/16)\n",
        "        feature_map_w = feature_map.size()[3] # (== w/16)\n",
        "\n",
        "        out_1x1 = F.relu(self.bn_conv_1x1_1(self.conv_1x1_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_1x1: {out_1x1.shape}\")\n",
        "        out_3x3_1 = F.relu(self.bn_conv_3x3_1(self.conv_3x3_1(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_1: {out_3x3_1.shape}\")\n",
        "        out_3x3_2 = F.relu(self.bn_conv_3x3_2(self.conv_3x3_2(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_2: {out_3x3_2.shape}\")\n",
        "        out_3x3_3 = F.relu(self.bn_conv_3x3_3(self.conv_3x3_3(feature_map))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_3x3_3: {out_3x3_3.shape}\")\n",
        "\n",
        "        out_img = self.avg_pool(feature_map) # (shape: (batch_size, 512, 1, 1))\n",
        "        #print(f\"Shape of out_img after avg_pool: {out_img.shape}\")\n",
        "        out_img = F.relu(self.bn_conv_1x1_2(self.conv_1x1_2(out_img))) # (shape: (batch_size, 256, 1, 1))\n",
        "        #print(f\"Shape of out_img after conv_1x1_2: {out_img.shape}\")\n",
        "        out_img = F.interpolate(out_img, size=(feature_map_h, feature_map_w), mode=\"bilinear\") # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out_img after interpolate: {out_img.shape}\")\n",
        "\n",
        "        out = torch.cat([out_1x1, out_3x3_1, out_3x3_2, out_3x3_3, out_img], 1) # (shape: (batch_size, 1280, h/16, w/16))\n",
        "        #print(f\"Shape of out after concatenation: {out.shape}\")\n",
        "        out = F.relu(self.bn_conv_1x1_3(self.conv_1x1_3(out))) # (shape: (batch_size, 256, h/16, w/16))\n",
        "        #print(f\"Shape of out after conv_1x1_3: {out.shape}\")\n",
        "        out = self.conv_1x1_4(out) # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "        #print(f\"Shape of out after conv_1x1_4: {out.shape}\")\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YCLcdf0B9UPN"
      },
      "source": [
        "## DeepLabV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVGsTLZxklEK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import sys\n",
        "# sys.path.insert(0, '../')\n",
        "\n",
        "# from Ours.resnet import ResNet18_OS16, ResNet34_OS16, ResNet50_OS16, ResNet101_OS16, ResNet152_OS16, ResNet18_OS8, ResNet34_OS8\n",
        "# from Ours.ASPP import ASPP, ASPP_Bottleneck\n",
        "\n",
        "# class DeepLabV3(nn.Module): | \"DeepLabV3\" is called as \"base\" in the BAT class\n",
        "# class base(nn.Module):\n",
        "#     def __init__(self, num_classes, num_layers):\n",
        "#         super(base, self).__init__()\n",
        "\n",
        "#         self.num_classes = num_classes\n",
        "#         layers = num_layers\n",
        "#         # NOTE! specify the type of ResNet here\n",
        "#         # NOTE! if you use ResNet50-152, set self.aspp = ASPP_Bottleneck(num_classes=self.num_classes) instead\n",
        "#         if layers == 18:\n",
        "#             self.resnet = ResNet18_OS16()\n",
        "#             self.aspp = ASPP(num_classes=self.num_classes)\n",
        "#         elif layers == 50:\n",
        "#             self.resnet = ResNet50_OS16()\n",
        "#             self.aspp = ASPP_Bottleneck(num_classes=self.num_classes)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # (x has shape (batch_size, 3, h, w))\n",
        "#         h = x.size()[2]\n",
        "#         w = x.size()[3]\n",
        "#         feature_map = self.resnet(x)\n",
        "\n",
        "#         # (shape: (batch_size, 512, h/16, w/16)) (assuming self.resnet is ResNet18_OS16 or ResNet34_OS16.\n",
        "#         # If self.resnet is ResNet18_OS8 or ResNet34_OS8, it will be (batch_size, 512, h/8, w/8).\n",
        "#         # If self.resnet is ResNet50-152, it will be (batch_size, 4*512, h/16, w/16))\n",
        "#         output = self.aspp(\n",
        "#             feature_map)  # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "#         output = F.upsample(\n",
        "#             output, size=(h, w),\n",
        "#             mode=\"bilinear\")  # (shape: (batch_size, num_classes, h, w))\n",
        "#         return output\n",
        "\n",
        "# -------------------------------------------------------------------\n",
        "# The \"base\" model acts like a DeepLabV3 backbone.\n",
        "# It instantiates a segmentation network using a ResNet backbone (with OS16)\n",
        "# plus an ASPP module. (Ensure that ASPP and ASPP_Bottleneck are defined/imported.)\n",
        "# -------------------------------------------------------------------\n",
        "class base(nn.Module):\n",
        "    def __init__(self, num_classes, num_layers):\n",
        "        super(base, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        layers = num_layers\n",
        "\n",
        "        if layers == 18:\n",
        "            self.resnet = ResNet18_OS16()\n",
        "            self.aspp = ASPP(num_classes=self.num_classes)  # ASPP for BasicBlock variant\n",
        "        elif layers == 50:\n",
        "            self.resnet = ResNet50_OS16()\n",
        "            self.aspp = ASPP_Bottleneck(num_classes=self.num_classes)  # ASPP_Bottleneck for Bottleneck variant\n",
        "        else:\n",
        "            raise ValueError(\"Only 18 and 50 are supported in this example.\")\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x is of shape (batch_size, 3, h, w)\n",
        "        h, w = x.size(2), x.size(3)\n",
        "        feature_map = self.resnet(x)  # Expected shape: [B, C, h/16, w/16]\n",
        "        # Process through the ASPP module:\n",
        "        output = self.aspp(feature_map)  # Expected shape: (batch_size, num_classes, h/16, w/16)\n",
        "        # Upsample the output to original image resolution.\n",
        "        output = F.interpolate(output, size=(h, w), mode=\"bilinear\", align_corners=False)\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZWZ7jTw9UPO"
      },
      "source": [
        "## Base Transformer (BAT class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6jR8NwS9UPO"
      },
      "outputs": [],
      "source": [
        "import sys, os\n",
        "\n",
        "# root_path = os.path.join(os.path.dirname(os.path.abspath(__file__)), '..')\n",
        "# sys.path.insert(0, os.path.join(root_path))\n",
        "# sys.path.insert(0, os.path.join(root_path, 'lib'))\n",
        "# sys.path.insert(0, os.path.join(root_path, 'lib/Cell_DETR_master'))\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# from Ours.base import DeepLabV3 as base\n",
        "\n",
        "# from src.BAT_Modules import BoundaryCrossAttention, CrossAttention\n",
        "# from src.BAT_Modules import MultiHeadAttention as Attention_head\n",
        "# from src.transformer import BoundaryAwareTransformer, Transformer\n",
        "\n",
        "\n",
        "class BAT(nn.Module):\n",
        "    def __init__(\n",
        "            self,\n",
        "            num_classes,\n",
        "            num_layers,\n",
        "            point_pred,\n",
        "            decoder=False,\n",
        "            transformer_type_index=0,\n",
        "            hidden_features=128,  # 256\n",
        "            number_of_query_positions=1,\n",
        "            segmentation_attention_heads=8):\n",
        "\n",
        "        super(BAT, self).__init__()\n",
        "\n",
        "        self.num_classes = num_classes\n",
        "        self.point_pred = point_pred\n",
        "        self.transformer_type = \"BoundaryAwareTransformer\" if transformer_type_index == 0 else \"Transformer\"\n",
        "        self.use_decoder = decoder\n",
        "\n",
        "        self.deeplab = base(num_classes, num_layers)\n",
        "\n",
        "        in_channels = 2048 if num_layers == 50 else 512\n",
        "\n",
        "        self.convolution_mapping = nn.Conv2d(in_channels=in_channels,\n",
        "                                             out_channels=hidden_features,\n",
        "                                             kernel_size=(1, 1),\n",
        "                                             stride=(1, 1),\n",
        "                                             padding=(0, 0),\n",
        "                                             bias=True)\n",
        "\n",
        "        self.query_positions = nn.Parameter(data=torch.randn(\n",
        "            number_of_query_positions, hidden_features, dtype=torch.float),\n",
        "                                            requires_grad=True)\n",
        "\n",
        "        self.row_embedding = nn.Parameter(data=torch.randn(100,\n",
        "                                                           hidden_features //\n",
        "                                                           2,\n",
        "                                                           dtype=torch.float),\n",
        "                                          requires_grad=True)\n",
        "        self.column_embedding = nn.Parameter(data=torch.randn(\n",
        "            100, hidden_features // 2, dtype=torch.float),\n",
        "                                             requires_grad=True)\n",
        "\n",
        "        self.transformer = [\n",
        "            Transformer(d_model=hidden_features),\n",
        "            BoundaryAwareTransformer(d_model=hidden_features)\n",
        "        ][point_pred]\n",
        "\n",
        "        if self.use_decoder:\n",
        "            self.BCA = BoundaryCrossAttention(hidden_features, 8)\n",
        "\n",
        "        self.trans_out_conv = nn.Conv2d(in_channels=hidden_features,\n",
        "                                        out_channels=in_channels,\n",
        "                                        kernel_size=(1, 1),\n",
        "                                        stride=(1, 1),\n",
        "                                        padding=(0, 0),\n",
        "                                        bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = x.size()[2]\n",
        "        w = x.size()[3]\n",
        "        feature_map = self.deeplab.resnet(x)\n",
        "\n",
        "        features = self.convolution_mapping(feature_map)\n",
        "        height, width = features.shape[2:]\n",
        "        batch_size = features.shape[0]\n",
        "        positional_embeddings = torch.cat([\n",
        "            self.column_embedding[:height].unsqueeze(dim=0).repeat(\n",
        "                height, 1, 1),\n",
        "            self.row_embedding[:width].unsqueeze(dim=1).repeat(1, width, 1)\n",
        "        ],\n",
        "                                          dim=-1).permute(\n",
        "                                              2, 0, 1).unsqueeze(0).repeat(\n",
        "                                                  batch_size, 1, 1, 1)\n",
        "\n",
        "        if self.transformer_type == 'BoundaryAwareTransformer':\n",
        "            latent_tensor, features_encoded, point_maps = self.transformer(\n",
        "                features, None, self.query_positions, positional_embeddings)\n",
        "        else:\n",
        "            latent_tensor, features_encoded = self.transformer(\n",
        "                features, None, self.query_positions, positional_embeddings)\n",
        "            point_maps = []\n",
        "\n",
        "        latent_tensor = latent_tensor.permute(2, 0, 1)\n",
        "        # shape:(bs, 1 , 128)\n",
        "\n",
        "        if self.use_decoder:\n",
        "            features_encoded, point_dec = self.BCA(features_encoded,\n",
        "                                                   latent_tensor)\n",
        "            point_maps.append(point_dec)\n",
        "\n",
        "        trans_feature_maps = self.trans_out_conv(\n",
        "            features_encoded.contiguous())  #.contiguous()\n",
        "\n",
        "        trans_feature_maps = trans_feature_maps + feature_map\n",
        "\n",
        "        output = self.deeplab.aspp(\n",
        "            trans_feature_maps\n",
        "        )  # (shape: (batch_size, num_classes, h/16, w/16))\n",
        "        output = F.interpolate(\n",
        "            output, size=(h, w),\n",
        "            mode=\"bilinear\")  # (shape: (batch_size, num_classes, h, w))\n",
        "\n",
        "        if self.point_pred == 1:\n",
        "            return output, point_maps\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIIdw0tLK2S4"
      },
      "source": [
        "## 2. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svv3B6UJ9UPP"
      },
      "outputs": [],
      "source": [
        "model = BAT(1, parse_config.net_layer, parse_config.point_pred,\n",
        "                    parse_config.ppl).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ag6qGuR9UPP"
      },
      "source": [
        "### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20fGhStqikfl"
      },
      "outputs": [],
      "source": [
        "# Based on: https://github.com/facebookresearch/detr/blob/master/models/transformer.py\n",
        "import copy\n",
        "from typing import Optional, List\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, Tensor\n",
        "\n",
        "# from .BAT_Modules import BoundaryWiseAttentionGate2D, BoundaryWiseAttentionGate1D, BoundaryWiseAttentionGateAtrous2D, BoundaryWiseAttentionGateAtrous1D\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model=512,\n",
        "                 nhead=8,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=2,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False,\n",
        "                 return_intermediate_dec=False):\n",
        "        super().__init__()\n",
        "\n",
        "        encoder_layer = TransformerEncoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n",
        "        self.encoder = TransformerEncoder(encoder_layer, num_encoder_layers,\n",
        "                                          encoder_norm)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        decoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            decoder_layer,\n",
        "            num_decoder_layers,\n",
        "            decoder_norm,\n",
        "            return_intermediate=return_intermediate_dec)\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, mask, query_embed, pos_embed):\n",
        "        bs, c, h, w = src.shape\n",
        "        src = src.flatten(2).permute(2, 0, 1)\n",
        "        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n",
        "        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
        "        if mask is not None:\n",
        "            mask = mask.flatten(1)\n",
        "\n",
        "        tgt = torch.zeros_like(query_embed)\n",
        "        memory = self.encoder(src, src_key_padding_mask=mask, pos=pos_embed)\n",
        "        #         print(\"Trans Encoder\",memory.shape)\n",
        "        hs = self.decoder(tgt,\n",
        "                          memory,\n",
        "                          memory_key_padding_mask=mask,\n",
        "                          pos=pos_embed,\n",
        "                          query_pos=query_embed)\n",
        "        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h, w)\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 point_pred_layers=6,\n",
        "                 d_model=512,\n",
        "                 nhead=8,\n",
        "                 num_encoder_layers=6,\n",
        "                 num_decoder_layers=2,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False,\n",
        "                 return_intermediate_dec=False,\n",
        "                 BAG_type='2D',\n",
        "                 Atrous=False):\n",
        "        super().__init__()\n",
        "\n",
        "        encoder_layer = BoundaryAwareTransformerEncoderLayer(\n",
        "            d_model, nhead, BAG_type, Atrous, dim_feedforward, dropout,\n",
        "            activation, normalize_before)\n",
        "        encoder_norm = nn.LayerNorm(d_model) if normalize_before else None\n",
        "        self.encoder = BoundaryAwareTransformerEncoder(point_pred_layers,\n",
        "                                                       encoder_layer,\n",
        "                                                       num_encoder_layers,\n",
        "                                                       encoder_norm)\n",
        "        decoder_layer = TransformerDecoderLayer(d_model, nhead,\n",
        "                                                dim_feedforward, dropout,\n",
        "                                                activation, normalize_before)\n",
        "        decoder_norm = nn.LayerNorm(d_model)\n",
        "        self.decoder = TransformerDecoder(\n",
        "            decoder_layer,\n",
        "            num_decoder_layers,\n",
        "            decoder_norm,\n",
        "            return_intermediate=return_intermediate_dec)\n",
        "        self._reset_parameters()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.nhead = nhead\n",
        "\n",
        "    def _reset_parameters(self):\n",
        "        for p in self.parameters():\n",
        "            if p.dim() > 1:\n",
        "                nn.init.xavier_uniform_(p)\n",
        "\n",
        "    def forward(self, src, mask, query_embed, pos_embed):\n",
        "        bs, c, h, w = src.shape\n",
        "        src = src.flatten(2).permute(2, 0, 1)\n",
        "        pos_embed = pos_embed.flatten(2).permute(2, 0, 1)\n",
        "        query_embed = query_embed.unsqueeze(1).repeat(1, bs, 1)\n",
        "        if mask is not None:\n",
        "            mask = mask.flatten(1)\n",
        "\n",
        "        tgt = torch.zeros_like(query_embed)\n",
        "        memory, weights = self.encoder(src,\n",
        "                                       src_key_padding_mask=mask,\n",
        "                                       pos=pos_embed,\n",
        "                                       height=h,\n",
        "                                       width=w)\n",
        "\n",
        "        hs = self.decoder(tgt,\n",
        "                          memory,\n",
        "                          memory_key_padding_mask=mask,\n",
        "                          pos=pos_embed,\n",
        "                          query_pos=query_embed)\n",
        "        return hs.transpose(1, 2), memory.permute(1, 2, 0).view(bs, c, h,\n",
        "                                                                w), weights\n",
        "\n",
        "\n",
        "class TransformerEncoder(nn.Module):\n",
        "    def __init__(self, encoder_layer, num_layers, norm=None):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None):\n",
        "        output = src\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output,\n",
        "                           src_mask=mask,\n",
        "                           src_key_padding_mask=src_key_padding_mask,\n",
        "                           pos=pos)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformerEncoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 point_pred_layers,\n",
        "                 encoder_layer,\n",
        "                 num_layers,\n",
        "                 norm=None):\n",
        "        super().__init__()\n",
        "        self.point_pred_layers = point_pred_layers\n",
        "        self.layers = _get_clones(encoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                height: int = 32,\n",
        "                width: int = 32):\n",
        "        output = src\n",
        "        weights = []\n",
        "\n",
        "        for layer_i, layer in enumerate(self.layers):\n",
        "            if layer_i > self.num_layers - self.point_pred_layers - 1:\n",
        "                output, weight = layer(\n",
        "                    True,\n",
        "                    output,\n",
        "                    src_mask=mask,\n",
        "                    src_key_padding_mask=src_key_padding_mask,\n",
        "                    pos=pos,\n",
        "                    height=height,\n",
        "                    width=width)\n",
        "                weights.append(weight)\n",
        "            else:\n",
        "                output = layer(False,\n",
        "                               output,\n",
        "                               src_mask=mask,\n",
        "                               src_key_padding_mask=src_key_padding_mask,\n",
        "                               pos=pos,\n",
        "                               height=height,\n",
        "                               width=width)\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "\n",
        "        return output, weights\n",
        "\n",
        "\n",
        "class TransformerEncoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation()\n",
        "        self.normalize_before = normalize_before\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "\n",
        "    def forward_post(self,\n",
        "                     src,\n",
        "                     src_mask: Optional[Tensor] = None,\n",
        "                     src_key_padding_mask: Optional[Tensor] = None,\n",
        "                     pos: Optional[Tensor] = None):\n",
        "        q = k = self.with_pos_embed(src, pos)\n",
        "        src2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=src,\n",
        "                              attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src = self.norm1(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        src = self.norm2(src)\n",
        "        return src\n",
        "\n",
        "    def forward_pre(self,\n",
        "                    src,\n",
        "                    src_mask: Optional[Tensor] = None,\n",
        "                    src_key_padding_mask: Optional[Tensor] = None,\n",
        "                    pos: Optional[Tensor] = None):\n",
        "        src2 = self.norm1(src)\n",
        "        q = k = self.with_pos_embed(src2, pos)\n",
        "        src2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=src2,\n",
        "                              attn_mask=src_mask,\n",
        "                              key_padding_mask=src_key_padding_mask)[0]\n",
        "        src = src + self.dropout1(src2)\n",
        "        src2 = self.norm2(src)\n",
        "        src2 = self.linear2(self.dropout(self.activation(self.linear1(src2))))\n",
        "        src = src + self.dropout2(src2)\n",
        "        return src\n",
        "\n",
        "    def forward(self,\n",
        "                src,\n",
        "                src_mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None):\n",
        "        if self.normalize_before:\n",
        "            return self.forward_pre(src, src_mask, src_key_padding_mask, pos)\n",
        "        return self.forward_post(src, src_mask, src_key_padding_mask, pos)\n",
        "\n",
        "\n",
        "class BoundaryAwareTransformerEncoderLayer(TransformerEncoderLayer):\n",
        "    \"    Add Boundary-wise Attention Gate to Transformer's Encoder\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 BAG_type='2D',\n",
        "                 Atrous=True,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__(d_model, nhead, dim_feedforward, dropout, activation,\n",
        "                         normalize_before)\n",
        "        if BAG_type == '1D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous1D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate1D(d_model)\n",
        "        elif BAG_type == '2D':\n",
        "            if Atrous:\n",
        "                self.BAG = BoundaryWiseAttentionGateAtrous2D(d_model)\n",
        "            else:\n",
        "                self.BAG = BoundaryWiseAttentionGate2D(d_model)\n",
        "        self.BAG_type = BAG_type\n",
        "\n",
        "    def forward(self,\n",
        "                use_bag,\n",
        "                src,\n",
        "                src_mask: Optional[Tensor] = None,\n",
        "                src_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                height: int = 32,\n",
        "                width: int = 32):\n",
        "        if self.normalize_before:\n",
        "            features = self.forward_pre(src, src_mask, src_key_padding_mask,\n",
        "                                        pos)\n",
        "            if use_bag:\n",
        "                b, c = features.shape[1:]\n",
        "                if self.BAG_type == '1D':\n",
        "                    features = features.permute(1, 2, 0)\n",
        "                    features, weights = self.BAG(features)\n",
        "                    features = features.permute(2, 0, 1).contiguous()\n",
        "                    weights = weights.view(b, 1, height, width)\n",
        "                elif self.BAG_type == '2D':\n",
        "                    features = features.permute(1, 2,\n",
        "                                                0).view(b, c, height, width)\n",
        "                    features, weights = self.BAG(features)\n",
        "                    features = features.flatten(2).permute(2, 0,\n",
        "                                                           1).contiguous()\n",
        "                return features, weights\n",
        "            else:\n",
        "                return features\n",
        "        features = self.forward_post(src, src_mask, src_key_padding_mask, pos)\n",
        "        if use_bag:\n",
        "            b, c = features.shape[1:]\n",
        "            if self.BAG_type == '1D':\n",
        "                features = features.permute(1, 2, 0)\n",
        "                features, weights = self.BAG(features)\n",
        "                features = features.permute(2, 0, 1).contiguous()\n",
        "                weights = weights.view(b, 1, height, width)\n",
        "            elif self.BAG_type == '2D':\n",
        "                features = features.permute(1, 2, 0).view(b, c, height, width)\n",
        "                features, weights = self.BAG(features)\n",
        "                features = features.flatten(2).permute(2, 0, 1).contiguous()\n",
        "            return features, weights\n",
        "        else:\n",
        "            return features\n",
        "\n",
        "\n",
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 decoder_layer,\n",
        "                 num_layers,\n",
        "                 norm=None,\n",
        "                 return_intermediate=False):\n",
        "        super().__init__()\n",
        "        self.layers = _get_clones(decoder_layer, num_layers)\n",
        "        self.num_layers = num_layers\n",
        "        self.norm = norm\n",
        "        self.return_intermediate = return_intermediate\n",
        "\n",
        "    def forward(self,\n",
        "                tgt,\n",
        "                memory,\n",
        "                tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                query_pos: Optional[Tensor] = None):\n",
        "        output = tgt\n",
        "\n",
        "        intermediate = []\n",
        "\n",
        "        for layer in self.layers:\n",
        "            output = layer(output,\n",
        "                           memory,\n",
        "                           tgt_mask=tgt_mask,\n",
        "                           memory_mask=memory_mask,\n",
        "                           tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                           memory_key_padding_mask=memory_key_padding_mask,\n",
        "                           pos=pos,\n",
        "                           query_pos=query_pos)\n",
        "            if self.return_intermediate:\n",
        "                intermediate.append(self.norm(output))\n",
        "\n",
        "        if self.norm is not None:\n",
        "            output = self.norm(output)\n",
        "            if self.return_intermediate:\n",
        "                intermediate.pop()\n",
        "                intermediate.append(output)\n",
        "\n",
        "        if self.return_intermediate:\n",
        "            return torch.stack(intermediate)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 d_model,\n",
        "                 nhead,\n",
        "                 dim_feedforward=2048,\n",
        "                 dropout=0.1,\n",
        "                 activation=nn.LeakyReLU,\n",
        "                 normalize_before=False):\n",
        "        super().__init__()\n",
        "        self.self_attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout)\n",
        "        self.multihead_attn = nn.MultiheadAttention(d_model,\n",
        "                                                    nhead,\n",
        "                                                    dropout=dropout)\n",
        "        # Implementation of Feedforward model\n",
        "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "        self.dropout3 = nn.Dropout(dropout)\n",
        "\n",
        "        self.activation = activation()\n",
        "        self.normalize_before = normalize_before\n",
        "\n",
        "    def with_pos_embed(self, tensor, pos: Optional[Tensor]):\n",
        "        return tensor if pos is None else tensor + pos\n",
        "\n",
        "    def forward_post(self,\n",
        "                     tgt,\n",
        "                     memory,\n",
        "                     tgt_mask: Optional[Tensor] = None,\n",
        "                     memory_mask: Optional[Tensor] = None,\n",
        "                     tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                     memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                     pos: Optional[Tensor] = None,\n",
        "                     query_pos: Optional[Tensor] = None):\n",
        "        q = k = self.with_pos_embed(tgt, query_pos)\n",
        "        tgt2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=tgt,\n",
        "                              attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt = self.norm1(tgt)\n",
        "        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt, query_pos),\n",
        "                                   key=self.with_pos_embed(memory, pos),\n",
        "                                   value=memory,\n",
        "                                   attn_mask=memory_mask,\n",
        "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt = self.norm2(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        tgt = self.norm3(tgt)\n",
        "        return tgt\n",
        "\n",
        "    def forward_pre(self,\n",
        "                    tgt,\n",
        "                    memory,\n",
        "                    tgt_mask: Optional[Tensor] = None,\n",
        "                    memory_mask: Optional[Tensor] = None,\n",
        "                    tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                    memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                    pos: Optional[Tensor] = None,\n",
        "                    query_pos: Optional[Tensor] = None):\n",
        "        tgt2 = self.norm1(tgt)\n",
        "        q = k = self.with_pos_embed(tgt2, query_pos)\n",
        "        tgt2 = self.self_attn(q,\n",
        "                              k,\n",
        "                              value=tgt2,\n",
        "                              attn_mask=tgt_mask,\n",
        "                              key_padding_mask=tgt_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout1(tgt2)\n",
        "        tgt2 = self.norm2(tgt)\n",
        "        tgt2 = self.multihead_attn(query=self.with_pos_embed(tgt2, query_pos),\n",
        "                                   key=self.with_pos_embed(memory, pos),\n",
        "                                   value=memory,\n",
        "                                   attn_mask=memory_mask,\n",
        "                                   key_padding_mask=memory_key_padding_mask)[0]\n",
        "        tgt = tgt + self.dropout2(tgt2)\n",
        "        tgt2 = self.norm3(tgt)\n",
        "        tgt2 = self.linear2(self.dropout(self.activation(self.linear1(tgt2))))\n",
        "        tgt = tgt + self.dropout3(tgt2)\n",
        "        return tgt\n",
        "\n",
        "    def forward(self,\n",
        "                tgt,\n",
        "                memory,\n",
        "                tgt_mask: Optional[Tensor] = None,\n",
        "                memory_mask: Optional[Tensor] = None,\n",
        "                tgt_key_padding_mask: Optional[Tensor] = None,\n",
        "                memory_key_padding_mask: Optional[Tensor] = None,\n",
        "                pos: Optional[Tensor] = None,\n",
        "                query_pos: Optional[Tensor] = None):\n",
        "        if self.normalize_before:\n",
        "            return self.forward_pre(tgt, memory, tgt_mask, memory_mask,\n",
        "                                    tgt_key_padding_mask,\n",
        "                                    memory_key_padding_mask, pos, query_pos)\n",
        "        return self.forward_post(tgt, memory, tgt_mask, memory_mask,\n",
        "                                 tgt_key_padding_mask, memory_key_padding_mask,\n",
        "                                 pos, query_pos)\n",
        "\n",
        "\n",
        "def _get_clones(module, N):\n",
        "    return nn.ModuleList([copy.deepcopy(module) for i in range(N)])\n",
        "\n",
        "\n",
        "def build_transformer(args):\n",
        "    return Transformer(\n",
        "        d_model=args.hidden_dim,\n",
        "        dropout=args.dropout,\n",
        "        nhead=args.nheads,\n",
        "        dim_feedforward=args.dim_feedforward,\n",
        "        num_encoder_layers=args.enc_layers,\n",
        "        num_decoder_layers=args.dec_layers,\n",
        "        normalize_before=args.pre_norm,\n",
        "        return_intermediate_dec=True,\n",
        "    )\n",
        "\n",
        "\n",
        "def _get_activation_fn(activation):\n",
        "    \"\"\"Return an activation function given a string\"\"\"\n",
        "    if activation == \"leaky relu\":\n",
        "        return F.leaky_relu\n",
        "    if activation == \"selu\":\n",
        "        return F.selu\n",
        "    if activation == \"relu\":\n",
        "        return F.relu\n",
        "    if activation == \"gelu\":\n",
        "        return F.gelu\n",
        "    if activation == \"glu\":\n",
        "        return F.glu\n",
        "    raise RuntimeError(\n",
        "        F\"activation should be relu, gelu, glu, leaky relu or selu, not {activation}.\"\n",
        "    )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vzze2VhIK2S5"
      },
      "source": [
        "### Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbTO94ePK2S5"
      },
      "outputs": [],
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=7, mode=\"max\", delta=0.0001):\n",
        "        self.patience = patience\n",
        "        self.counter = 0\n",
        "        self.mode = mode\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.delta = delta\n",
        "        self.BEST_MODEL_PATH = \"\"\n",
        "        if self.mode == \"min\":\n",
        "            self.val_score = np.inf\n",
        "        else:\n",
        "            self.val_score = -np.inf\n",
        "\n",
        "    def __call__(self, epoch, epoch_score, model, optimizer, loss, model_path):\n",
        "        if self.mode == \"min\":\n",
        "            score = -1.0 * epoch_score\n",
        "        else:\n",
        "            score = np.copy(epoch_score)\n",
        "\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(epoch, epoch_score, model, optimizer, loss, model_path)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            print(\n",
        "                \"EarlyStopping counter: {} out of {}\".format(\n",
        "                    self.counter, self.patience\n",
        "                )\n",
        "            )\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(epoch, epoch_score, model, optimizer, loss, model_path)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, epoch, epoch_score, model, optimizer, loss, model_path):\n",
        "        model_path = Path(model_path)\n",
        "        parent = model_path.parent\n",
        "        os.makedirs(parent, exist_ok=True)\n",
        "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\n",
        "            print(\n",
        "                \"Validation score improved ({} --> {}). Model saved at {}!\".format(\n",
        "                    self.val_score, epoch_score, model_path\n",
        "                )\n",
        "            )\n",
        "            torch.save({\"Epoch\": epoch, \"Train Loss\": loss, \"Validation Dice Score\": self.val_score, \"model_state_dict\": model.state_dict(), \"optimizer_state_dict\": optimizer.state_dict()}, model_path)\n",
        "            self.BEST_MODEL_PATH = model_path\n",
        "            print(f\"Checkpoint saved on epoch - {epoch} with dice score - {epoch_score}\")\n",
        "        self.val_score = epoch_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JwQu_LDS9UPS"
      },
      "outputs": [],
      "source": [
        "criterion = CRITERION\n",
        "es = EarlyStopping(patience=EARLY_STOPPING_PATIENCE, mode='max')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOlM9jTEK2S5"
      },
      "source": [
        "### Training Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_amog1GHK2S5"
      },
      "outputs": [],
      "source": [
        "class AverageMeter:\n",
        "    def __init__(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xbn3pKTaK2S5"
      },
      "outputs": [],
      "source": [
        "def train_one_epoch(train_loader, model, optimizer, loss_fn, epoch, accumulation_steps=int(EFFECTIVE_BATCH_SIZE/BATCH_SIZE), device='cuda'):\n",
        "    losses = AverageMeter()\n",
        "    # Lists to store batch-to-batch progress details within the epoch while training\n",
        "    batch_count_train = []\n",
        "    batch_train_loss = []\n",
        "\n",
        "    model = model.to(device)\n",
        "    model.train()\n",
        "    if accumulation_steps > 1:\n",
        "      optimizer.zero_grad()\n",
        "    tk0 = tqdm(train_loader, total=len(train_loader))\n",
        "    for b_idx, data in enumerate(tk0):\n",
        "      #print(data['image'].shape) # print(data['image'].shape) -> torch.Size([8, 3, 512, 512])\n",
        "      #print(data['mask'].shape) # print(data['mask'].shape) -> torch.Size([8, 1, 512, 512])\n",
        "      if (b_idx + 1) % accumulation_steps == 0:\n",
        "        batch_count_train.append(b_idx)\n",
        "\n",
        "      # moves image tensor and mask tensor to gpu\n",
        "      for key, value in data.items():\n",
        "        data[key] = value.to(\"cuda\")\n",
        "      point = (data['point'] > 0).cuda().float()\n",
        "\n",
        "      if parse_config.net_layer == 18:\n",
        "          point_c4 = nn.functional.max_pool2d(point,\n",
        "                                              kernel_size=(16, 16),\n",
        "                                              stride=(16, 16))\n",
        "          point = nn.functional.max_pool2d(point,\n",
        "                                          kernel_size=(8, 8),\n",
        "                                          stride=(8, 8))\n",
        "      else:\n",
        "          point_c5 = nn.functional.max_pool2d(point,\n",
        "                                              kernel_size=(32, 32),\n",
        "                                              stride=(32, 32))\n",
        "\n",
        "          point_c4 = nn.functional.max_pool2d(point,\n",
        "                                              kernel_size=(16, 16),\n",
        "                                              stride=(16, 16))\n",
        "\n",
        "      if accumulation_steps == 1 and b_idx == 0:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "      if parse_config.point_pred == 1:\n",
        "            output, point_maps_pre = model(data['image'])\n",
        "            output = torch.sigmoid(output)\n",
        "\n",
        "            #print(\"point_maps_pre[-1] shape:{}, point_c4 shape:{}\".format(point_maps_pre[-1].shape,point_c4.shape))\n",
        "            assert (output.shape == data['mask'].float().shape)\n",
        "            loss_dc = dice_loss(output, data['mask'].float())\n",
        "            #print(point_maps_pre[-1].shape, point_c4.shape)\n",
        "            assert (point_maps_pre[-1].shape == point_c4.shape)\n",
        "\n",
        "            point_loss = 0.\n",
        "            for i in range(len(point_maps_pre)):\n",
        "                point_loss += criterion(point_maps_pre[i], point_c4)\n",
        "            point_loss = point_loss / len(point_maps_pre)\n",
        "\n",
        "            loss = loss_dc + point_loss  # point_loss weight: 3\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "              loss.backward()\n",
        "              # if (b_idx + 1) % accumulation_steps == 0:\n",
        "              #   if GRADIENT_CLIPPING:\n",
        "              #     clip_grad_norm_(model.parameters(), GRADIENT_CLIPPING_THRESHOLD)\n",
        "              optimizer.step()\n",
        "              optimizer.zero_grad()\n",
        "      ###############################################################################################\n",
        "      # out  = model(data['image']) # out.shape = torch.Size([8, 1, 512, 512])\n",
        "      # loss = loss_fn(out, data['mask'].float()) # mask.shape = torch.Size([8, 1, 512, 512])\n",
        "      # with torch.set_grad_enabled(True):\n",
        "      #   loss.backward()\n",
        "      #   if (b_idx + 1) % accumulation_steps == 0:\n",
        "      #     if GRADIENT_CLIPPING:\n",
        "      #       clip_grad_norm_(model.parameters(), GRADIENT_CLIPPING_THRESHOLD)\n",
        "      #     optimizer.step()\n",
        "      #     optimizer.zero_grad()\n",
        "      losses.update(loss.item(), train_loader.batch_size)\n",
        "      if (b_idx + 1) % accumulation_steps == 0:\n",
        "        batch_train_loss.append(loss.item())\n",
        "      tk0.set_postfix(loss=losses.avg, learning_rate=optimizer.param_groups[0]['lr'])\n",
        "    return losses.avg, batch_count_train, batch_train_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "id": "FKL6S336-unk",
        "outputId": "21eeeeac-c22b-4c26-9e29-7d6ea31672ef"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>focal_loss</b><br/>def focal_loss(inputs: torch.Tensor, targets: torch.Tensor, alpha: float=0.6, gamma: float=2, reduction: str=&#x27;mean&#x27;) -&gt; torch.Tensor</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-16-defc6de845ef&gt;</a>&lt;no docstring&gt;</pre></div>"
            ],
            "text/plain": [
              "<function __main__.focal_loss(inputs: torch.Tensor, targets: torch.Tensor, alpha: float = 0.6, gamma: float = 2, reduction: str = 'mean') -> torch.Tensor>"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "criterion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K136b3eqK2S5"
      },
      "source": [
        "### Validation Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N1RY2NxC-unk"
      },
      "source": [
        "#### Mask Binarizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4my02Uf-unk"
      },
      "outputs": [],
      "source": [
        "class MaskBinarization():\n",
        "    def __init__(self):\n",
        "        self.thresholds = 0.5\n",
        "    def transform(self, predicted):\n",
        "        yield predicted > self.thresholds\n",
        "\n",
        "class SimpleMaskBinarization(MaskBinarization):\n",
        "    def __init__(self, score_thresholds):\n",
        "        super().__init__()\n",
        "        self.thresholds = score_thresholds\n",
        "    def transform(self, predicted):\n",
        "        for thr in self.thresholds:\n",
        "            yield predicted > thr\n",
        "\n",
        "class DupletMaskBinarization(MaskBinarization):\n",
        "    def __init__(self, duplets, with_channels=True):\n",
        "        super().__init__()\n",
        "        self.thresholds = duplets\n",
        "        self.dims = (2,3) if with_channels else (1,2)\n",
        "    def transform(self, predicted):\n",
        "        for score_threshold, area_threshold in self.thresholds:\n",
        "            mask = predicted > score_threshold\n",
        "            mask[mask.sum(dim=self.dims) < area_threshold] = 0\n",
        "            yield mask\n",
        "\n",
        "class TripletMaskBinarization(MaskBinarization):\n",
        "    def __init__(self, triplets, with_channels=True):\n",
        "        super().__init__()\n",
        "        self.thresholds = triplets\n",
        "        self.dims = (2,3) if with_channels else (1,2) # dims should be HxW, basically it should ignore batch_size and no_of_channels in the general format of BxCxHxW\n",
        "    def transform(self, predicted):\n",
        "        for top_score_threshold, area_threshold, bottom_score_threshold in self.thresholds:\n",
        "            clf_mask = (predicted > top_score_threshold).float()\n",
        "            pred_mask = (predicted > bottom_score_threshold).float()\n",
        "            pred_mask[clf_mask.sum(dim=self.dims) < area_threshold] = 0\n",
        "            yield pred_mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joGnfZgw-unl"
      },
      "source": [
        "#### Metric used in validation and evaluate function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zlWOcwQdK2S5"
      },
      "outputs": [],
      "source": [
        "def metric(probability, truth):\n",
        "    probability = torch.from_numpy(probability)\n",
        "    truth = torch.from_numpy(truth)\n",
        "    # print(probability.shape, truth.shape)\n",
        "    if probability.shape[0] == truth.shape[0]: # checking for batch size mismatches in the code for image & mask\n",
        "        batch_size = probability.shape[0]\n",
        "    with torch.no_grad():\n",
        "        probability = probability.view(batch_size, -1) # probability's size is [8, 1*512*512]\n",
        "        truth = truth.view(batch_size, -1)             # truth's size is [8, 1*512*512]\n",
        "        assert(probability.shape == truth.shape)\n",
        "\n",
        "        p = probability.float() # prob_preds already comes in binarized.\n",
        "        t = (truth > 0.5).float()\n",
        "\n",
        "        t_sum = t.sum(-1) # t_sum size is 8 # Each value in the vector represents the sum of all pixels in one mask\n",
        "        p_sum = p.sum(-1) # p_sum size is 8 # Each value in the vector represents the sum of all elements in one pred_probs\n",
        "        neg_index = torch.nonzero(t_sum == 0) # indices of masks which are negative.\n",
        "        pos_index = torch.nonzero(t_sum >= 1) # indices of masks which are positive.\n",
        "\n",
        "        dice_neg = (p_sum == 0).float() # tensor of size 8\n",
        "        \"\"\"\n",
        "        if t_sum = torch.tensor([0.0, 1000.0, 0.0, 600.0, 720.0, 420.0, 0.0, 0.0]), then dice_neg = tensor([1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0])\n",
        "        \"\"\"\n",
        "        dice_pos = 2 * (p*t).sum(-1)/((p+t).sum(-1)) # tensor of size 8\n",
        "\n",
        "        dice_neg = dice_neg[neg_index] # selects elements of dice_neg acc to the indices in neg_index, it can have more than one element.\n",
        "        dice_pos = dice_pos[pos_index] # similar to the above code line.\n",
        "        dice = torch.cat([dice_pos, dice_neg])\n",
        "\n",
        "        num_neg = len(neg_index) # no. of negative masks in a batch\n",
        "        num_pos = len(pos_index) # no. of positive masks in a batch\n",
        "\n",
        "    return dice.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u3ovO3f9XHQt"
      },
      "outputs": [],
      "source": [
        "# Function to save the data dynamically\n",
        "def save_best_thresholds(epoch, b_idx, best_metric, best_threshold, filepath=Path(save_best_thresholds_path)):\n",
        "    # Create a dictionary of lists\n",
        "    data = {\n",
        "        'epoch': epoch,\n",
        "        'batch_number': b_idx,\n",
        "        'best_metric': best_metric,\n",
        "        'best_threshold': best_threshold\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Save DataFrame to CSV (mode='w' to write from scratch each time, mode='a' to append)\n",
        "    df.to_csv(filepath, index=False, mode='w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7opE5TuMRCvg"
      },
      "outputs": [],
      "source": [
        "epoch_count_thr = []\n",
        "batch_indices = []\n",
        "best_metrics_list = []\n",
        "best_thresholds_list = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww6ftfKmK2S5"
      },
      "outputs": [],
      "source": [
        "def evaluate(valid_loader, model, epoch, device=DEVICE, metric=metric, loss_fn=criterion):\n",
        "    losses = AverageMeter()\n",
        "    combolosses = AverageMeter()\n",
        "    metrics = defaultdict(float)\n",
        "    # Lists to store batch-to-batch progress details within the epoch while training\n",
        "    batch_count_val = []\n",
        "    batch_val_loss_values = []\n",
        "################################# top\n",
        "    dice_value = 0\n",
        "    iou_value = 0\n",
        "    dice_average = 0\n",
        "    iou_average = 0\n",
        "    numm = 0\n",
        "################################# bottom\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "    tk0 = tqdm(valid_loader, total=len(valid_loader))\n",
        "    with torch.inference_mode():\n",
        "        for b_idx, input_data in enumerate(tk0):\n",
        "            batch_count_val.append(b_idx)\n",
        "################################################################################ top\n",
        "            data = input_data['image'].cuda().float()\n",
        "            label = input_data['mask'].cuda().float()\n",
        "            point = (input_data['point'] > 0).cuda().float()\n",
        "            point_c5 = nn.functional.max_pool2d(point,\n",
        "                                                kernel_size=(32, 32),\n",
        "                                                stride=(32, 32))\n",
        "            point_c4 = nn.functional.max_pool2d(point,\n",
        "                                                kernel_size=(16, 16),\n",
        "                                                stride=(16, 16))\n",
        "################################################################################### bottom\n",
        "\n",
        "#################################################################################### top\n",
        "            if parse_config.arch == 'transfuse':\n",
        "                _, _, output = model(data)\n",
        "                loss_fuse = structure_loss(output, label)\n",
        "            elif parse_config.point_pred == 0:\n",
        "                output = model(data)\n",
        "            elif parse_config.cross == 1 and parse_config.point_pred == 1:\n",
        "                output, point_maps_pre_1, point_maps_pre_2 = model(data)\n",
        "                point_loss_c4 = 0.\n",
        "                for i in range(len(point_maps_pre_1) - 1):\n",
        "                    point_loss_c4 += criterion(point_maps_pre_1[i], point_c4)\n",
        "                point_loss_c4 = 1.0 / len(point_maps_pre_1) * (\n",
        "                    point_loss_c4 + criterion(point_maps_pre_1[-1], point_c4))\n",
        "                point_loss_c5 = 0.\n",
        "                for i in range(len(point_maps_pre_2) - 1):\n",
        "                    point_loss_c5 += criterion(point_maps_pre_2[i], point_c5)\n",
        "                point_loss_c5 = 1.0 / len(point_maps_pre_2) * (\n",
        "                    point_loss_c5 + criterion(point_maps_pre_2[-1], point_c5))\n",
        "                point_loss = 0.5 * (point_loss_c4 + point_loss_c5)\n",
        "            elif parse_config.point_pred == 1:\n",
        "                output, point_maps_pre = model(data)\n",
        "                point_loss = 0.\n",
        "                for i in range(len(point_maps_pre) - 1):\n",
        "                    point_loss += criterion(point_maps_pre[i], point_c4)\n",
        "                point_loss = 1.0 / len(point_maps_pre) * (\n",
        "                    point_loss + criterion(point_maps_pre[-1], point_c4))\n",
        "\n",
        "            output = torch.sigmoid(output)\n",
        "\n",
        "            loss_dc = dice_loss(output, label)\n",
        "\n",
        "            if parse_config.arch == 'transfuse':\n",
        "                loss = loss_fuse\n",
        "            elif parse_config.arch == 'transunet':\n",
        "                loss = 0.5 * loss_dc + 0.5 * ce_loss(output, label)\n",
        "            elif parse_config.point_pred == 0:\n",
        "                loss = loss_dc\n",
        "            elif parse_config.cross == 1 and parse_config.point_pred == 1:\n",
        "                loss = loss_dc + point_loss\n",
        "            elif parse_config.point_pred == 1:\n",
        "                loss = loss_dc + 3 * point_loss\n",
        "\n",
        "            output = output.cpu().numpy() > 0.5\n",
        "\n",
        "            label = label.cpu().numpy()\n",
        "            assert (output.shape == label.shape)\n",
        "            dice_ave = metric(output, label)\n",
        "            # iou_ave = jc(output, label)\n",
        "            dice_value += dice_ave\n",
        "            # iou_value += iou_ave\n",
        "            numm += 1\n",
        "\n",
        "            tk0.set_description('score: {:.5f}'.format(dice_ave))\n",
        "\n",
        "            epoch_count_thr.append(epoch)\n",
        "            batch_indices.append(b_idx)\n",
        "            best_metrics_list.append(dice_ave)\n",
        "\n",
        "            # if .item() is used then .cpu() is NOT required. .item() will itself return a float value.\n",
        "            losses.update(dice_ave, valid_loader.batch_size)\n",
        "            combolosses.update(loss.item(), valid_loader.batch_size)\n",
        "            batch_val_loss_values.append(loss.item())\n",
        "            tk0.set_postfix(dice_score=losses.avg, val_loss=combolosses.avg)\n",
        "    dice_average = dice_value / numm\n",
        "    # iou_average = iou_value / numm\n",
        "    print(\"Average dice value of evaluation dataset = \", dice_average)\n",
        "    # print(\"Average iou value of evaluation dataset = \", iou_average)\n",
        "    return losses.avg, batch_count_val, batch_val_loss_values, combolosses.avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE7TO5J9XHQt"
      },
      "source": [
        "### Optimizer & Scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGkO2pA_9UPW"
      },
      "outputs": [],
      "source": [
        "if PRETRAINED:\n",
        "  checkpoint = torch.load(TRAINING_MODEL_PATH)\n",
        "  model.to(DEVICE)\n",
        "  model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE, weight_decay= L2_WEIGHT_DECAY)\n",
        "\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "if SCHEDULER == \"ReduceLROnPlateau\":\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=10)\n",
        "elif SCHEDULER == \"CosineAnnealingLR\":\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fn0XAwlyK2S6"
      },
      "outputs": [],
      "source": [
        "# if PRETRAINED:\n",
        "#   checkpoint = torch.load(TRAINING_MODEL_PATH)\n",
        "#   model.to(DEVICE)\n",
        "#   model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "#   optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE, weight_decay= L2_WEIGHT_DECAY)\n",
        "#   if OPTIMIZER_LOAD:\n",
        "#     optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "\n",
        "#   # Manually set the new learning rate for this stage of training as loading optimizer's state dict will\n",
        "#   # load parameters that was there while saving the previous checkpoint but loading the optimizer's state dict is\n",
        "#   # crucial\n",
        "#   for param_group in optimizer.param_groups:\n",
        "#     param_group['lr'] = LEARNING_RATE\n",
        "\n",
        "#   if SCHEDULER == \"ReduceLROnPlateau\":\n",
        "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=SCHEDULER_PARAMS[\"factor\"], patience=SCHEDULER_PARAMS[\"patience\"], threshold=SCHEDULER_PARAMS[\"threshold\"], min_lr=SCHEDULER_PARAMS[\"min_lr\"])\n",
        "#   elif SCHEDULER == \"CosineAnnealingWarmRestarts\":\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=SCHEDULER_PARAMS[\"T_0\"], T_mult=SCHEDULER_PARAMS[\"T_mult\"], eta_min=SCHEDULER_PARAMS[\"eta_min\"])\n",
        "#   elif SCHEDULER == \"CosineAnnealingLR\":\n",
        "#     scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=SCHEDULER_PARAMS[\"T_max\"], eta_min=SCHEDULER_PARAMS[\"eta_min\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gK69cmOlRCvg"
      },
      "outputs": [],
      "source": [
        "# if not PRETRAINED:\n",
        "#     optimizer = torch.optim.Adam(model.parameters(), lr= LEARNING_RATE, weight_decay= L2_WEIGHT_DECAY)\n",
        "#     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=SCHEDULER_PARAMS[\"factor\"], patience=SCHEDULER_PARAMS[\"patience\"], threshold=SCHEDULER_PARAMS[\"threshold\"], min_lr=SCHEDULER_PARAMS[\"min_lr\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LqlFcFDSRCvh",
        "outputId": "11cc6c87-830f-415a-c482-35b9e3652e36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New learning rate: 0.0001\n"
          ]
        }
      ],
      "source": [
        "for param_group in optimizer.param_groups:\n",
        "    print(f\"New learning rate: {param_group['lr']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ig7E3afMOi-6"
      },
      "outputs": [],
      "source": [
        "# initial_lr_scheduler = scheduler.base_lrs[0]  # Assuming a single learning rate for all parameters\n",
        "# print(\"Initial learning rate of scheduler:\", initial_lr_scheduler)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOkP2HYpvsqr"
      },
      "source": [
        "### GPU Check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypne222KBjPe"
      },
      "outputs": [],
      "source": [
        "# # memory footprint support libraries/code\n",
        "# !ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "# !pip install gputil\n",
        "# !pip install psutil\n",
        "# !pip install humanize\n",
        "# import psutil\n",
        "# import humanize\n",
        "# import os\n",
        "# import GPUtil as GPU\n",
        "\n",
        "# GPUs = GPU.getGPUs()\n",
        "# # XXX: only one GPU on Colab and isn’t guaranteed\n",
        "# gpu = GPUs[0]\n",
        "# def printm():\n",
        "#  process = psutil.Process(os.getpid())\n",
        "#  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "#  print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "# printm()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtHHjC45vsqr"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcACWXgAXHQu"
      },
      "source": [
        "#### Saving Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzIGIAe2FmJQ"
      },
      "outputs": [],
      "source": [
        "def store_batch_training_details(epoch, batch_count_train, batch_train_loss):\n",
        "  # Directory where you want to save the CSV file\n",
        "  directory = store_batch_training_details_path\n",
        "\n",
        "  # Ensure the directory exists\n",
        "  os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "  # File path\n",
        "  file_path = os.path.join(directory, name_of_batch_training_details_csv + f\"{epoch}.csv\")\n",
        "\n",
        "  # Write to CSV file\n",
        "  with open(file_path, \"w\", newline=\"\") as file:\n",
        "      writer = csv.writer(file)\n",
        "      # Write header\n",
        "      writer.writerow([\"Batch Count Train\", \"Batch Train Loss\"])\n",
        "      # Write data rows\n",
        "      for batch_count, train_loss in zip(batch_count_train, batch_train_loss):\n",
        "          writer.writerow([batch_count, train_loss])\n",
        "\n",
        "  print(f\"CSV file for epoch-{epoch}has been created at: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5-0shprvsqr"
      },
      "outputs": [],
      "source": [
        "def store_batch_validation_details(epoch, batch_count_val, batch_val_score_values):\n",
        "  # Directory where you want to save the CSV file\n",
        "  directory = store_batch_validation_details_path\n",
        "\n",
        "  # Ensure the directory exists\n",
        "  os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "  # File path\n",
        "  file_path = os.path.join(directory, name_of_batch_validation_details_csv + f\"{epoch}.csv\")\n",
        "\n",
        "  # Write to CSV file\n",
        "  with open(file_path, \"w\", newline=\"\") as file:\n",
        "      writer = csv.writer(file)\n",
        "      # Write header\n",
        "      writer.writerow([\"Batch Count Validation\", \"Batch Validation Loss\"])\n",
        "      # Write data rows\n",
        "      for batch_count, batch_val_score in zip(batch_count_val, batch_val_score_values):\n",
        "          writer.writerow([batch_count, batch_val_score])\n",
        "\n",
        "  print(f\"CSV file for validation, epoch-{epoch}has been created at: {file_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijkQ3VlU-unm"
      },
      "outputs": [],
      "source": [
        "# Function to save the data dynamically\n",
        "def save_progress(epoch_count, loss_values, val_loss_values, filepath= Path(save_progress_path)):\n",
        "    # Create a dictionary of lists\n",
        "    data = {\n",
        "        'epoch': epoch_count,\n",
        "        'train_loss': loss_values,\n",
        "        'val_loss': [None] * (len(epoch_count) - len(val_loss_values)) + val_loss_values\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Save DataFrame to CSV (mode='w' to write from scratch each time, mode='a' to append)\n",
        "    df.to_csv(filepath, index=False, mode='w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PTogqmQgWkZC"
      },
      "outputs": [],
      "source": [
        "# Function to save the data dynamically\n",
        "def save_dice_score(epoch_count, val_score_values, filepath= Path(save_dice_score_path)):\n",
        "    # Create a dictionary of lists\n",
        "    data = {\n",
        "        'epoch': epoch_count,\n",
        "        'val_dice_scores': [None] * (len(epoch_count) - len(val_score_values)) + val_score_values\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Save DataFrame to CSV (mode='w' to write from scratch each time, mode='a' to append)\n",
        "    df.to_csv(filepath, index=False, mode='w')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ntFd7ioHXHQv"
      },
      "outputs": [],
      "source": [
        "# Function to save the data dynamically\n",
        "def save_losses(bce_losses=bce_losses, dice_losses=dice_losses, focal_losses=focal_losses, filepath= Path(save_3losses_path)):\n",
        "    # Create a dictionary of lists\n",
        "    data = {\n",
        "        'bce': bce_losses,\n",
        "        'dice': dice_losses,\n",
        "        'focal': focal_losses\n",
        "    }\n",
        "\n",
        "    # Create a DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Save DataFrame to CSV (mode='w' to write from scratch each time, mode='a' to append)\n",
        "    df.to_csv(filepath, index=False, mode='w')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMFmkSOtXHQv"
      },
      "source": [
        "#### Training Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "0bPiRNBuK2S6",
        "outputId": "540cc7ef-2a68-4bd0-c7c1-099e6619bd1a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/238 [00:39<?, ?it/s, learning_rate=0.0001, loss=1.04]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CSV file for epoch-1has been created at: /content/drive/MyDrive/Saved Models/Final_Model1024_from_0.8342/Project-2_EXP_first_run_12_04_2025/first_run_train_m512_b8/Project-2_TRAIN_512_b_8_epoch_1.csv\n",
            "EPOCH: 1, TRAIN LOSS: 1.0399261713027954\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "score: 0.00660:   9%|▉         | 25/268 [00:29<04:47,  1.18s/it, dice_score=tensor(0.0059), val_loss=1.27]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-71-04b3d3783826>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;34m\"\"\"-------------------VALIDATION---------------------\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mdice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_count_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_val_score_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Evaluates model performance by calculating the dice coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mval_score_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mval_loss_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-70-73f6ec662a91>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(valid_loader, model, epoch, device, metric, loss_fn)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m             \u001b[0mdice_ave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;31m# iou_ave = jc(output, label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mdice_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdice_ave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-67-63e7e327dde5>\u001b[0m in \u001b[0;36mmetric\u001b[0;34m(probability, truth)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m600.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m720.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m420.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mdice_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \"\"\"\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0mdice_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# tensor of size 8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mdice_neg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_neg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mneg_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# selects elements of dice_neg acc to the indices in neg_index, it can have more than one element.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "till_epoch = EPOCHS\n",
        "model.to(DEVICE)\n",
        "model.train()\n",
        "# Lists to store epoch-to-epoch progress details\n",
        "epoch_count = []\n",
        "loss_values = []\n",
        "val_score_values = []\n",
        "val_loss_values = []\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(1, till_epoch+1):\n",
        "    epoch_count.append(epoch)\n",
        "    loss, batch_count_train, batch_train_loss = train_one_epoch(train_dataloader, model, optimizer, criterion, epoch=epoch)\n",
        "    loss_values.append(loss)\n",
        "    store_batch_training_details(epoch, batch_count_train, batch_train_loss)\n",
        "    if not isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "        scheduler.step()\n",
        "    # Storing Training details for plotting curves and inference\n",
        "    print(f\"EPOCH: {epoch}, TRAIN LOSS: {loss}\")\n",
        "\n",
        "    \"\"\"-------------------VALIDATION---------------------\"\"\"\n",
        "    dice, batch_count_val, batch_val_score_values, val_loss = evaluate(val_dataloader, model, epoch=epoch) # Evaluates model performance by calculating the dice coefficient\n",
        "    val_score_values.append(dice)\n",
        "    val_loss_values.append(val_loss)\n",
        "    # Storing Validation details for plotting curves and inference\n",
        "    store_batch_validation_details(epoch, batch_count_val, batch_val_score_values)\n",
        "    print(f\"EPOCH: {epoch}, TRAIN LOSS: {loss}, VAL DICE: {dice}\")\n",
        "\n",
        "    save_progress(epoch_count, loss_values, val_loss_values)\n",
        "    save_dice_score(epoch_count, val_score_values)\n",
        "    save_losses()\n",
        "# \"\"\"\" If it is necessary to save model's state dict as checkpoint, do the essential changes\n",
        "#      in Early Stopping class.\"\"\"\n",
        "\n",
        "    if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
        "        scheduler.step(dice)\n",
        "\n",
        "    es(epoch, dice, model, optimizer, loss, model_path= model_checkpoint_path + f\"_epoch{epoch}_bst_model{IMG_SIZE}_fold{FOLD_ID}_{np.round(dice,4)}.tar\")\n",
        "    if es.early_stop:\n",
        "        print('\\n\\n -------------- EARLY STOPPING -------------- \\n\\n')\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cO0V40DhG6TM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "key_patch_map = np.load(\"C:/Users/nisha/Desktop/Research Project May-June/gt_keypatch/1.2.276.0.7230010.3.1.4.8323329.300.1517875162.258081.npy\")\n",
        "sns.heatmap(key_patch_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aRoO5PvbG6TM"
      },
      "outputs": [],
      "source": [
        "plt.imshow(key_patch_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSUJdNHlG6TM"
      },
      "outputs": [],
      "source": [
        "key_patch_map.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-LO3JIgG6TN"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "key_patch_map = torch.unsqueeze(torch.Tensor(key_patch_map), axis=0)\n",
        "print(key_patch_map.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiisnexiffgL"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0HjWY9ZfpjI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kD5eQNVliJ4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gJFz9wAhzL4k"
      },
      "source": [
        "# Visualizations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jgLZEbqwyAb4"
      },
      "source": [
        "20 mins for a single epoch of training and validation together with T4 GPU. If the no. of epoches is 50 and early stopping is 10, let's see how many hours it takes to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7ptGWY9E2cn"
      },
      "source": [
        "Visualizations for the predictions!!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KC5W67ovsqs"
      },
      "outputs": [],
      "source": [
        "# # Visualization of epoch to epoch progress while training\n",
        "# plt.style.use(\"seaborn-v0_8\")221d\n",
        "52\n",
        "# fig, ax = plt.subplots()awjk\n",
        "506\n",
        "132\n",
        "54\n",
        "# ax.plot(epoch_count, loss_values)\n",
        "# ax.set_title(\"Training Loss Curve [EPOCHS]\", fontsize=20)\n",
        "# ax.set_xlabel(\"epoch number\", fontsize=14)\n",
        "# ax.set_ylabel(\"loss value\", fontsize=14)\n",
        "# ax.tick_params(axis='both', labelsize=14)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8TB_fU0f1jh"
      },
      "outputs": [],
      "source": [
        "# # Visualization of epoch to epoch progress while training\n",
        "# plt.style.use(\"seaborn-v0_8\")\n",
        "# fig, ax = plt.subplots()\n",
        "\n",
        "# ax.plot(epoch_count, val_loss_values)\n",
        "# ax.set_title(\"Validation Loss Curve [EPOCHS]\", fontsize=20)\n",
        "# ax.set_xlabel(\"epoch number\", fontsize=14)\n",
        "# ax.set_ylabel(\"loss value\", fontsize=14)\n",
        "# ax.tick_params(axis='both', labelsize=14)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZ2c6YzKSuFU"
      },
      "outputs": [],
      "source": [
        "# # Visualization of epoch to epoch progress while training\n",
        "# plt.style.use(\"seaborn-v0_8\")\n",
        "# plt.figure(figsize=(10, 6))\n",
        "# plt.plot(epoch_count, loss_values)\n",
        "# plt.plot(epoch_count, val_loss_values)\n",
        "# plt.title(\"Training and Validation Loss Curves\", fontsize=20)\n",
        "# plt.xlabel(\"epoch number\", fontsize=14)\n",
        "# plt.ylabel(\"loss value\", fontsize=14)\n",
        "# plt.legend()\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n2BXTyFrPxzy"
      },
      "outputs": [],
      "source": [
        "# Load data from CSV into a DataFrame\n",
        "file_path = save_progress_path  # Replace with your CSV file path\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Plotting the line plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(df['epoch'], df['train_loss'], marker='o', linestyle='-', color='b', label='Train Loss')\n",
        "plt.plot(df['epoch'], df['val_loss'], marker='o', linestyle='-', color='r', label='Validation Loss')\n",
        "\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOQs9Sy2VBHR"
      },
      "source": [
        "# Sample Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_QmgkWSGPsu"
      },
      "outputs": [],
      "source": [
        "# checkpoint = torch.load(es.BEST_MODEL_PATH)\n",
        "# print(es.best_score)\n",
        "# model.to(DEVICE)\n",
        "# model.load_state_dict(checkpoint[\"model_state_dict\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnM0qtplSwyW"
      },
      "outputs": [],
      "source": [
        "# model.to(DEVICE)\n",
        "# model.eval()\n",
        "# idx = 1995\n",
        "# mask = val_dataset[idx][\"mask\"].unsqueeze(0)\n",
        "# print(\"Mask Shape: \",mask.shape)\n",
        "# image = val_dataset[idx][\"image\"].unsqueeze(0)\n",
        "# print(\"Image Shape: \",image.shape)\n",
        "# raw_output = model(image.to(DEVICE))\n",
        "# print(\"raw output shape: \", raw_output.shape)\n",
        "# print(\"------ Raw Output ------\")\n",
        "# print(raw_output)\n",
        "# print(\"------- Pred Probs -------\")\n",
        "# pred_probs = torch.sigmoid(raw_output)\n",
        "# print(pred_probs)\n",
        "# print(\"------- How does the Mask look like? ------\")\n",
        "# print(mask)\n",
        "# print(\"-------- Predicted Segmentation mask --------\")\n",
        "# # binarizer_fn = TripletMaskBinarization(triplets=[[0.7, 600, 0.3]])\n",
        "# # mask = binarizer_fn.transform(mask).float()\n",
        "# # print(segmentation_mask)\n",
        "# segmentation_mask = (pred_probs > 0.4).float()\n",
        "# print(segmentation_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cALrPDiZFyhu"
      },
      "outputs": [],
      "source": [
        "# mask.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prdvPG3XZiuL"
      },
      "outputs": [],
      "source": [
        "# segmentation_mask.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAzD4mVaTYJg"
      },
      "outputs": [],
      "source": [
        "# plt.style.use(\"classic\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak3eAHrDdY_V"
      },
      "outputs": [],
      "source": [
        "# first_channel_tensor = image[0, 0, :, :]\n",
        "# print(first_channel_tensor.shape)  # torch.Size([512, 512])\n",
        "# second_channel_tensor = image[0, 1, :, :]\n",
        "# print(second_channel_tensor.shape)  # torch.Size([512, 512])\n",
        "# third_channel_tensor = image[0, 2, :, :]\n",
        "# print(third_channel_tensor.shape)  # torch.Size([512, 512])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LRJzqWT1drZv"
      },
      "outputs": [],
      "source": [
        "# plt.title(\"First Channel Image\")\n",
        "# plt.imshow(first_channel_tensor.detach().cpu().numpy(), cmap=\"gray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tS4Lttr2TLad"
      },
      "outputs": [],
      "source": [
        "# plt.imshow(mask.squeeze().detach().cpu().numpy(), cmap = 'gray')\n",
        "# print(mask.squeeze().shape)\n",
        "# plt.title(\"Mask\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_X9nSoL1TNw_"
      },
      "outputs": [],
      "source": [
        "# print(segmentation_mask.squeeze().shape)\n",
        "# plt.imshow(segmentation_mask.squeeze().detach().cpu().numpy(), cmap='gray')\n",
        "# plt.title(\"Segmentation Mask\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xi-kZiELUV79"
      },
      "outputs": [],
      "source": [
        "# print(type(pred_probs), type(mask))\n",
        "# print(pred_probs.shape, mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKAY7_pFh_Vt"
      },
      "outputs": [],
      "source": [
        "# print(segmentation_mask.squeeze().squeeze().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sm9Qm1_FiFbS"
      },
      "outputs": [],
      "source": [
        "# print(mask.squeeze().squeeze().shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kiIFEw2TPZn"
      },
      "outputs": [],
      "source": [
        "# # \"\"\"\n",
        "# # Both methods aim to capture the overlap between predicted positive regions and actual positive regions in the ground truth.\n",
        "# # The dice_metric approach leverages the full range of predicted probabilities, while the  metric function relies on a binary classification based on a chosen threshold.\n",
        "# # \"\"\"\n",
        "# # Dice = metric(pred_probs.detach().cpu(), mask).item()\n",
        "# # print(f\"Dice coefficient: {Dice}\")\n",
        "# # dice_metric_score = dice_metric(pred_probs.detach().cpu(), mask)\n",
        "# # print(f\"Dice coefficient: {dice_metric_score}\")\n",
        "\n",
        "# \"\"\"\n",
        "# Both methods aim to capture the overlap between predicted positive regions and actual positive regions in the ground truth.\n",
        "# The dice_metric approach leverages the full range of predicted probabilities, while the  metric function relies on a binary classification based on a chosen threshold.\n",
        "# \"\"\"\n",
        "# Dice = metric(segmentation_mask.detach().cpu(), mask).item()\n",
        "# print(f\"Dice coefficient: {Dice}\")\n",
        "# dice_metric_score = dice_metric(segmentation_mask.squeeze().squeeze().detach().cpu(), mask.squeeze().squeeze(), per_image=False)\n",
        "# print(f\"Dice coefficient: {dice_metric_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLi3ZH-8ALZM"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5P0OtlxdALZN"
      },
      "outputs": [],
      "source": [
        "# from torchvision.transforms import Resize\n",
        "# from torchvision.utils import make_grid\n",
        "\n",
        "\n",
        "# def preprocess_image(image, target_size):\n",
        "#     transform = Resize(target_size)\n",
        "#     image = transform(image)\n",
        "#     return image\n",
        "\n",
        "# def generate_predictions(model, images):\n",
        "#     with torch.inference_mode():\n",
        "#         predictions = model(images.to(DEVICE))\n",
        "#         predictions = torch.sigmoid(predictions)\n",
        "#         return predictions\n",
        "\n",
        "\n",
        "# def visualize_predictions(images, target_masks, preds):\n",
        "#     images = images.cpu() # shape: [8, 3, 1024, 1024] or [8, 3, 512, 512]\n",
        "#     target_masks = target_masks.cpu() # shape: [8, 1, 1024, 1024] or [8, 1, 512, 512]\n",
        "#     preds = preds.cpu() # shape: [8, 1, 1024, 1024] or [8, 1, 512, 512]\n",
        "\n",
        "#     fig, axes = plt.subplots(2, 3, figsize=(20, 30))\n",
        "\n",
        "#     for i in range(2):\n",
        "#         # axes[i, 0].imshow(images[i].permute(1, 2, 0))\n",
        "#         axes[i, 0].imshow(images[i, 0], cmap=\"gray\")\n",
        "#         axes[i, 0].set_title(\"Input Image\")\n",
        "#         # axes[i, 0].axis(\"off\")\n",
        "\n",
        "#         axes[i, 1].imshow(target_masks[i, 0], cmap=\"gray\")\n",
        "#         axes[i, 1].set_title(\"Target Mask\")\n",
        "#         # axes[i, 1].axis(\"off\")\n",
        "\n",
        "#         axes[i, 2].imshow(preds[i, 0], cmap=\"gray\")\n",
        "#         axes[i, 2].set_title(\"Model 512 prediction\")\n",
        "#         # axes[i, 2].axis(\"off\")\n",
        "\n",
        "#     plt.tight_layout()\n",
        "#     plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CPbHLrDvALZN"
      },
      "outputs": [],
      "source": [
        "# \"\"\"----------------------------- Inference --------------------------------\"\"\"\n",
        "\n",
        "# metrics512 = defaultdict(float)\n",
        "# for b_idx, data in enumerate(val_dataloader):\n",
        "#     batch_images = data[\"image\"] # shape: [8, 3, 1024, 1024]\n",
        "#     images_resized_512 = preprocess_image(batch_images, (512, 512))\n",
        "\n",
        "#     # Generate predictions\n",
        "#     preds = generate_predictions(model, images_resized_512)  # shape: [1, 1, 512, 512]\n",
        "#     print(\"preds - Shape: \", preds.shape, \" || device: \", preds.get_device())\n",
        "#     seg_mask_ensemble_512 = preds > 0.4\n",
        "#     # mask preprocessing\n",
        "#     batch_masks = data[\"mask\"]\n",
        "#     masks_resized_512 = preprocess_image(batch_masks, (512, 512))\n",
        "\n",
        "\n",
        "\n",
        "#     print(\"---------------------------- Dice Scores -----------------------------------\")\n",
        "\n",
        "\n",
        "#     dice_scores_512 = dice_metric(seg_mask_ensemble_512, masks_resized_512.to(DEVICE), per_image=True)\n",
        "#     print(\"dice_scores_512 - Shape: \", dice_scores_512.shape, \" || type: \", type(dice_scores_512))\n",
        "\n",
        "#     # dice_scores_1024 = dice_metric(combined_pred, batch_images.to(DEVICE), per_image=True)\n",
        "#     # print(\"dice_scores_1024 - Shape: \", dice_scores_1024.shape, \" || type: \", type(dice_scores_1024))\n",
        "\n",
        "#     print(\"Dice scores of predictions on the 512x512 scale\\n\", dice_scores_512)\n",
        "#     print(\"Dice score of the batch 512x512 scale: \", dice_scores_512.mean())\n",
        "\n",
        "#     print(\"---------------------------- SCALE = 1024x1024 -----------------------------------\")\n",
        "#     visualize_predictions(batch_images, batch_masks, seg_mask_ensemble_512)\n",
        "#     print(\"-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-x-\")\n",
        "#     break"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Y7HFiESzDWcY",
        "Xfcsl-YW_ck9",
        "3A4XlffPf1jV",
        "7xtZrBIJeLH_",
        "A-y8ovXEK2St",
        "od_pZDUoK2Su",
        "EqxMQpqB5JFV",
        "BNLEHf3QK2Sv",
        "6-dcysMmK2Sw",
        "Vzze2VhIK2S5",
        "kOlM9jTEK2S5",
        "K136b3eqK2S5",
        "pOkP2HYpvsqr",
        "LcACWXgAXHQu",
        "gJFz9wAhzL4k",
        "iOQs9Sy2VBHR",
        "cLi3ZH-8ALZM"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}